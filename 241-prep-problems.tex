


\documentclass[letterpaper,oneside]{book}%
\newcommand{\onlinetext}{https://content.byui.edu/file/c2f91762-7a1e-4d0b-a1ae-8d5f5f548e17/1/341-Book.pdf}
\newcommand{\urllineartransformationsinplane}{http://bmw.byuimath.com/dokuwiki/doku.php?id=2d\_linear\_transformations}


\newif\ifinstructor
%% uncomment one of the following, depending if you want to include the
%% instructor notes or not
%\instructortrue
\instructorfalse


\newif\ifnotes
%% uncomment one of the following, depending if you want to include the
%% instructor notes or not
%\notestrue
\notesfalse



\usepackage[left=1in,right=2.75in,top=1in,bottom=1in]{geometry}
\marginparwidth 1.75in

%5\usepackage{tabls}
\usepackage{booktabs}
\usepackage{amsmath,amssymb,amsthm,amsfonts,mathrsfs}
\usepackage{multicol}
%\usepackage{enumitem}
\usepackage{microtype}
\usepackage{pstricks}
\usepackage{tikz}
\usetikzlibrary{positioning}

\usetikzlibrary{arrows}
\newcommand{\midarrow}{\tikz \draw[-triangle 90] (0,0) -- +(.1,0);}


\newcommand{\myscale}{1}

%\usepackage{comment}


\usepackage{graphicx}
%\usepackage{wrapfig}

\newcommand{\ds}{\displaystyle}
\newcommand{\dfdx}[1]{\frac{d#1}{dx}}
\newcommand{\ddx}{\frac{d}{dx}}
\newcommand{\WA}[1]{\marginpar{\href{#1}{See WolframAlpha}}}


\let\oldmarginpar\marginpar
\renewcommand\marginpar[1]{\-\oldmarginpar{\raggedright\footnotesize #1}}
%\renewcommand\marginpar[1]{\-\oldmarginpar[\raggedleft\footnotesize #1]{\raggedright\footnotesize #1}}


%\usepackage[12hr]{datetime}
%\newdateformat{draftdate}{%
%\shortdayofweekname{\THEDAY}{\THEMONTH}{\THEYEAR}, %
%\THEDAY\ \shortmonthname[\THEMONTH] \THEYEAR}
%\draftdate
%\usepackage{eso-pic}
%\AddToShipoutPicture{\put(10,10){\small Draft: \today\ at \currenttime }}%--- version: \MakeUppercase{\svnInfoRevision}}}

\newcommand{\bmw}[1]{#1}
\newcommand{\marginparbmw}[1]{\bmw{\marginpar{#1}}}

% Notes for Larson, 5th edition
\newcommand{\larsonfive}[1]{}

% Instructor-specific material (answers, helps, etc.)
\ifinstructor
  \newcommand{\instructor}[1]{\marginpar{\textbf{Instructor: }#1}}
\else
  \newcommand{\instructor}[1]{}
\fi

\ifnotes
\renewcommand{\thefootnote}{\roman{footnote}}
\newcommand{\note}[1]{\footnote{#1}\marginpar{\fbox{\textbf{\thefootnote}}}}
\else
\newcommand{\note}[1]{}
\fi

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem*{theorem*}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem*{lemma*}{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}


\newtheoremstyle{box}%
{}{}% standard spacing before and after
{}% Body style
{}{\bfseries}{.}% Heading indent, font, and punctuation
{ }% space after heading
{\thmname{#1}\thmnumber{ #2}\thmnote{: #3}}% head spec

\newtheoremstyle{problem}%
{}{}% standard spacing before and after
{}% Body style
{}{\bfseries}{}% Heading indent, font, and punctuation
{1em}% space after heading
{\fbox{\thmname{#1}\thmnumber{ #2}\thmnote{: #3}}}% head spec

\theoremstyle{box}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{dfn}[theorem]{Definition}
\newtheorem*{definition*}{Definition}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{question}[theorem]{Question}
\newtheorem*{prep-problems}{Preparation Problems}

%\newtheorem{problem}[theorem]{Problem}
\theoremstyle{problem}
\newtheorem{problemnum}{Problem}[chapter]
\newtheorem*{problemnum*}{Problem}
\newtheorem*{hwenum*}{Home Work Practice}
\newtheorem*{reviewnum*}{Review}
\newenvironment{problem}[1][]{\begin{problemnum}[#1]}{\end{problemnum}\nopagebreak\hrule\bigskip}
\newenvironment{problem*}[1][]{\begin{problemnum*}[#1]}{\end{problemnum*}\nopagebreak\hrule\bigskip}
\newenvironment{hw*}[1][]{\begin{hwenum*}[#1]}{\end{hwenum*}\nopagebreak\hrule\bigskip}
\newenvironment{review*}[1][]{\begin{reviewnum*}[#1]}{\end{reviewnum*}\nopagebreak\hrule\bigskip}


% Abbreviations
\newcommand{\ii}{\ensuremath{\vec \imath}}
\newcommand{\jj}{\ensuremath{\vec \jmath}}
\newcommand{\kk}{\ensuremath{\vec k}}
\newcommand{\vv}{\ensuremath{\mathbf{v}}}
\newcommand{\colvec}[1]{\ensuremath{\begin{bmatrix}#1\end{bmatrix}}}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\rref}{rref}
\DeclareMathOperator{\vspan}{span}
\DeclareMathOperator{\trace}{tr}
\DeclareMathOperator{\proj}{proj}
\DeclareMathOperator{\curl}{curl}
\newcommand{\RR}{\ensuremath{\mathbb{R}}}
% \vp is "vector prime" and corrects spacing when doing something like
% $\vec r'$ (which has the vector and prime almost touching).
% Instead, do something like $\vec r\vp$
\newcommand{\vp}{\ensuremath{^{\,\prime}}}

%The purpose of this code is to allow me to put lines in matrices so that I can create augmented matrices.
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

\newcommand{\cl}[1]{  \begin{matrix}  #1  \end{matrix}  }
\newcommand{\bm}[1]{  \begin{bmatrix}  #1  \end{bmatrix}  }
\newcommand{\inv}{^{-1}}
\newcommand{\im}{\ensuremath{\text{im }}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\blank}[1]{\raisebox{0pt}[14pt]{\rule{#1}{1pt}}}

\newcommand{\pvec}[1]{\begin{pmatrix} #1 \end{pmatrix}}
\newcommand{\nvec}[1]{\begin{matrix} #1 \end{matrix}}
\newcommand{\bvec}[1]{\begin{bmatrix} #1 \end{bmatrix}}

%------------------------------------------------------------------------------------------------------------

\usepackage{color}
\definecolor{darkblue}{rgb}{0, 0, .6}
\usepackage[breaklinks]{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=darkblue,
	anchorcolor=darkblue,
	citecolor=darkblue,
%	pagecolor=darkblue,
	urlcolor=darkblue,
}

\begin{document}

\mainmatter

\chapter{Vector and Matrix Operations}

\section{Prep for Tuesday April 23}

We can use vectors to model the velocity of moving objects.  The next two problems ask you to do this.

\begin{problem}
 Consider the curve traced out by the equations $x=\cos t$, $y=\sin t$. You could think of theses equations as describing the position of a plane, where at time $t$, the plane is at the position $(x,y)$.  
\begin{enumerate}
 \item Draw the curve in the $xy$ plane.  Remember to create a $t|(x,y)$ table to show how you got this curve. Next to several points, write the $t$ value used to get to this point. 
 \item At $t=\pi/6$, what is a velocity vector for the plane?  Draw this vector on your graph. 
\end{enumerate}
\end{problem}

\begin{problem}
 What happens if you double the speed of the plane?  We can model doubling the speed by replacing $t$ with $2t$ to obtain the equation $x=\cos 2t, y=\sin 2t$.
\begin{enumerate}
 \item Draw the curve in the $xy$ plane.  Remember to create a $t|(x,y)$ table to show how you got this curve. Next to several points, write the $t$ value used to get to this point. 
 \item At $t=\pi/12$, what is a velocity vector for the plane?  Draw this vector on your graph. How is this related to the vector from part 2 of the previous problem.
\end{enumerate}

\end{problem}


Another use of vectors has to do with modeling forces around us. You can think of forces as pushes and pulls. In the next two problems, your job is to draw a vector field. 

\begin{problem}
 Consider the function $\vec F(x,y) = (2x+y, x+2y)$. This is a function where the input is a point $(x,y)$, and the output is a vector $(2x+y,x+2y)$. For example, at the point $(1,0)$, the vector is $\vec F(1,0) = (2(1)+0,1+2(0))=(2,1)$.  To draw this function, we make a graph in the $xy$ plane where at each point $(x,y)$ we draw an arrow which starts at this point and follows the vector. So at the point (1,0) we would draw an arrow that points right 2 and up 1.  
\begin{enumerate}
 \item Construct a sketch of this vector field by picking several points in the plane and drawing the corresponding vectors.  
 \item When you feel like you understand this vector field, check your work by following this \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=vector_field_plotter}{technology link}.
 \item Does this vector field pull things inwards, or push things outwards?  
Are there any directions in which this vector field pushes things either straight out or pulls things straight in?
\end{enumerate}
\end{problem}


\begin{problem}
 Consider the vector field $\vec F(x,y) = (-y, x+y)$. 
\begin{enumerate}
 \item Construct a sketch of this vector field by picking several points in the plane and drawing the corresponding vectors.  You should check your work with the link above when you feel like you have an good understanding of the field.
 \item Suppose you drop an object into this field at the point $(2,0)$, and then the vectors started pushing the object. What path would the object follow?  Obtain a computer printout of the vector field from this \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=vector_field_plotter}{technology link} and draw the path of the object on your plot.  Then pick several other starting points besides (2,0) and draw the path as well.
\end{enumerate}
\end{problem}


Your preparation for tomorrow is to come to class with solutions to these 4 problems. There is a difference between the work you will do to discover a problem (scratch work), and the work you would do to share your results with someone else. Please come to class having done both (discovered, and then organized in a way that you can share with others).  Write each problem on its own sheet of paper.  I'll be asking a few of you, at random, to share your work with the class.  I'll collect the page you have prepared (this is why each should be on its own page), scan it, and then display your work on the overhead projector and let you share what you did. Do your best to organize your work in a manner that others can easily follow what you have done. 


\section{Prep for Thursday April 25}

\begin{problem}
 Joe rows a boat across a river.  He rows due east at  3 m/s.  The river flows southeast, and has velocity vector $(1,-1)$.  
\begin{enumerate}
 \item If Joe is currently at $(0,0)$, where will he be after 1 second? after 2 seconds?  After 3 seconds?
 \item What is Joe's actual speed? (This should be a number, namely distance/time, not a vector).  What's the speed of the river? 
 \item If Joe can paddle 3 m/s in any direction, which direction should Joe point his boat so that he moves due east, after taking into account the flow of the river?
\end{enumerate}
\end{problem}


\begin{problem}
 Sally is trying to find a treasure that's located in a corn field (she's geocaching). 
Her position is currently at $(0,0)$, and she knows that the treasure is located at $(7,8)$ (units are hundreds of yards). 
She can't walk in a straight line to the geocache, because that would damage the rows of corn.  
The corn is planted in rows that run parallel to the vector $(2,1)$.  
She's currently on a road that moves parallel to the vector $(-1,2)$. 
The farmer will only allow her to walk parallel to the rows of corn (if she crosses between rows, she might damage the crop).  
So she has to follow the road for some distance by following the vector $(-1,2)$ along the road, and then enter the rows of corn and follow the vector $(2,1)$.   
\begin{enumerate}
 \item 
What does the vector equation 
$$\begin{pmatrix}-1\\2\end{pmatrix}x+\begin{pmatrix}2\\1\end{pmatrix}y=\begin{pmatrix}7\\8\end{pmatrix}$$ 
have to do with Sally's problem.
 \item 
Find values for $x$ and $y$ that make this equation valid. 
 \item 
(Optional) How far does Sally travel along the road?  How far does she travel in the corn?
\end{enumerate}

\end{problem}


\begin{problem}
A plane is flying in a circle above a city (the center of the city is at $(0,0)$).  The plane's path is given by $(x,y) = (3\cos t, 3\sin t)$.  The pilot places the plane on autopilot to continue this circular path. After the plane has been placed on autopilot, the wind starts blowing. The pilot doesn't adjust for the wind, which means the pilot will start to veer off course.  Your job on this problem is to figure out the path of the plane.
\begin{enumerate}
 \item The velocity of the plane without the wind is $(x',y') = (-3\sin t, 3\cos t)$.  The wind blows somewhat northeast and results in a new velocity vector for the plane of $(x',y') = (-3\sin t, 3\cos t)+(1/3, 1/5)$. Find equations for $x(t)$ and $y(t)$ that would give the position of the plane. Then graph the plane's position for $t$ between 0 and $4\pi$. You can use \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=parametric_curve_plotter}{this parametric curve plotter} to check your work. Follow the link.
 \item If the wind speed were to double, how would this change your work above.  Repeat the previous part with twice the wind speed.
 
In class, we'll look at what happens if we change the plane speed and the wind speed.
\end{enumerate}

\end{problem}



\begin{problem}
 A triangle has corners at $P=(0,0,0)$, $Q=(a,b,c)$, and $R=(d,e,f)$. Your job on this problem is to find a formula that would give the angle between the segments $PQ$ and $PR$.  Here are some helps.  
\begin{itemize}
 \item Try finding the length of each edge first.
\item Once you know the length of each edge, the law of cosines will get you the angle.  Feel free to look up and use the law of cosines.
 \item If you're struggling with the fact that it's all variables, try doing this problem with some numbers like (2,3), and (5,7), and doing it in 2D instead of 3D. Your work in 2D will generalize to give the answer in 3D.    
\end{itemize}


\end{problem}



\section{Prep for Friday April 26}

%Review problem about dot products of vectors would be great.
\begin{problem}[Dot Product and Angles]
 Do the following:
\begin{enumerate}
 \item If $\vec u = (u_1,u_2,\ldots, u_n)$ and $\vec v = (v_1,v_2,,\ldots,v_n)$ are vectors with $n$ components, then define the dot product of the two vectors $\vec u\cdot \vec v$.  You can find a definition in your Schaum's text, or you can look one up on the web.
 \item Compute the dot products $(2,1)\cdot(-1,2)$ and then $(1,2,-2)\cdot (3,0,4)$.  
 \item 
\marginpar{This is the formula we developed in Problem 1.8. It comes from the law of cosines.}
The angle $\theta$ between two vectors $\vec u$ and $\vec v$ satisfies the equation
$$\cos\theta = \frac{\vec u\cdot \vec v}{|\vec u||\vec v|}$$ where $|\vec u|$ is the length of $\vec u$. Find the angle between $(2,1)$ and $(-1,2)$, and then find the angle between $(1,2,-2)$ and $(3,0,4)$. You'll need to compute the lengths of each vector along the way.
\end{enumerate}
\end{problem}


%We want to get to solving linear systems.  So have a problem involving a linear combination of vectors. Connect it to a problem involving two lines.
Here's a formal definition of a linear combination.
\begin{definition}[Linear Combination]
 Given $n$ vectors  $\vec v_1, \vec v_2,\cdots,\vec v_n$ and $n$ scalars $c_1, c_2, \cdots, c_n$ their linear combination is the sum $$c_1\vec v_1+c_2\vec v_2+\cdots+c_n\vec v_n.$$

 Given $n$ functions $f_1,f_2,\cdots,f_n$ and $n$ scalars $c_1, c_2, \cdots, c_n$ their linear combination is the sum 
$$c_1f_1+c_2 f_2+\cdots+c_nf_n.$$

 In general, if we have $n$ objects $o_1, o_2, \cdots, o_n$ where it makes sense to multiply each by a scalar $c_i$ and then add them, then their linear combination is precisely 
$$c_1o_1+c_2 o_2+\cdots+c_no_n.$$
\end{definition}

\begin{problem}
 Complete each of the following.
\begin{enumerate}
 \item Consider the vectors $\vec v_1 = (1,2,3)$ and $\vec v_2= (2,0,-1)$ and the scalars $c_1=2$ and $c_2=-3$.  Compute and simplify their linear combination. You should obtain a single vector.
 \item Is the vector $(7,8)$ a linear combination of the vectors $\vec v_1 = (-1,2)$ and $\vec v_2=(2,1)$? If it is, then state the scalars $c_1$ and $c_2$ needed. 
 \item Is the vector $(1,0,0)$ a linear combination of the vectors $(1,0,1)$ and $(0,1,1)$ and $(1,1,2)$?  If it is, then state the scalars $c_1$ and $c_2$. 

[Hint: Solve the equation $c_1(1,0,1) + c_2(0,1,1)+c_3(1,1,2) = (1,0,0)$.  This is the same as solving
$x(1,0,1) + y(0,1,1)+z(1,1,2) = (1,0,0)$
or in column form 
$$x\pvec{1\\0\\1} + y\pvec{0\\1\\1}+z\pvec{1\\1\\2} = \pvec{1\\0\\0}.]$$
\end{enumerate}

\end{problem}




%Introduce a matrix (look up the definition, or by column). Have them produce a few matrices. 
\begin{problem}[Matrix]
 
\begin{enumerate}
  \item State the definition of a matrix.
  \item How do you determine the size of a matrix.  Give an example of a 3 by 4 matrix and in your example show us how to find the $a_{3,2}$ entry. 
  \item Define and give an example of each of the following special types of matrices: 
\begin{multicols}{3}
\begin{itemize}
 \item square matrix
 \item diagonal matrix 
 \item symmetric matrix 
 \item zero matrix 
 \item row matrix
 \item column matrix.
\end{itemize}
 \end{multicols}
 \end{enumerate}

\end{problem}


%Have a problem that asks them about matrix multiplication (have them look it up, define it, and come to class with an example).  
\begin{definition}[The Product $A\vec x$ of a Matrix $A$ and a vector $\vec x$]
Suppose that $A = \begin{bmatrix}\vec v_1&\vec v_2&\cdots& \vec v_n\end{bmatrix}$
is a matrix where the columns are the vectors $\vec v_1, \vec v_2,\ldots, \vec v_n$. 
Let $\vec x = (x_1,x_2,\ldots,x_n)$ be a vector of scalars. 
We define the product of a matrix $A$ and a vector $\vec x$ to be the linear combination
$$
A\vec x = \begin{bmatrix}\vec v_1&\vec v_2&\cdots& \vec v_n\end{bmatrix} \begin{bmatrix}x_1\\ x_2 \\ \vdots \\ x_n \end{bmatrix} = x_1\vec v_1+x_2\vec v_2+\cdots+x_n\vec v_n = \sum_{i=1}^n x_i \vec v_i.
$$ 
\end{definition}

\begin{problem}
 Use the definition above to compute the following products. Make sure you show the intermediate steps you used, as this will show how you used linear combinations. The second problem shows the first step (though it leaves some blanks for you to fill in).
\begin{enumerate}
 \item 
$
\begin{bmatrix}
  1&2
\end{bmatrix}
\begin{bmatrix}
  3\\4
\end{bmatrix}
$
 \item 
$
\begin{bmatrix}
  1&4\\2&5\\3&6
\end{bmatrix}
\begin{bmatrix}
  3\\-2
\end{bmatrix}
=
\begin{bmatrix}
  1\\2\\3
\end{bmatrix}
?+
\begin{bmatrix}
  ?\\?\\?
\end{bmatrix}
(-2)
=\cdots$
 \item 
$
\begin{bmatrix}
  \nvec{0\\1\\2\\-1\\0}&
  \nvec{1\\0\\0\\2\\0}&
  \nvec{0\\0\\3\\-1\\0}&
  \nvec{2\\1\\0\\0\\1}&
\end{bmatrix}
\begin{bmatrix}
  3\\-1\\0\\2
\end{bmatrix}
$
\end{enumerate}
 
\end{problem}



\section{Prep for Monday April 29}

\marginpar{You'll find all the definitions you need in your Schaum's Outlines book.  You'll also find examples of each idea that you are welcome to use.}%
For today, our goal is to become much more comfortable with matrices.  We'll learn some additional operations with matrices, such as the product of two matrices, the transpose of a matrix, and the trace of a matrix. We'll also practice looking for patterns, making conjectures, and showing that our conjectures are valid. 

\begin{definition}[The Product $AB$ of a Matrix $A$ and a matrix $B$]
Let $m$, $n$, and $p$ be positive integers.
Suppose that 
$$A = \begin{bmatrix}\vec a_1&\vec a_2&\cdots& \vec a_n\end{bmatrix}
=\begin{bmatrix}
\nvec{a_{1,1}\\a_{2,1}\\\vdots\\a_{m,1}}
&\nvec{a_{1,2}\\a_{2,2}\\\vdots\\a_{m,2}}
&\nvec{\cdots\\\cdots\\\ddots\\\cdots}
&\nvec{a_{1,n}\\a_{2,n}\\\vdots\\a_{m,n}}
\end{bmatrix}$$
is an $m$ by $n$ matrix where the columns are the vectors $\vec a_1, \vec a_2,\ldots, \vec a_n$. 
Suppose 
$$B = 
\begin{bmatrix}\vec b_1&\vec b_2&\cdots& \vec b_p\end{bmatrix}
=\begin{bmatrix}
\nvec{b_{1,1}\\b_{2,1}\\\vdots\\b_{n,1}}
&\nvec{b_{1,2}\\b_{2,2}\\\vdots\\b_{n,2}}
&\nvec{\cdots\\\cdots\\\ddots\\\cdots}
&\nvec{b_{1,p}\\b_{2,p}\\\vdots\\b_{n,p}}
\end{bmatrix}$$
is an $n$ by $p$ matrix where the columns are the vectors $\vec b_1, \vec b_2,\ldots, \vec a_p$.
Then we define the matrix product $AB$ to be the $m$ by $p$ matrix given by
\begin{align*}
AB 
&= A\begin{bmatrix}\vec b_1&\vec b_2&\cdots& \vec b_p\end{bmatrix} \\
&= \begin{bmatrix}A\vec b_1 & A\vec b_2 & \cdots & A\vec b_p\end{bmatrix}
\end{align*}
The $j$th column of $AB$ is the product of the matrix $A$ and the vector $\vec b_j$, which means it is a linear combination of the columns of $A$ using the scalars in $\vec b_{j}$.   
\end{definition}

You can use the Sage matrix product calculator on the web to check any of your answers. Just follow the link
\begin{itemize}
 \item \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=matrix\_product\_calculator}{http://bmw.byuimath.com/dokuwiki/doku.php?id=matrix\_product\_calculator}
\end{itemize}
Let's now practice this definition.
\begin{problem}[Matrix Products]\label{matrix product problem}
 Consider the matrices
$$
A=
\begin{bmatrix}
 1&2\\3&4\\5&6
\end{bmatrix},
B=
\begin{bmatrix}
 1&2&-1&0\\3&-1&2&1
\end{bmatrix},
C=
\begin{bmatrix}
 0&1\\-1&2\\3&0\\4&-1
\end{bmatrix}
$$
\begin{enumerate}
 \item Compute the product $AB$.  Show your intermediate steps.  Remember to check your work with the technology link before this problem.
 \item Why can you not compute the product $AC$? 
 \item When we multiply numbers together, the order doesn't matter.  We can compute either $bc$ or $cb$ and we'll get the same answer.  Is this true with matrices?  Does $BC=CB$? Compute both.
\end{enumerate}

\end{problem}

\begin{problem}[Commutativity]
Construct two matrices $D$ and $E$, both 2 by 2, so that $DE=ED$.  
Then construct two matrices $F$ and $G$, both 2 by 2, so that $FG\neq GF$. 
You'll need 4 matrices, and 4 matrix products. 

Which was easier to find, an example where the matrix product is commutative, or an example where the matrix product is not commutative?
\end{problem}

\begin{problem}[The Transpose of a Matrix]
Start by defining the transpose, written $A^T$, of a matrix $A$.  
\begin{enumerate}
 \item Compute $A^T$ and $B^T$, where $A$ and $B$ come from Problem \ref{matrix product problem}.
 \item Consider the matrices $A$ and $B$ given by
$A
=\begin{bmatrix}
\nvec{1\\3}
&\nvec{2\\4}
\end{bmatrix}
$ and 
$B 
=\begin{bmatrix}
\nvec{5\\7}
&\nvec{6\\8}
\end{bmatrix}$. Let $C=A+B$. Compute $A^T$, $B^T$, and $C^T$. Then conjecture a relationship between $A^T$, $B^T$, and $C^T$. 
 \item Now consider the matrices $A$ and $B$ given by
$$A
=\begin{bmatrix}
\nvec{a_{1,1}\\a_{2,1}\\\vdots\\a_{m,1}}
&\nvec{a_{1,2}\\a_{2,2}\\\vdots\\a_{m,2}}
&\nvec{\cdots\\\cdots\\\ddots\\\cdots}
&\nvec{a_{1,n}\\a_{2,n}\\\vdots\\a_{m,n}}
\end{bmatrix}
\quad \text{and}\quad 
B 
=\begin{bmatrix}
\nvec{b_{1,1}\\b_{2,1}\\\vdots\\b_{m,1}}
&\nvec{b_{1,2}\\b_{2,2}\\\vdots\\b_{m,2}}
&\nvec{\cdots\\\cdots\\\ddots\\\cdots}
&\nvec{b_{1,n}\\b_{2,n}\\\vdots\\b_{m,n}}
\end{bmatrix}$$
Let $C=A+B$. What are the $(i,j)$ entries of $A^T$, $B^T$, and $C^T$? What does this mean about the connection between $A^T$, $B^T$, and $C^T$?
\end{enumerate}
 
\end{problem}

\newcommand{\tr}{\text{tr}}
\begin{problem}[The Trace of a Matrix]
Start by  defining the trace of a matrix. 
\begin{enumerate}
 \item Construct a matrix $A$ whose trace is not zero, and a nonzero matrix $B$ whose trace is zero.
 \item Let $C=\begin{bmatrix}c_{1,1}&c_{1,2}\\c_{2,1}&c_{2,2}\end{bmatrix}$. We compute the product $kC$ by multiplying each entry in $C$ by $k$. Compute the trace of $C$ and the trace of $kC$. Make a conjecture about the connection between the trace of $C$ and the trace of $kC$. 
 \item For the $n$ by $n$ matrix
$A
=\begin{bmatrix}
\nvec{a_{1,1}\\a_{2,1}\\\vdots\\a_{n,1}}
&\nvec{a_{1,2}\\a_{2,2}\\\vdots\\a_{n,2}}
&\nvec{\cdots\\\cdots\\\ddots\\\cdots}
&\nvec{a_{1,n}\\a_{2,n}\\\vdots\\a_{n,n}}
\end{bmatrix}
$, compute the trace of $A$ and the trace of $kA$. What pattern do you see?
\end{enumerate}
\end{problem}


\section{Prep for Tuesday April 30}

%Graph three planes with a computer.  Use the computer to  solve a system of equations. Then rewrite the system as a linear combination problem (same problem, just ask them what the solution is). Then give them 3 different planes that intersect in a line.  Ask them to repeat this problem (write down what the computer says).  The point is to get them ready for the definition below.
\begin{problem}
 Each of the equations $x+2y-z=3$, $2x-y+4z=0$, and $-x+2z=4$ represents a plane in 3D.  Use the software link, \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=visualizing\_systems\_of\_equations}{Visualizing Systems of Equations},  to graph these three planes. How many points of intersection are there? State the point of intersection.  

 Now repeat the above with the planes $x+2y-z=3$, $2x-y+4z=0$, and $-5y+6z=-6$.  How many points of intersection are there?  State the points of intersection (or just write down whatever the software gave you as a solution). If you let $z=0$, what are $x$ and $y$?  

 If I wanted to write the vector $(3,0,4)$ as a linear combination of the vectors $(1,2,-1)$, $(2,-1,0)$, and $(-1,4,2)$, then what should I let $c_1$, $c_2$, and $c_3$ equal so that 
$$ c_1(1,2,-1)+c_2(2,-1,0)+c_3(-1,4,2)=(3,0,4),$$ 
which we could rewrite in the easier to use column form
$$ c_1\pvec{1\\2\\-1}+c_2\pvec{2\\-1\\0}+c_3\pvec{-1\\4\\2}=\pvec{3\\0\\4}.$$
[Hint: What does this have to do with the first part?] 

\end{problem}



\begin{definition}[Linear Dependence]
We say that a set of vectors $\{\vec v_1,\vec v_2, \ldots, \vec v_n\}$ is linearly independent if the only solution to the vector equation $$c_1\vec v_{1}+c_2\vec v_{2}+\ldots+c_n\vec v_{n}=\vec 0$$ is the trivial solution where $c_1=c_2=\cdots=c_n=0$. 
Otherwise we say the vectors are linearly dependent.

When the vectors are linearly dependent, it is always possible to write one of the vectors as a linear combination of the other vectors. 
We say the vectors are dependent because one of them depends on (can be obtained as a linear combination of) the others.
\end{definition}

%We need a problem that gets at dependent, independent, and inconsistent.  Have them do some.  Maybe use software to get at this in 2D (no need for software in 2D).  Do this in the context of vectors to start with. Show that the vectors ... are linearly independet.  Show that the vectors ... are linearly dependent. 
\begin{problem}
Use the definition above to complete the following.
\begin{enumerate}
 \item  
Show that the vectors $(-1,2)$ and $(2,1)$ are linearly independent. (Solve the equation $c_1\pvec{-1\\2}+c_2\pvec{2\\1}=\pvec{0\\0}$. Replace $c_1$ and $c_2$ with $x$ and $y$ if you'd rather work with $x$ and $y$. )
 \item 
Then show that the vectors $(-1,2)$ and $(3,-6)$ are linearly dependent. (Solve the system $c_1(-1,2)+c_2(3,-6)=(0,0)$ and show there are infinitely many solutions).  Then write one of the vectors as a linear combination of the others. 
%Can you give another vector $(a,b)$ so that $(-1,2)$ and $(a,b)$ are linearly dependent?
 \item
Show that the vectors $(1,0)$, $(1,1)$, and $(a,b)$ are always linearly dependent by finding $c_1$ and $c_2$ so that $(a,b) = c_1(1,0)+c_2(1,1)$. 
\end{enumerate}
\end{problem}



%Use software to get at this idea of independence in 3D. Have them examine graphically what happens in 2 cases (repeat of problem 1). 
\begin{problem}
 Are the vectors $\vec v_1 = (1,3,5)$, $ \vec v_2=(-1,0,1)$, and $\vec v_3=(0,3,1)$ linearly independent?  Solve the system $c_1\vec v_1+c_2\vec v_2+c_3\vec v_3=\vec 0$ to answer this question. If they are dependent, then write one of the vectors as a linear combination of the others.


 Are the vectors $\vec v_1 = (1,2,0)$, $ \vec v_2=(2,0,3)$, and $\vec v_3=(3,-2,6)$ linearly independent?  Solve the system $c_1\vec v_1+c_2\vec v_2+c_3\vec v_3=\vec 0$ to answer this question.  If they are dependent, then write one of the vectors as a linear combination of the others. 

\marginpar{After writing the problems above as system of 3 equations with 3 unknowns, you can use the software link \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=visualizing\_systems\_of\_equations}{Visualizing Systems of Equations} to obtain a solution.}
[Hint: Rewrite each of these problems as a system of 3 equations.  Then you may use software to answer each problem.  You do  not need to show your work on this problem, rather show what system you use, what the software gave as an answer, and then how you used that solution to answer the question.]
\end{problem}



%Solve a problem with Gaussian elimination (no matrices).  Make it either a plane problem, a linear independence problem, or both (but ask them to do this one by hand).  Make it have a single solution (for ease).  You are of course welcome to check your answer with the computer.  Make the answer have somewhat nice integers. 
\begin{problem}
 Write the vector $(1,-4,5)$ as a linear combination of the vectors $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$.  

 Then write $(1,-4,5)$ as a linear combination of the vectors $(1,0,2)$, $(3,1,0)$, and $(4,-2,-1)$.  Show how to solve this system by hand. You are of course welcome to check your answer with technology.
\end{problem}

\note{In class, we took the corn problem and extended it.  I had them use the road (-1,1), the corn (2,1), and sprinklers (0,1), and then asked them to give several ways to get from the origin to the point (7,8).  It was amazing.  I had groups let x=0, let y=0, and then start letting variables equal lots of other things. It opened a great discussion up about free variables.  They did amazing. I was floored at how well it went. 

We then discussed.  We got to equations of lines in vector form. We talked about slope in middle school, and instead we could use vectors. I showed them how to get an equation of a line. in space.  It was amazing.  Do this example again in class, or have them come to class with several answers. It will open up a discussion.  I need more problems like this one. 
}

%\end{document}

%Gaussian elimination (no matrices)

\section{Prep for Thursday May 2}
Today we will focus on learning how to solve a system of equations by using Gaussian elimination. As you complete each problem, please check your work with Sage by following the link to the \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=rref\_calculator}{Sage RREF Calculator}.  \marginpar{Sage is a free open source computer algebra system that you can have your students use in high school.  See \href{http://sagemath.org/}{sagemath.org} for more information.}

The first part of your prep for tomorrow involves reading a few examples and/or watching some YouTube videos that describe the algorithm. I've created the following videos to supplement the reading below:
\begin{itemize}
 \item \href{http://www.youtube.com/watch?v=Di1Gr1jVMMk&feature=share&list=PL7A2089C33C8EFC84}{A system with 2 equations and 2 unknowns}
 \item \href{http://www.youtube.com/watch?v=9_lAevTRNTg&feature=share&list=PL7A2089C33C8EFC84}{A system with 3 equations and 3 unknowns}
 \item \href{http://www.youtube.com/watch?v=89QO4t1S-cA&feature=share&list=PL7A2089C33C8EFC84}{Interpreting RREF}
\end{itemize}
 

Gaussian elimination is an efficient algorithm we will use to solve systems of equations. This is the same algorithm implemented on most computers systems. The main idea is to eliminate each variable from all but one equation/row (if possible), using the following three operations (called elementary row operations):
\begin{enumerate}
  \item Multiply an equation (or row of a matrix) by a nonzero constant,
  \item Add a nonzero multiple of any equation (or row) to another equation,
  \item Interchange two equations (or rows).
\end{enumerate}
These three operations are the operations learned in college algebra when solving a system using a method of elimination.  Gaussian elimination streamlines elimination methods to solve generic systems of equations of any size. The process involves a forward reduction and (optionally) a backward reduction. The forward reduction creates zeros in the lower left corner of the matrix.  The backward reduction puts zeros in the upper right corner of the matrix. We eliminate the variables in the lower left corner of the matrix, starting with column 1, then column 2, and proceed column by column until all variables which can be eliminated (made zero) have been eliminated. Before formally stating the algorithm, let's look at a few examples. 

\begin{example}
Let's start with a system of 2 equations and 2 unknowns. I will write the augmented matrix representing the system as we proceed. To solve $$
\begin{array}{rr}
\begin{array}{rl}
x_1-3x_2&=4\\
2x_1-5x_2&=1 
\end{array}
&
\begin{bmatrix}[cc|c] 1&-3&4\\2&-5&1
\end{bmatrix} 
\end{array}
$$
we eliminate the $2x_1$ in the 2nd row by adding -2 times the first row to the second row.
$$\begin{array}{rr}
\begin{array}{rl}
x_1-3x_2&=4\\
x_2&=-7 
\end{array}
&
\begin{bmatrix}[cc|c] 1&-3&4\\0&1&-7
\end{bmatrix} 
\end{array}
$$
The matrix at the right is said to be in \textbf{row echelon form}. \marginpar{row echelon form} 
\begin{definition}[Row Echelon Form]
A matrix is in row echelon form if
\begin{itemize}
  \item each nonzero row begins with a 1 (called a leading 1),
  \item the leading 1 in a row occurs further right than a leading 1 in the row above, and
  \item any rows of all zeros appear at the bottom.
\end{itemize}
The position in the matrix where the leading 1 occurs is called a pivot. 
The column containing a pivot is called a pivot column. \marginpar{pivot column}
\end{definition}
At this point in our example, we can use ``back-substitution'' to get {$x_2=-7$} and {$x_1=4+3x_2 = 4-21=-17$}. 
Alternatively, we can continue the elimination process by eliminating the terms above each pivot, starting on the right and working backwards. 
This will result in a matrix where all the pivot columns contain all zeros except for the pivot. 
If we add 3 times the second row to the first row, we obtain.
$$\begin{array}{rr}
\begin{array}{rl}
x_1&=-17\\
x_2&=-7 
\end{array}
&
\begin{bmatrix}[cc|c] 1&0&-17\\0&1&-7
\end{bmatrix} 
\end{array}
$$
The matrix on the right is said to be in \textbf{reduced row echelon form} (or just rref). 
We can easily read solutions to systems of equations directly from a matrix which is in reduced row echelon form.

\begin{definition}[Reduced Row Echelon Form]
\marginpar{reduced row echelon form - rref}
We say that a matrix is in reduced row echelon form (rref) if 
\begin{itemize}
\item the matrix is in row echelon form, and 
\item each pivot column contains all zeros except for the pivot (leading one).
\end{itemize}
\end{definition}


\end{example}


\begin{example}
Let's now solve a system with 3 equations and 3 unknowns, namely 
$$\begin{array}{rl}
2x_1+x_2-x_3&=2\\
x_1-2x_2 &=3\\
4x_2+2x_3&=1
\end{array} \quad\quad\quad\quad\quad
 \begin{bmatrix}[ccc|c] 2&1&-1&2\\1&-2&0&3\\0&4&2&1\end{bmatrix}.$$ 
%We'll encounter some homogeneous systems later on.
To simplify the writing, we'll just use matrices this time. 
To keep track of each step, I will write the row operation next to the row I will replace. 
Remember that the 3 operations are (1) multiply a row by a nonzero constant, (2) add a multiple of one row to another, and (3) interchange any two rows.  
If I write $R_2+3R1$ next to $R_2$, then this means I will add 3 times row 1 to row 2.  
If I write $2R_2-R1$ next to $R_2$, then I have done two row operations, namely I multiplied $R_2$ by 2, and then added (-1) times $R1$ to the result (replacing $R2$ with the sum). 
The steps below read left to right, top to bottom. 
In order to avoid fractions, I wait to divide until the last step, only putting a 1 in each pivot at the very end.
\marginpar{Try using the \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=rref\_calculator}{Sage RREF Calculator} to check this result.}%
$$\begin{array}{rlcl}
\Rightarrow^{(1)}&
 \begin{bmatrix}[ccc|c] 2&1&-1&2\\1&-2&0&3\\0&4&2&1\end{bmatrix}
  \begin{array}{lr} \ \\2R_2-R_1\\ \ \end{array}
&\Rightarrow^{(2)}& 
\begin{bmatrix}[ccc|c] 2&1&-1&2\\0&-5&1&4\\0&4&2&1\end{bmatrix} 
\begin{array}{lr}\ \\ \ \\5R_3+4R_2 \end{array}
\\ \\ \Rightarrow^{(3)}&
 \begin{bmatrix}[ccc|c] 2&1&-1&2\\0&-5&1&4\\0&0&14&21\end{bmatrix} 
 \begin{array}{lr}\ \\ \ \\R_3/7 \end{array}
&\Rightarrow^{(4)}& 
\begin{bmatrix}[ccc|c] 2&1&-1&2\\0&-10&2&8\\0&0&2&3\end{bmatrix} 
\begin{array}{l} 2R_1+R_3\\R_2-R_3\\ \ \end{array}
\\ \\ \Rightarrow^{(5)}&
 \begin{bmatrix}[ccc|c] 4&2&0&7\\0&-10&0&5\\0&0&2&3\end{bmatrix}  
 \begin{array}{lr}\ \\R_2/5\\ \ \end{array} 
&\Rightarrow^{(6)}& 
\begin{bmatrix}[ccc|c] 4&2&0&7\\0&-2&0&1\\0&0&2&3\end{bmatrix}  
\begin{array}{lr} R_1+R_2\\ \ \\ \ \end{array}
\\ \\ \Rightarrow^{(7)}&
\begin{bmatrix}[ccc|c] 4&0&0&8\\0&-2&0&1\\0&0&2&3\end{bmatrix} 
\begin{array}{lr} R_1/4\\R_2/-2\\R_3/2 \end{array}
&\Rightarrow^{(8)}&  
\begin{bmatrix}[ccc|c] 1&0&0&2\\0&1&0&-1/2\\0&0&1&3/2\end{bmatrix} 
\end{array}
$$
Writing the final matrix in terms of a system, we have the solution {$x_1=2, x_2=-1/2, x_3=3/2$}. Remember that this tells us (1) where three planes intersect, (2) how to write the 4th column $\vec b$ in our original augmented matrix as a linear combination of the columns of the coefficient matrix $A$, and (3) how to solve the matrix equation $A\vec x = \vec b$ for $\vec x$.
\end{example}


The following steps describe the Gaussian elimination algorithm that we used above. 
Please take a moment to compare what is written below with the example above. 
Most of the problems in this unit can be solved using Gaussian elimination, so we will practice it as we learn a few new ideas.
\begin{enumerate}
\item Forward Phase (row echelon form - Gaussian Elimination) - The following 4 steps should be repeated until you have mentally erased all the rows or all the columns. In step 1 or 4 you will erase a column and/or row from the matrix.
\begin{enumerate}
	\item  
	\marginpar{Computer algorithms place the largest (in absolute value) nonzero entry in the first row. This reduces potential errors due to rounding that can occur in later steps.}
Consider the first column of your matrix. Start by interchanging rows (if needed) to place a nonzero entry in the first row. If all the elements in the first column are zero, then ignore that column in future computations (mentally erase the column) and begin again with the smaller matrix which is missing this column. If you ignore the last column, then stop.
  \item 
  Divide the first row (of your possibly smaller matrix) row by its leading entry so that you have a leading 1. This entry is a pivot, and the column is a pivot column. [When doing this by hand, it is often convenient to skip this step and do it at the very end so that you avoid fractional arithmetic. If you can find a common multiple of all the terms in this row, then divide by it to reduce the size of your computations.  ] 
	\item Use the pivot to eliminate each nonzero entry below the pivot, by adding a multiple of the top row (of your smaller matrix) to the nonzero lower row.
	\item 
	\marginpar{Ignoring rows and columns is equivalent to incrementing row and column counters in a computer program.}
	Ignore the row and column containing your new pivot and return to the first step (mentally cover up or erase the row and column containing your pivot). If you erase the last row, then stop.
\end{enumerate}
	\item Backward Phase (reduced row echelon form - often called Gauss-Jordan elimination) - At this point each row should have a leading 1, and you should have all zeros to the left and below each leading 1. If you skipped step 2 above, then at the end of this phase you should divide each row by its leading coefficient to make each row have a leading 1.
\begin{enumerate}
	\item Starting with the last pivot column, use the pivot in that column to eliminate all the nonzero entries above it. Do so by adding multiples of the row containing the pivot to the nonzero rows above the pivot. 
	\item Work from right to left, using each pivot to eliminate the nonzero entries above it. Notice that since everything to the left of the pivot is zero in the pivot row, nothing to the left of the current pivot column changes when you eliminate above the pivot.  By working right to left, you greatly reduce the number of computations needed to fully reduce the matrix.
\end{enumerate}
\end{enumerate}


\begin{example}\label{ex rref last}
As a final example, let's reduce 
{\small $
\begin{bmatrix}[cccc|c]
 0 & 1 & 1 & -2 & 7 \\
  1 & 3 & 5 & 1 & 6 \\
 2 & 0 & 4 & 3 & -8 \\
 -2 & 1 & -3 & 0 & 5
\end{bmatrix}
$} to reduced row echelon form (rref). The first step involves swapping 2 rows. We swap row 1 and row 2 because this places a 1 as the leading entry in row 1.
\marginpar{Try using the \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=rref\_calculator}{Sage RREF Calculator} to check this result.}%
{\small  $$\begin{array}{rlcl}
\multicolumn{2}{l}{\text{(1) Get a nonzero entry in upper left}}&
\multicolumn{2}{l}{\text{(2) Eliminate entries in 1st column}}\\
\Rightarrow&
\begin{bmatrix}[cccc|c]
 0 & 1 & 1 & -2 & 7 \\
  1 & 3 & 5 & 1 & 6 \\
 2 & 0 & 4 & 3 & -8 \\
 -2 & 1 & -3 & 0 & 5
\end{bmatrix}
  \begin{array}{lr} R_1\leftrightarrow R_2 \\ \ \\ \ \\ \ \end{array}
&\Rightarrow& 
\begin{bmatrix}[cccc|c]
  1 & 3 & 5 & 1 & 6 \\
 0 & 1 & 1 & -2 & 7 \\
 2 & 0 & 4 & 3 & -8 \\
 -2 & 1 & -3 & 0 & 5
\end{bmatrix}
  \begin{array}{lr} \ \\ \ \\ R_3-2R_1 \\ R_4+2R_1 \end{array}
\\ \\
\multicolumn{2}{l}{\text{(3) Eliminate entries in 2nd column}}&
\multicolumn{2}{l}{\text{(4) Make a leading 1 in 4th column}}\\
\Rightarrow&
\begin{bmatrix}[cccc|c]
  1 & 3 & 5 & 1 & 6 \\
 0 & 1 & 1 & -2 & 7 \\
 0 & -6 & -6 & 1 & -20 \\
 0 & 7 & 7 & 2 & 17
\end{bmatrix}
  \begin{array}{lr} \ \\ \ \\ R_3+6R_2 \\ R_4-7R_2 \end{array}
&\Rightarrow& 
\begin{bmatrix}[cccc|c]
  1 & 3 & 5 & 1 & 6 \\
 0 & 1 & 1 & -2 & 7 \\
 0 & 0 & 0 & -11 & 22 \\
 0 & 0 & 0 & 16 & -32
\end{bmatrix}
  \begin{array}{lr} \ \\ \ \\ R_3/(-11) \\ R_4/16 \end{array}
\\ \\
\multicolumn{2}{l}{\text{(5) Eliminate entries in 4th column}}&
\multicolumn{2}{l}{\text{(6) Row Echelon Form}}\\
\Rightarrow&
\begin{bmatrix}[cccc|c]
  1 & 3 & 5 & 1 & 6 \\
 0 & 1 & 1 & -2 & 7 \\
 0 & 0 & 0 & 1 & -2 \\
 0 & 0 & 0 & 1 & -2
\end{bmatrix}
  \begin{array}{lr} \ \\ \ \\ \ \\ R_4-R_3 \end{array}
&\Rightarrow& 
\begin{bmatrix}[cccc|c]
  1 & 3 & 5 & 1 & 6 \\
 0 & 1 & 1 & -2 & 7 \\
 0 & 0 & 0 & 1 & -2 \\
 0 & 0 & 0 & 0 & 0
\end{bmatrix}
\end{array}
$$}\begin{picture}(0,0)
\begin{tikzpicture}[scale=.39]
\draw[help lines,step=1cm,transparent] (0,0) grid (30,20);
\draw[opacity=.2,fill][shift={(2.6,16.6)}] (0,0) rectangle (1.4,.8);
\draw[opacity=.2,fill][shift={(19.6,13.6)}] (0,0) rectangle (1.4,2.8);
\draw[opacity=.1,fill][shift={(2.6,10.6)}] (0,0) rectangle (8.9,.8);
\draw[opacity=.1,fill][shift={(2.6,7.6)}] (0,0) rectangle (.7,3.8);
\draw[opacity=.2,fill][shift={(3.9,7.6)}] (0,0) rectangle (1.4,1.8);
\draw[opacity=.1,fill][shift={(19.5,10.6)}] (0,0) rectangle (8.1,.8);
\draw[opacity=.1,fill][shift={(19.5,7.6)}] (0,0) rectangle (.7,3.8);
\draw[opacity=.1,fill][shift={(20.8,9.6)}] (0,0) rectangle (6.8,.8);
\draw[opacity=.1,fill][shift={(20.8,7.6)}] (0,0) rectangle (.7,2.8);
\draw[opacity=.1,fill][shift={(22.15,7.6)}] (0,0) rectangle (.7,1.8);
\draw[opacity=.2,fill][shift={(23.6,8.6)}] (0,0) rectangle (1.6,.8);

\draw[opacity=.1,fill][shift={(2.6,4.6)}] (0,0) rectangle (7.2,.8);
\draw[opacity=.1,fill][shift={(2.6,1.6)}] (0,0) rectangle (.7,3.8);
\draw[opacity=.1,fill][shift={(3.9,3.6)}] (0,0) rectangle (5.9,.8);
\draw[opacity=.1,fill][shift={(3.9,1.6)}] (0,0) rectangle (.7,2.8);
\draw[opacity=.1,fill][shift={(5.2,1.6)}] (0,0) rectangle (.7,1.8);
\draw[opacity=.2,fill][shift={(6.7,1.6)}] (0,0) rectangle (1.1,.8);

\draw[opacity=.1,fill][shift={(19.5,4.6)}] (0,0) rectangle (7.2,.8);
\draw[opacity=.1,fill][shift={(19.5,1.6)}] (0,0) rectangle (.7,3.8);
\draw[opacity=.1,fill][shift={(20.8,3.6)}] (0,0) rectangle (5.9,.8);
\draw[opacity=.1,fill][shift={(20.8,1.6)}] (0,0) rectangle (.7,2.8);
\draw[opacity=.1,fill][shift={(22.15,1.6)}] (0,0) rectangle (.7,1.8);
\draw[opacity=.1,fill][shift={(23.6,1.6)}] (0,0) rectangle (1.1,1.8);
\draw[opacity=.1,fill][shift={(23.6,2.6)}] (0,0) rectangle (3.1,.8);
\draw[opacity=.1,fill][shift={(25.6,1.6)}] (0,0) rectangle (1.1,.8);

\end{tikzpicture}
\end{picture}At this stage we have found a row echelon form of the matrix. 
Notice that we eliminated nonzero terms in the lower left of the matrix by starting with the first column and working our way over column by column.  Columns 1, 2, and 4 are the pivot columns of this matrix. We now use the pivots to eliminate the other nonzero entries in each pivot column (working right to left).\marginpar{Recall that a matrix is in reduced row echelon (rref) if:
\begin{enumerate}
	\item Nonzero rows begin with a leading 1. 
	\item Leadings 1's on subsequent rows appear further right than previous rows. 
	\item Rows of zeros are at the bottom.
	\item Zeros are above and below each pivot.
\end{enumerate}}
{\small $$ \begin{array}{rlcl}
\multicolumn{2}{l}{\text{(7) Eliminate entries in 4th column}}&
\multicolumn{2}{l}{\text{(8) Eliminate entries in 2nd column}}\\
\Rightarrow&
\begin{bmatrix}[cccc|c]
  1 & 3 & 5 & 1 & 6 \\
 0 & 1 & 1 & \begin{picture}(0,0)(0,3) \tikz \draw[scale=.39,fill,opacity=.2] (0,0) rectangle (1.6,2);\end{picture}
							-2 & 7 \\
 0 & 0 & 0 & 1 & -2 \\
 0 & 0 & 0 & 0 & 0
\end{bmatrix}
  \begin{array}{lr} R_1-R3 \\ R_2+2R_3 \\ \ \\ \ \end{array}
&\Rightarrow& 
\begin{bmatrix}[cccc|c]
  1 & \begin{picture}(0,0)(4,3) \tikz \draw[scale=.39,fill,opacity=.2] (0,0) rectangle (1,1);\end{picture}
  		3 & 5 & 0 & 8 \\
 0 & 1 & 1 & 0 & 3 \\
 0 & 0 & 0 & 1 & -2 \\
 0 & 0 & 0 & 0 & 0
\end{bmatrix}
  \begin{array}{lr} R_1-3R_2 \\ \ \\ \ \\ \ \end{array}
\\ \\ 
\multicolumn{2}{l}{\text{(9) Reduced Row Echelon Form}}&
\multicolumn{2}{l}{\text{(10) Switch to system form}}\\
\Rightarrow&
\begin{bmatrix}[cccc|c]
  1 & 0 & 2 & 0 & -1 \\
 0 & 1 & 1 & 0 & 3 \\
 0 & 0 & 0 & 1 & -2 \\
 0 & 0 & 0 & 0 & 0
\end{bmatrix}
&\Rightarrow& 
\begin{array}{rl}
x_1+2x_3&=-1\\
x_2+x_3&=3\\
x_4&=-2\\
0&=0
\end{array}
\end{array}
$$}We have obtained the reduced row echelon form. 
When we write this matrix in the corresponding system form, notice that there is not a unique solution to the system. Because the third column did not contain a pivot column, we can write every variable in terms of $x_3$ (the redundant equation $x_3=x_3$ allows us to write $x_3$ in terms of $x_3$). We are free to pick any value we want for $x_3$ and still obtain a solution. For this reason, we call $x_3$ a free variable, \marginpar{Free variables correspond to non pivot columns. Solutions can be written in terms of free variables.} and write our infinitely many solutions in terms of $x_3$ as 
$$
\begin{array}{ll}
x_1=-1-2x_3\\
x_2=3-x_3\\
x_3=x_3\\
x_4=-2
\end{array}
\quad \text{ or by letting $x_3=t$ }\quad
\begin{array}{ll}
x_1=-1-2t\\
x_2=3-t\\
x_3=t\\
x_4=-2
\end{array}
.
$$
\marginpar{parametric form}By choosing a value (such as $t$) for $x_3$, we can write our solution in so called parametric form. We have now given a parametrization of the solution set, where $t$ is an arbitrary real number. 
\end{example}




\begin{problem}
Each of the following augmented matrices requires one row operation to be in reduced row echelon form. Perform the required row operation, and then write the solution to the corresponding system of equations. If there are infinitely many solutions, write the solution by expressing each unknown in terms of the free variables.
\begin{multicols}{2}
\begin{enumerate}
	\item 
$
\begin{bmatrix}[ccc|c]
 1 & 0 & 0 & 3 \\
 0 & 0 & 1 & 1 \\
 0 & 1 & 0 & -2
\end{bmatrix}
$
	\item 
$
\begin{bmatrix}[ccc|c]
 1 & 2 & 0 & -4 \\
 0 & 0 & 1 & 3 \\
 -3 & -6 & 0 & 12
\end{bmatrix}
$
	\item 
$
\begin{bmatrix}[ccc|c]
 1 & 0 & 2 & 4 \\
 0 & 1 & -3 & 0 \\
 0 & 0 & 0 & 1
\end{bmatrix}
$
	\item 
$
\begin{bmatrix}[ccccc|c]
 0 & 1 & 0 & 7 & 0 & 3 \\
 0 & 0 & 1 & 5 & -3 & -10 \\
 0 & 0 & 0 & 0 & 1 & 2 \\
 0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}
$
\end{enumerate}
\end{multicols}
\end{problem}

\begin{problem}
\marginpar{Use the \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=rref\_calculator}{Sage RREF Calculator} to check your result.}%
Use Gaussian elimination to solve 
\begin{align*}
  x_2 -2x_3 &= -5 \\
 2x_1 -x_2 + 3x_3 &= 4 \\
 4x_1 +x_2 + 4x_3 &= 5
\end{align*}
by row reducing the matrix to reduced row echelon form.
[Hint: Start by interchanging row 1 and row 2.] 

Use your work above to write the vector $(-5,4,5)$ as linear combination of the vectors $(0,2,4)$, $(1,-1,1)$, and $(-2,3,4)$.
\end{problem}

\begin{problem}
\marginpar{Use the \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=rref\_calculator}{Sage RREF Calculator} to check your result.}%
Use Gauss-Jordan elimination to solve the linear system
\begin{align*}
 x_1 -2x_2 +x_3 &= 4 \\
 -x_1 + 2x_2 + 3x_3 &= 8 \\
 2x_1  -4x_2 +x_3 &= 5.
\end{align*}
Using Gauss-Jordan elimination requires that you find the reduced row echelon form of the matrix. 
[Hint: You should end up with infinitely many solutions. State your solution by writing each variable in terms of the free variable(s).]
\end{problem}

\begin{problem}
\marginpar{Use the \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=rref\_calculator}{Sage RREF Calculator} to check your result.}%
Use Gauss-Jordan elimination to solve 
\begin{align*}
 x_1 + 2x_3 + 3x_4 &= -7 \\
 2x_1 +x_2 + 4x_4 &= -7 \\
 -x_1 + 2x_2 + 3x_3  &= 0 \\
 x_2  -2x_3  -x_4 &= 4.
\end{align*}


\end{problem}



%All are done.  
%They need to read an example.  Copy and paste from my text. 
%Gaussian elimination, with matrices. (one solution)
%Gaussian elimination, with matrices. (we need an example with infinitely many solutions.)
%Discuss the new method. Then have them solve with matrices.
%Gauss Jordan elimination, with matrices
%Gauss Jordan elimination, with matrices
%(we need an example with infinitely many solutions, or no solution.  Maybe both.)
%Maybe we just need a problem that has them interpret RREF and state solutions from RREF alone.
%\end{document}

\section{Prep for Friday May 3}
With each prep problem for today, you will need to row reduce matrices.  Use software to check all your work. The goal today is to learn how to interpret the reduced row echelon form of a matrix to make decisions. 

%Are vectors independent or dependent? Make it real (moving around in space?) Which pairs are/are not independent. Make this involve a rocket.
\begin{problem}\label{rocket booster problem}
Imagine you are in a rocket traveling through space.  The rocket has 4 boosters on it, which currently allow you to travel in any direction you want.  The boosters provide thrust in a specific direction (vector), with the ability to adjust how strong the push should be in each direction (possibly even moving backwards in that direction). The 4 boosters allow movement in the directions $(1,1,2)$, $(0,1,3)$, $(2,1,1)$, and $(-2,1,0)$.
\begin{enumerate}
 \item 
\marginpar{Use the \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=rref\_calculator}{Sage RREF Calculator} to check your result.}%
Start by row reducing the matrix 
$\begin{bmatrix}
1 & 0 & 2 & -2 \\
1 & 1 & 1 & 1 \\
2 & 3 & 1 & 0
\end{bmatrix}$ to determine which columns are pivot columns. Check your answer with technology.
 \item If the 4th booster breaks, could some linear combination of the first three rocket thrusts allow you to move in the direction of the 4th rocket? In other words, is it possible to write $(-2,1,0)$ as a linear combination of $(1,1,2)$, $(0,1,3)$, and $(2,1,1)$? You should be able to use your rref above to answer this.
 \item If the 3rd booster breaks, show that some linear combination of the other three rocket thrusts allow you to move in the direction of the 3rd rocket? What is that linear combination. If you decide to use a new matrix to answer this questions, use software to obtain the rref. Just show the class the matrix you started with, and its rref, without any steps along the way. 
 \item You have been asked to give advice on a new rocket design. The designers figure that as long as they pick 3 directions in which to provide thrust, they should be able to fly in any direction they want. They attach boosters which allow movement in the directions $(1,3,2)$, $(-3,1,4)$, $(0,1,1)$. Set up an appropriate matrix and use software to row reduce the matrix. What advice would you give the designers?
 \item What does any of the above have to do with linear independence and linear dependence?
\end{enumerate}
\note{In class, I would like to talk about what it would take to design a rocket so that any of the three rockets could go out, and you would still be able to move freely in space.  All they would need is an rref that I followed by a column with no zero entries.  But I would like them to figure this out.  }
\end{problem}

%Linear combination facts from rref (the rref tells you how the columns are related to the pivots polumns)
\begin{problem}
\marginpar{Use the \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=rref\_calculator}{Sage RREF Calculator} to check your result.}%
Start by finding the reduced row echelon form of the matrix
$$
B = 
\begin{bmatrix}
\nvec{2\\1}&
\nvec{-1\\1}&
\nvec{1\\0}&
\nvec{0\\1}&
\nvec{2\\0}&
\nvec{0\\3}&
\nvec{2\\3}
\end{bmatrix}.
$$
Show the steps you used to row reduce this matrix. The point to this problem is to help you see how this single row reduction can answer all of the questions below. 
\begin{enumerate}
 \item Write $(1,0)$ as a linear combination of $(2, 1)$ and $(-1,1)$. Remember, that when writing $c_1(2,1)+c_2(-1,1)=(1,0)$, you must solve for the unknown constants. Feel free to row reduce the augmented matrix  
$\begin{bmatrix}
\nvec{2\\1}&
\nvec{-1\\1}&
\nvec{1\\0}
\end{bmatrix}
$
with technology. You don't need to show any steps of the computation.
 \item Write $(0,1)$ as a linear combination of $(2, 1)$ and $(-1,1)$. Remember, that when writing $c_1(2,1)+c_2(-1,1)=(0,1)$, you must solve for the unknown constants. If you decide to row reduce the matrix
$\begin{bmatrix}
\nvec{2\\1}&
\nvec{-1\\1}&
\nvec{0\\1}
\end{bmatrix}
$, then use technology and don't show us any of the intermediate steps. 
 \item Continue to write each of $\pvec{2\\0}$, $\pvec{0\\3}$, and $\pvec{2\\3}$ as a linear combination of $\pvec{2\\1}$ and $\pvec{-1\\1}$. [Hint: At some point, rather than row reducing 
$\begin{bmatrix}
\nvec{2\\1}&
\nvec{-1\\1}&
\vec v
\end{bmatrix}
$, ask yourself how you could use the larger matrix to answer this.]
\item The following matrix row reduces to give
$$\begin{bmatrix}
1 & 0 & 2 & 4 & 5 & 8 \\
0 & 2 & 5 & 2 & -1 & 3 \\
0 & -2 & -1 & 0 & 2 & 1
\end{bmatrix}
\xrightarrow{\text{rref}}
\begin{bmatrix}
1 & 0 & 0 & 3 & \frac{9}{2} & 6 \\
0 & 1 & 0 & -\frac{1}{4} & -\frac{9}{8} & -1 \\
0 & 0 & 1 & \frac{1}{2} & \frac{1}{4} & 1 
\end{bmatrix}
.$$
Use this to write both $(4,2,0)$ and $(5,-1,2)$ as a linear combination of the first three columns.
\end{enumerate}
 
\end{problem}

\begin{definition}
 The identity matrix $I$ is a square matrix so that if $A$ is a square matrix, then $IA=AI=A$. The identity matrix acts like the number 1 when performing matrix multiplication.

 If $A$ is a square matrix, then the inverse of $A$ is a matrix $A^{-1}$ where we have $AA^{-1}=A^{-1}A=I$, provided such a matrix exists.
\end{definition}



\begin{problem}
Let 
$A=
\begin{bmatrix}
\nvec{1\\3}&
\nvec{2\\4}
\end{bmatrix}
.$
We now develop an algorithm for computing the inverse $A^{-1}$.
If an inverse matrix exists, then we know it's the same size as $A$, so we could let $A^{-1}=\begin{bmatrix}\vec v_1 & \vec v_2\end{bmatrix}$ be the inverse matrix, where $\vec v_1$ and $\vec v_2$ are the columns of $A^{-1}$.  
\begin{enumerate}
 \item  We know that $A A^{-1} = \begin{bmatrix}\nvec{1\\0}&\nvec{0\\1}\end{bmatrix}.$ 
Explain why $A\vec v_1=\pvec{1\\0}$ and $A\vec v_2=\pvec{0\\1}$.
 \item Solve the matrix equations $A\vec v_1=\pvec{1\\0}$ and $A\vec v_2=\pvec{0\\1}$.  (This involves row reducing 
$
\begin{bmatrix}[cc|c]
\nvec{1\\3}&
\nvec{2\\4}&
\nvec{1\\0}
\end{bmatrix}
$
and 
$
\begin{bmatrix}[cc|c]
\nvec{1\\3}&
\nvec{2\\4}&
\nvec{0\\1}
\end{bmatrix}
$).
 \item What is the reduced row echelon form of
$
\begin{bmatrix}[cc|cc]
\nvec{1\\3}&
\nvec{2\\4}&
\nvec{1\\0}&
\nvec{0\\1}
\end{bmatrix}
$.  How is this related to your previous work.
 \item State the inverse of $A$. 
\end{enumerate}

\end{problem}

The previous problem showed you how to obtain a matrix $B$ so that $AB=I$. You just had to row reduce that matrix $\begin{bmatrix}[c|c]A&I\end{bmatrix}$ to the matrix $\begin{bmatrix}[c|c]I&A^{-1}\end{bmatrix}$.  The inverse shows up instantly after row reduction.


\begin{problem}
 Use the algorithm described immediately before this problem to compute the inverse of 
$$A=\begin{bmatrix}
 3 & 1 & -11 \\
 0 & -1 & 1 \\
 1 & 0 & -4
\end{bmatrix}.$$
Check your row reduction with technology.  

Then use your work to write each of the vectors $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$ as a linear combination of the columns of $A$.  
\end{problem}



%\end{document}
\section{Prep for Monday May 6}

%Find the inverse, and use it to solve a system.
\begin{problem}
Start by writing the system of equations 
$$\left\{
\begin{array}{rl}
 -2x_1+ 5x_3 &=-2\\
 -x_1+ 3x_3 &=1\\
 4x_1 +x_2  -x_3 &=3
\end{array}
\right.$$ as a matrix product $A\vec x =\vec b$.  (What are $A$, $\vec x$ and $\vec b$?)  
\begin{enumerate}
\item 
\marginpar{You should use technology to rapidly compute the inverse and row reduce the augmented system.  Show by hand any matrix computations you do on  part 3. }%
Use software to find the inverse of the matrix $A$ (state the matrix you row reduced, and the rref of the matrix). 
\item Use software to row reduce the augmented matrix $\begin{bmatrix}[c|c]A&\vec b \ \end{bmatrix}$. State the rref.
\item To solve the problem $ax=b$ where $a$, $x$, and $b$ are numbers, we multiply both sides by $\frac{1}{a}$ to obtain $\frac{1}{a}ax=\frac{1}{a}b$, or because $\frac{1}{a}a=1$, we simplify to get $x=\frac{1}{a}b$. How can you use this idea to solve the matrix problem $A\vec x = \vec b$?  Show how to obtain the solution to this system by using the matrix inverse. 
\end{enumerate}
\end{problem}

%Solve a general inverse problem (introduce the determinant)
\begin{problem}
Let $A=\begin{bmatrix}a&b\\c&d\end{bmatrix}$. Use Gauss-Jordan elimination to show that the inverse of $A$ is 
$$A^{-1}=\frac{1}{ad-bc}\begin{bmatrix}d&-b\\-c&a\end{bmatrix}.$$
Are there any conditions under which a matrix would not have an inverse?  What are they, and why? Is there a number you could check to determine if there is an inverse of a matrix?
\note{This problem needs way more scaffolding.  The students struggled with this quite a bit. They don't know how to row reduce something with variables.  They need this, but need more scaffolding.  See later down for another attempt.}
\end{problem}

In computing the inverse of a 2 by 2 matrix, the number $ad-bc$ appears in the denominator. We call this number the determinant. 
\marginpar{Take a guess as to why we call this number the determinant.  What does it help determine?}% 
If I asked you to compute the inverse of a 3 by 3 matrix, you would again see a number appear in the denominator.  We call that number the determinant. This holds true in all dimensions.

\begin{problem*}[Optional]
  Let $A=\begin{bmatrix}a&b&c\\d&e&f\\g&h&i\end{bmatrix}$. Use Gauss-Jordan elimination to find the inverse of $A$, and show that the common denominator is $a(ei-hf)-b(di-gf)+c(dh-ge)$. 
\end{problem*}


\begin{definition}[Determinants of 2 by 2 and 3 by 3 matrices]\label{determinat of 2 by 2 and 3 by 3}
\marginpar{In Sage, we've been using A.rref() to get the reduced row echelon form of $A$. You can type A.determinant() to get the determinant. Similarly, A.inverse() will get you the inverse. }
 The determinant of a {$2\times 2$} and {$3\times 3$} matrix are the numbers 
\begin{align*}
\det\begin{bmatrix}a&b\\c&d\end{bmatrix} &=\begin{vmatrix}a&b\\c&d\end{vmatrix} = ad-bc\\
\begin{vmatrix}a&b&c\\d&e&f\\g&h&i\end{vmatrix} &= a\det\begin{vmatrix}e&f\\h&i\end{vmatrix} -b\det\begin{vmatrix}d&f\\g&i\end{vmatrix} +c\det\begin{vmatrix}d&e\\g&h\end{vmatrix}\\
&=a(ei-hf)-b(di-gf)+c(dh-ge)
\end{align*}
\marginpar{This approach generalizes to give the determinant of any square matrix.  We'll only have a need for 2 by 2 and 3 by 3 determinants. Ask in class if you'd like more. }% 
We use vertical bars next to a matrix to state we want the determinant. Notice the negative sign on the middle term of the {$3 \times 3$} determinant. 
Also, notice that we can compute three determinants of 2 by 2 matrices in order to find the determinant of a 3 by 3. 
\end{definition}

%\end{document}
%Determinants and area (a couple examples)
\begin{problem}Do each of the following:
\begin{enumerate}
\item Compute the determinant of 
$
\begin{bmatrix}
 \nvec{2\\0}&\nvec{0\\3}
\end{bmatrix}
$ 
and state the area of the parallelogram whose vertices are $(0,0)$, $(2,0)$, $(0,3)$, and $(2,3)$. 
 \item Compute the determinants of
$
\begin{bmatrix}
 \nvec{2\\0}&\nvec{1\\3}
\end{bmatrix}
$ 
and
$
\begin{bmatrix}
 \nvec{1\\3}&\nvec{2\\0}
\end{bmatrix}
$.  
Then draw the parallelogram whose edges are the vectors $\pvec{2\\0}$ and $\pvec{1\\3}$, so it has vertices at (0,0), (2,0), (1,3), and (3,3) Compute the area of this parallelogram. 
 \item Compute the determinant of
$
\begin{bmatrix}
 \nvec{-1\\2}&\nvec{2\\1}
\end{bmatrix}
$. 
Then show that the columns in this matrix meet at a 90$^\circ$ angle (remember the dot product) which means that $\pvec{-1\\2}$ and $\pvec{2\\1}$  are the edges of a rectangle. Find the area of this rectangle by computing lengths of edges. 
 \item Compute the determinant of 
$
\begin{bmatrix}
 \nvec{3\\2}&\nvec{4\\-1}
\end{bmatrix}
$.
Guess the area of the parallelogram whose edges are the vectors $\pvec{3\\2}$ and $\pvec{4\\-1}$. Then use your guess to determine the area of the triangle connecting $(0,0)$, $(3,2)$, and $(4,-1)$.
\end{enumerate}

%Give them upper triangular and lower triangular examples where I ask them for area and the determinant.  Then give them a non nice example example.  How would they obtain the volume of 
%End by giving them a 3D determinant.  Have them compute it (and guess the volume of the box). 
\note{In class have them do this. Give them a box in 3D, a slided over box, and then some crazy parallelogram.  Ask them to give the determinant of each, and make a guess as to the area.

This problem would go much better if I asked them to compute all the determinants, and had the parallelograms drawn underneath each matrix and asked them to then compute the area of each parallelogram.  A right angle on one could be really nice.
} 
\end{problem}


%Find an inverse, but you can't. Connect it to learn dependence of columns and the determinant.
\begin{problem}

Consider the matrices 
$$
A=
\begin{bmatrix}
1 & 0 & 2  \\
1 & 1 & 1  \\
2 & 3 & 1 
\end{bmatrix}
\quad\quad\text{ and }\quad\quad
B=
\begin{bmatrix}
1 & 0 &  -2 \\
1 & 1 &  1 \\
2 & 3 &  0
\end{bmatrix}.$$
\marginpar{You can use Sage to check all your work. First store the matrices as A and B. Then use A.inverse(), B.inverse(), A.determinant(), and B.determinant() to check.}%
These matrices are related to the rocket booster problem (Problem \ref{rocket booster problem}).
\begin{enumerate}
 \item Row reduce $[A|I]$ and $[B|I]$.  Which matrix doesn't have an inverse? Why?
 \item Compute the determinants of $A$ and $B$. (See Definition \ref{determinat of 2 by 2 and 3 by 3}.) 
 \item 
\marginpar{You basically already answered this in Problem \ref{rocket booster problem}. }%
Are the columns of $A$ linearly independent or linearly dependent?  
 
Are the columns of $B$ linearly independent or linearly dependent?  

 \item 
\marginpar{This question is almost identical to the previous. What does it mean to be linearly independent?  

Recall that there are three possible options for a linear system. It can have one solution, infinitely many solutions, or no solution.}%
How many solutions does 
$x\pvec{1\\0\\2}+
y\pvec{0\\1\\3}+
z\pvec{3\\-2\\0}=
\pvec{0\\0\\0}
$ have?

How many solutions does 
$x\pvec{1\\0\\2}+
y\pvec{0\\1\\3}+
z\pvec{3\\-2\\1}=
\pvec{0\\0\\0}
$ have?


\item Make some conjectures about the relationships you see above. 

\end{enumerate}


% Find the inverse of  matrix.  What can you say about the columns of the matrix.  What is the determinant of the matrix. Why?  This should be a quick 3 by 3 example.  

% Make a guess as to the connection between when a matrix has an inverse and the linear dependence of the columns. Go back to the rocket example for a wrap around. 
\end{problem}




%\end{document}
\section{Prep for Tuesday May 7}

\begin{hw*}Do the following:
\begin{enumerate}
 \item 
 Complete Problem 2.77 on page 102 in Schaum's. 

Only row reduce one of the systems by hand.  Use a computer (or calculator) to row reduce the others. Make sure you can identify which has a unique solution, which has no solution, and which has infinitely many solutions (in which case you should give your answer by writing each variable in terms of a free variable).

\item  Complete Problem 3.78 on page 145 in Schaum's. Only find the inverse of $B$. Do the row reduction by hand. 
\end{enumerate}
\end{hw*}


\begin{problem}
Let $A=\begin{bmatrix}a&b\\c&d\end{bmatrix}$. Use Gauss-Jordan elimination on $[A | I]$ to show that the inverse of $A$ is 
$$A^{-1}=\frac{1}{ad-bc}\begin{bmatrix}d&-b\\-c&a\end{bmatrix}.$$
[Hint: Try multiplying the top row by $c$ and the bottom row by $a$.  Then you can subtract the top row from the bottom.  At this point, you might need to multiply the top row by $ad-bc$ and the bottom row by something else, so that they are the same and you can substract row 2 from row 1.  Then divide both rows by whatever is needed to get a 1 in the right spot.]

Are there any conditions under which a matrix would not have an inverse?  What are they, and why? Is there a number you could check to determine if there is an inverse of a matrix?
\end{problem}


%Encryption using matrices (and inverses to decode things).
\begin{problem}
Consider the matrix 
$A =
\begin{bmatrix}
 2&1&-1\\
 5&2&-3\\
 0&2&1
\end{bmatrix}
$.  
Joe decides to send a message to Sam by encrypting the message with the matrix $A$. He first takes his message and converts it to numbers by replacing A with 1, B with 2, C with 3, and so on till replacing Z with 26.  He uses a 0 for spaces.  After replacing the letters with numbers, he breaks the message up into chunks of 3 letters.  He then multiplies each chunk of 3 by the matrix $A$, resulting in a coded message. For example, to send the message ``good job ben'' he firsts converts the letters to the numbers and places them in a large matrix $M$ (top to bottom, left to right) 
$$
\left[
\begin{bmatrix}g\\o\\o\end{bmatrix}, \begin{bmatrix}d\\ \ \\ j\end{bmatrix},\begin{bmatrix}o\\b\\\  \end{bmatrix},\begin{bmatrix}b\\e\\n\end{bmatrix}\right] 
\rightarrow
\left[\begin{bmatrix}7\\15\\15\end{bmatrix}, \begin{bmatrix}4\\0\\10\end{bmatrix},\begin{bmatrix}15\\2\\0\end{bmatrix},\begin{bmatrix}2\\5\\14\end{bmatrix}\right] 
= M=
\begin{bmatrix}
7 & 4 & 15 & 2 \\
15 & 0 & 2 & 5 \\
15 & 10 & 0 & 14  
\end{bmatrix}
.$$
To encode the matrix, he computes 
$$AM = 
\begin{bmatrix}
14 & -2 & 32 & -5 \\
20 & -10 & 79 & -22 \\
45 & 10 & 4 & 24
\end{bmatrix}.$$
and then sends the numbers 
$[
[ 14,  20,  45],
[ -2, -10,  10],
[ 32,  79,   4],
[ -5, -22,  24]]
$ to Sam. Sam uses the inverse of $A$ to decode the message. 
\begin{enumerate}
 \item Find the inverse of $A$. 
 \item Use $A^{-1}$ to decode $[
[ 14,  20,  45],
[ -2, -10,  10],
[ 32,  79,   4],
[ -5, -22,  24]]$ and show the message is ``good job ben''.
 \item Decode the message $[[39, 89, 22],[20, 48,  4],[39, 88, 33]]$.
\end{enumerate}


\end{problem}





%Vector field push in/out (Eigenvalues problem introduction)
\begin{problem}
The following parts ask you to look for points in a vector field where the vector field pushes either straight outwards from the origin, or pulls straight towards the origin.
\begin{enumerate}
\item
Consider the vector field $\vec F(x,y) = \bvec{3&2\\0&2}\bvec{x\\y} = \bvec{3x+2y\\2y}$. 
For two of the input vectors $(2,2)$, $(2,1)$, $(2,0)$, $(2,-1)$, $(2,-2)$, the output $F(x,y)$ is a linear combination of the input $(x,y)$. For example, if $(x,y)=(-4,2)$, then we compute $\vec F(-4,2) = (-8, 4)$ and we see that $(-8,4) = 2(-4,2)$.  The vector field doubles the input $(-4,2)$. Find the two vectors from the list above, and write the output $F(x,y)$ as the vector $(x,y)$ times a scalar. For each of these two directions, does the field pull straight in, or does it push straight out. 
 \item Suppose you knew that there was a direction in which the vector field 
$\vec F(x,y) = \bvec{2&5\\4&1}\bvec{x\\y} = \bvec{2x+5y\\4x+y}$ causes a radial push outwards of 6 units. This would mean there exists $(x,y)\neq(0,0)$ such that 
$$\bvec{2&5\\4&1}\bvec{x\\y} = 6\bvec{x\\y}.$$
Find a vector $(x,y)$ that satisfies this equation. How could you get all vectors that satisfy this relationship?

[Hint: Write the matrix equation as a system of equations.  Then subtract  $6\bvec{x\\y}$ from both sides, combine terms to get a new matrix to row reduce, and then row reduce the matrix. You should find there are infinitely many correct answers.] 

\end{enumerate}


\end{problem}









%Eigenvalues/Eigenvectors
\begin{problem}
Consider the matrix 
$A=\bvec{3&4\\2&1}$.  This matrix gives us the vector field $\vec F(x,y) = A\bvec{x\\y}$. We would like to find the directions in which the vector field either pulls a point $(x,y)$ directly towards the origin, or pushes the point $(x,y)$ directly away from the origin.
\begin{enumerate}
 \item Explain why we seek a solution to $$ A\bvec{x\\y} = c\bvec{x\\y}$$ where $c$ is some constant. 
 \item Explain why $(x,y)=(0,0)$ is always a solution to the above equation.  We call this the trivial solution and will ignore it from now on.
 \item Subtract $c\bvec{x\\y}$ from both sides above.  Show that to find $(x,y)$ we need to row reduce the matrix $\bvec{[cc|c]3-c&4&0\\2&1-c&0}$. Then use elimination to eliminate the 2 in the lower left of the matrix. [Hint: Take row 2 and multiply it by $(3-c)$, and then subtract 2 times row 1 from row 2.]
 \item If you want to have more than one solution to this system of equations, what must occur at this stage of row reduction?  You should have an equation involving $c$ where something equals zero.  What is this equation you must solve? Solve this equation for $c$.  These are the scalars for which you can find a vector that either pushes directly out or pulls directly in.
\end{enumerate}

\end{problem}

%NO.  Needs to change.  Determinant of a 3 by 3 (only by solving the general inverse problem)
%\begin{problem}
% Consider the matrix $A$ (have $A-\lambda I$). If I want the columns of $A$ to be linearly dependent, what should $\lambda$ equal?  If I want $A\vec x = \lambda \vec x$, then what must $\lambda$ equal?
%\end{problem}

\note{in class I'm going to give them a problem that asks them to find the coefficient needed in a matrix to make sure that you have a specific eigenvalue, if I can come up with one.}


%\end{document}
\section{Prep for Thursday May 9}




\begin{hw*}
Complete the following:
\begin{enumerate}
 \item 
%row reduction with variables. 
Schaum's 2.92 (page 103).
\item
%Eigenvalue/Eigenvector
Schaum's 11.9a (page 413). They give the complete solution. Try to complete it without reading the solution. The vocabulary in Schaum's is slightly outdated.  They use $\Delta(t) = t^2-\text{tr}(A)t+|A|$. We use $|A-\lambda I|$.
\end{enumerate}


\end{hw*}


%Vector field push in/out (Eigenvalues problem introduction)
\begin{problem}
The following parts ask you to look for points in a vector field where the vector field pushes either straight outwards from the origin, or pulls straight towards the origin.
\begin{enumerate}
\item
Consider the vector field $\vec F(x,y) = \bvec{3&2\\0&2}\bvec{x\\y} = \bvec{3x+2y\\2y}$. 
For two of the input vectors $(2,2)$, $(2,1)$, $(2,0)$, $(2,-1)$, $(2,-2)$, the output $F(x,y)$ is a linear combination of the input $(x,y)$. For example, if $(x,y)=(-4,2)$, then we compute $\vec F(-4,2) = (-8, 4)$ and we see that $(-8,4) = 2(-4,2)$.  The vector field doubles the input $(-4,2)$. Find the two vectors from the list above, and write the output $F(x,y)$ as the vector $(x,y)$ times a scalar. For each of these two directions, does the field pull straight in, or does it push straight out. 
 \item Suppose you knew that there was a direction in which the vector field 
$\vec F(x,y) = \bvec{2&5\\4&1}\bvec{x\\y} = \bvec{2x+5y\\4x+y}$ causes a radial push outwards of 6 units. This would mean there exists $(x,y)\neq(0,0)$ such that 
$$\bvec{2&5\\4&1}\bvec{x\\y} = 6\bvec{x\\y}.$$
Find a vector $(x,y)$ that satisfies this equation. How could you get all vectors that satisfy this relationship?

[Hint: Write the matrix equation as a system of equations.  Then subtract  $6\bvec{x\\y}$ from both sides, combine terms to get a new matrix to row reduce, and then row reduce the matrix. You should find there are infinitely many correct answers.] 

\end{enumerate}


\end{problem}









%Eigenvalues/Eigenvectors
\begin{problem}
Consider the matrix 
$A=\bvec{3&4\\2&1}$.  This matrix gives us the vector field $\vec F(x,y) = A\bvec{x\\y}$. We would like to find the directions in which the vector field either pulls a point $(x,y)$ directly towards the origin, or pushes the point $(x,y)$ directly away from the origin.
\begin{enumerate}
 \item Explain why we seek a solution to $$ A\bvec{x\\y} = c\bvec{x\\y}$$ where $c$ is some constant. 
 \item Explain why $(x,y)=(0,0)$ is always a solution to the above equation.  We call this the trivial solution and will ignore it from now on.
 \item Subtract $c\bvec{x\\y}$ from both sides above.  Show that to find $(x,y)$ we need to row reduce the matrix $\bvec{[cc|c]3-c&4&0\\2&1-c&0}$. Then use elimination to eliminate the 2 in the lower left of the matrix. [Hint: Take row 2 and multiply it by $(3-c)$, and then subtract 2 times row 1 from row 2.]
 \item If you want to have more than one solution to this system of equations, what must occur at this stage of row reduction?  You should have an equation involving $c$ where something equals zero.  What is this equation you must solve? Solve this equation for $c$.  These are the scalars for which you can find a vector that either pushes directly out or pulls directly in.
\end{enumerate}

\end{problem}



%Traffic flow application
\begin{problem}
Consider the following traffic flow grid.
\begin{center}
\begin{tikzpicture}[scale=1.3]
\begin{scope}[very thick, every node/.style={sloped,allow upside down}]
%\draw[step=1cm,gray,very thin] (-2,-2) grid (2,2);
\draw (-2,1)-- node(A) {\midarrow} (-1,1); 
\draw (-1,2)-- node(B) {\midarrow} (-1,1);  
\draw (1,1)-- node(C) {\midarrow} (1,2) ;  
\draw (1,1)-- node(D) {\midarrow} (2,1) ;  
\draw (2,-1) -- node(E) {\midarrow} (1,-1) ;  
\draw (1,-2) -- node(F) {\midarrow} (1,-1) ;  
\draw (-1,-1) -- node(G) {\midarrow} (-1,-2) ;  
\draw (-1,-1) -- node(H) {\midarrow} (-2,-1) ;  
\draw (-1,1) -- node(I) {\midarrow} (1,1) ;  
\draw (-1,1) -- node(J) {\midarrow} (-1,-1) ;  
\draw (1,-1) -- node(K) {\midarrow} (1,1) ;  
\draw (1,-1) -- node(L) {\midarrow} (-1,-1) ;  
\end{scope}
\draw (-1,1)  ++(-.2,.2) node {$A$}; 
\draw (1,1)  ++(-.2,.2) node {$B$}; 
\draw (1,-1)  ++(-.2,.2) node {$C$}; 
\draw (-1,-1)  ++(-.2,.2) node {$D$}; 
\node[left of=A] {100};
\node[above of=B] {200};
\node[above of=C] {100};
\node[right of=D] {150};
\node[right of=E] {50};
\node[below of=F] {50};
\node[below of=G] {50};
\node[left of=H] {100};
\node[label=above:$x_1$] at (I){};
\node[label=right:$x_2$] at (K){};
\node[label=below:$x_3$] at (L){};
\node[label=left:$x_4$] at (J){};
\end{tikzpicture}
\end{center}
The numbers on the edges represent the number of vehicles that either enter or leave the system each hour.  The variables $x_1$, $x_2$, $x_3$, and $x_4$ represent the number of cars on each road. Assume that all streets are one-way streets where the arrows give the direction of traffic flow.
\begin{enumerate}
 \item How do you know there are 400 total cars entering this network of roads each hour? Are all these cars leaving?
 \item The number of cars entering an intersection must match the number of cars leaving an intersection.  We can use this to build a system of equations to help us understand the unknown traffic flows $x_1, x_2,x_3, x_4$.  For example, every hour at node $A$ there are 300 cars entering the intersection and $x_1+x_4$ cars leaving the intersection. This gives us an equation $x_1+x_4=300$. Continue in this fashion to obtain an equation at each intersection point. You should have a system of 4 equations with 4 unknowns.
 \item Use Gauss-Jordan elimination to solve the system. You should obtain infinitely many solutions. Write your solution in terms of the free variable(s).
 \item What's the minimum number of cars that can be on road $AD$ each hour? In this scenario, what are the traffic flow rates on the other streets? 
 \item What's the minimum number of cars that can be on road $AB$ each hour? In this scenario, what are the traffic flow rates on the other streets?
\end{enumerate}
\end{problem}




%NOPE.......Matrix Decomposition... Diagonalize?
%Linear Independence problem.  Make sure it illustrates that it is NOT the row of zeros at the bottom that determines anything, rather it's the nonpivot column.   Then ask them to generalize and state what they see. If its  a square matrix, then it is the row of zeros.....
%Maybe something like, ``suppose you reduce a 7 by 5 matrix, and end up with 2 rows of zeros accross the bottom.  What can you say about them...''  Then have  something similar with a 5 by 7, or a 7 by 7, or a 5 by 5.  Under what conditions will the rows of zeros tell you anything about linear dependence.  Is it possible to row reduce a 7 by 5 and have 1 row of zeros.... :)  Nope.  Perhaps this is exactly what they need.  
\begin{problem}
For each collection of vectors, determine if they are linearly independent or linearly dependent.  If they are linearly dependent, write one of the vectors as a linear combination of the others. You do not need to row reduce matrices by hand, rather on each problem first show the matrix you would row reduce to answer the question, and then give the reduced row echelon form (use technology).
\begin{enumerate}
 \item $(1,0,0)$, $(0,1,1)$, $(2,3,2)$, and $(0,1,-1)$ 
 \item $(1,0,2,0)$, $(0,1,3,1)$, and $(0,1,2,-1)$
 \item $(1,1,2,-1)$, $(-3,1,4,1)$, and $(-1,1,3,0)$
 \item Suppose you have 5 vectors that are each 7 tall. Row reducing the 7 by 5 matrix obtained from these vectors results in a matrix that has 3 rows of zeros at the bottom.  Why are the vectors linearly dependent?

 How many rows of zeros would be at the bottom if the vectors are linearly independent. 
\end{enumerate}
[Hint: For all parts, think about the number of pivot columns.]
\end{problem}





\section{Prep for Friday May 10}
%Eigenvalues/Eigenvectors (Vector Field)
%This problem again needs to get at the heart of linear algebra, without just introducing something random.
\begin{hw*}
\begin{enumerate}
\item 
Complete 11.58a (page 438).
 \item Complete 2.80 (page 102).  Do all row reductions with technology.  The point here is to just make sure you can recognize when there are infinitely many solutions, and then also express the solutions in terms of the free variables.
\end{enumerate}
\end{hw*}


\begin{problem}
 Consider the matrix $A=\bvec{-2&1\\3&4}$. From a plot of the vector field associated with $A$, we know that there is a direction in which the field pushes a point $(x,y)$ straight out, and direction in which the field pulls straight in.  
\marginpar{\includegraphics[width=1.75in,height=1.75in]{241-image1}}
We would like to find the directions $(x,y)$ in which this occurs. We need $A\bvec{x\\y}=c\bvec{x\\y}$ for some constant $c$ and nonzero vector $(x,y)$. For this problem, do all row reductions by hand.
\begin{enumerate}
 \item By row reducing an appropriate matrix, show that the only solution to $A\bvec{x\\y}=3\bvec{x\\y}$ is $(x,y)=(0,0)$. 
 \item By row reducing an appropriate matrix, show that the only solution to $A\bvec{x\\y}=4\bvec{x\\y}$ is $(x,y)=(0,0)$. 
 \item We want to solve $A\bvec{x\\y}=c\bvec{x\\y}$ where $(x,y)\neq (0,0)$. Row reduce an appropriate matrix and explain why we must have $c^2-2c-11=0$. Solve for $c$.
 \item Pick one of your values of $c$ and then state a nonzero vector $(x,y)$ such that $A\bvec{x\\y}=c\bvec{x\\y}$. Your vector will have irrational numbers in it. 
\end{enumerate}

\end{problem}

Generally people use the Greek letter $\lambda$ (read lamb-da) instead of $c$ when talking about the scalars above.  This scalar is called an eigenvalue of the matrix.  The nonzero vectors $(x,y)$ for which $A(x,y)=\lambda(x,y)$ are called eigenvectors.  The next problem has you find the eigenvalues and eigenvectors.

%Powers of a matrix (Why would someone care about that?)
%Google page rank instead?
%Give them a matrix that has already been orthogonalized.  Ask them to compute the inverse.  Then ask them to tell me WHY it works. This gets at an orthogonal basis really fast. It reviews angles and lengths.  Maybe have them give me two inverses.  Let the computer do the inverting, and then just have them interpret.  Have them compute A^T A.  What would it take for A^T A to equal I. Have them give conditions.  Then maybe give them a half of a 2 by 2 matrix, and then have them fill in the other half. 
%\begin{problem}
% This will be up soon.
%\end{problem}

\begin{problem}
 Consider the matrix $A=\bvec{5&6\\3&-2}$. 
\begin{enumerate}
 \item Show that the eigenvalues are $\lambda = 7$ and $\lambda = -4$. (Use determinants.)
 \item If we let $\lambda = 7$, find a nonzero vector $\vec x = (x,y)$ such that $A\vec x = 7\vec x$.  
 \item If we let $\lambda = -4$, find a nonzero vector $\vec x = (x,y)$ such that $A\vec x = -4\vec x$.  
 \item If we let $\lambda = 6$, then what is the solution to $\vec x = (x,y)$ such that $A\vec x = 6\vec x$. [Hint: this one can be answered without doing any row reduction.] 
\end{enumerate}

\end{problem}






\begin{problem}
Consider the following traffic flow grid.
\begin{center}
\begin{tikzpicture}[scale=.8]
\begin{scope}[very thick, every node/.style={sloped,allow upside down}]
%\draw[step=1cm,gray,very thin] (-4,-4) grid (4,4);
\draw (-2,1)-- node(A) {\midarrow} (-3,1); 
\draw (-1,3)-- node(B) {\midarrow} (-1,2);  
\draw (1,2)-- node(C) {\midarrow} (1,3) ;  
\draw (3,1)-- node(D) {\midarrow} (2,1) ;  
\draw (2,-1) -- node(E) {\midarrow} (3,-1) ;  
\draw (1,-3) -- node(F) {\midarrow} (1,-2) ;  
\draw (-1,-2) -- node(G) {\midarrow} (-1,-3) ;  
\draw (-3,-1) -- node(H) {\midarrow} (-2,-1) ;  
\draw (2,1) -- node(I) {\midarrow} (1,2)  
   -- node(J) {\midarrow} (-1,2)  
   -- node(K) {\midarrow} (-2,1)  
   -- node(L) {\midarrow} (-2,-1)  
   -- node(M) {\midarrow} (-1,-2)  
   -- node(N) {\midarrow} (1,-2)  
   -- node(O) {\midarrow} (2,-1)  
   -- node(P) {\midarrow} (2,1);  

\end{scope}
%\draw (-1,1)  ++(-.2,.2) node {$A$}; 
%\draw (1,1)  ++(-.2,.2) node {$B$}; 
%\draw (1,-1)  ++(-.2,.2) node {$C$}; 
%\draw (-1,-1)  ++(-.2,.2) node {$D$}; 
\node[left of=A] {130};
\node[above of=B] {90};
\node[above of=C] {100};
\node[right of=D] {155};
\node[right of=E] {120};
\node[below of=F] {75};
\node[below of=G] {80};
\node[left of=H] {110};
\node[label=right:$x_1$] at (I){};
\node[label=above:$x_2$] at (J){};
\node[label=left:$x_3$] at (K){};
\node[label=left:$x_4$] at (L){};
\node[label=left:$x_5$] at (M){};
\node[label=below:$x_6$] at (N){};
\node[label=right:$x_7$] at (O){};
\node[label=right:$x_8$] at (P){};

\end{tikzpicture}
\end{center}
The numbers on the edges represent the number of vehicles that either enter or leave the system each hour.  The variables $x_1$, $x_2$, $x_3$, and $x_4$ represent the number of cars on each road. Assume that all streets are one-way streets where the arrows give the direction of traffic flow.
\begin{enumerate}
 \item Set up a system of 8 equations that describe the flow of traffic along the roads.
 \item Solve this system and write your solution in terms of the free variable(s).
 \item What is the minimum flow along $x_1$?  How about maximum flow? Give your answer as $?\leq x_1\leq ?$.
\end{enumerate}
\end{problem}






%Linear recurrence.Nope
\begin{problem}[Number of operations]
Recall that there are three types of row operations, namely (1) swap rows, (2) multiply a row by a nonzero constant, and (3) add a multiple of a row to another row.  

When you row reduce the matrix $\bvec{a&b&c\\d&e&f}$ using Gauss-Jordan elimination (or any $2$ by $n$ matrix), what's the largest number of row operations you should ever need to perform?  Assume that at each stage you decide to swap two rows to get a nice nonzero number in the pivot spot, and then you multiply that row by a nonzero number to make the pivot a 1. With a 2 by $n$ matrix, we would swap rows 1 and 2, multiply row 1 by a nonzero number and then add a multiple of row 1 to row 2 to eliminate the 2,1 entry. We then would multiply row 2 by a nonzero number to get a 1 in the pivot spot.  Then we need one more operation to eliminate the number of the pivot in column 2. This is a total of 5 operations. 

\marginpar{
This question is extremely important to computer programmers, as it tells us how long it would take to row reduce a million by million matrix, something that happens all the time since the advent of computers.
} 
Here's your challenge:  How many row operations are needed to fully reduce a 3 by $n$ matrix.  What about a 4 by $n$ matrix, a 5 by $n$, and a 6 by $n$ matrix? Your answer should be an explanation of how you got your answer. The key here is to explain your logic (not get a number). Then, see if you can come up with how many row operations it will take to fully reduce an  $m$ by $n$ matrix.  Make a conjecture (you may or may not be right, it's OK). 

[Hint: For the 3 by 3, there are 2 swaps, 3 multiplications to obtain a 1 in the pivot spot, and then we add a multiple of a row to another 3 times in the forward elimination and 3 times in the backward elimination (why?). This gives a total of 11 row operations.]
\end{problem}


%Encryption (but this time done from the other side.  Compare to the previous.  Which do they prefer....  Jonas does the encryption from the right, Sam from the left. Alternate, they both have different encryption matrices.  Joey is not sure who sent the message.  Who did? Who has seen it?  This sounds like a great matrix multiplication issues. 
\section{Prep for Monday May 13}

\begin{hw*}
 Make sure you finish up all the extra practice problems from the days before. If you were completing them as we go (12-20 minutes each day), then you should already have this done.

 Bring your work to class, and make sure you check your answers on each problem before coming. 
\end{hw*}

\begin{problem}
We'll be reviewing for the exam.  Your assignment consists of reviewing the 44 problems, and making a list of the ideas that each problem teaches.  Then come to class with 6-10 examples that you feel illustrate the key concepts from the entire chapter. 
\begin{enumerate}
 \item \marginpar{I would suggest that you type this list in Excel.  Just put one idea on each row. If you use software to type out this list, it will be easier for you to organize your ideas and look for common patterns.}%
For each of the 44 problem we have done, go back and look at the problem.  Write a sentence or two that describes what outcomes (goals, objectives, ideas) the problem was aiming at.  Was the outcome that you would be able to ``Find the angle between vectors,'' or ``Row reduce a matrix,'' or ``Understand what a linear combination is in the context of something real, like rows of corn and a road, or rockets in space,'' or ``Determine when vectors are independent or dependent,'' etc. For each of the problems, jot down what you see as the outcome to the problem.
 \item 
\marginpar{If you typed your 44 outcomes in excel, you can now sort the ideas by attaching numbers to ideas.  Then you can sort the material so that common outcomes are together, and then combine those common outcomes into more general, bigger picture,  outcomes.}%
After looking at all 44 problems, try to look for common goals.  Try to reduce this list of 44 objectives to a smaller list of maybe 20.  Then reduce it to a smaller list of maybe 6-10.
 \item For each of your outcomes on your small list of 6-10, write a simpler review problem that reminds you of the computations needed to complete this type of problems.
 \item Only spend 2 hours on this assignment. Then come to class ready to share what you got as your objectives, and how you narrowed them down.  If you don't have enough time to finish making 6-10 short examples, but spend 2 hours, that's fine.  
\end{enumerate}

\end{problem}

On Monday, we'll start by sharing the few problems that we have not yet had time to share in class. Then we'll discuss the objectives you discovered as a class. Bring your list of 44 things, how you condensed it, and what your 6-10 main objectives are. Be ready to discuss these objectives with your peers. 

\section{Prep for Tuesday May 14}
We'll be continuing to review for the exam.  Based on our discussion in class on Monday, we'll agree (or agree to disagree) on some common objectives for the course. We'll then use those common objectives to create a plan for reviewing for the test.  Your assignment will be to create examples of questions that you think would be great exam questions to give to your future students.  We'll then share these questions with each other and tackle them in small groups. 

\chapter{Applications}
\section{Prep for Thursday May 16}





\begin{problem}
 Answer the following by row reducing an appropriate matrix. Just show us the matrix you needed to row reduce, and the rref. [Hint: Each point produces an equation.]
\begin{enumerate}
 \item Find the intercept $a_0$ and slope $a_1$ of a line $y = a_0+a_1 x$ that passes through the points $(1,2)$ and $(3,5)$. [We could have used $m$ and $b$, but I chose to use $a_0$ and $a_1$ so you can see how this generalizes quickly to all dimensions.]
 \item Find the coefficients $a_0$, $a_1$, and $a_2$ of a parabola $y = a_0+a_1 x^1+a_2x^2$ that passes through the points $(0, 1)$,  $(2, 3)$, and  $(−1, 4)$. [Hint: The second point produces the equation $3=a_0+a_1(2)+a_2(2)^2$.]
\end{enumerate}
\end{problem}



\begin{problem}
 Find the equation of a rational function of the form $y=\dfrac{ax+b}{x+c}$ that goes through the points $(4,1/3)$, $(6,3/4)$, and $(8,1)$. [Hint: if you multiply both sides by the denominator, then you'll have some linear equations in terms of $a$, $b$, and $c$ after you plug in the three points.]
\end{problem}




\begin{problem}
The following three vector fields have imaginary eigenvalues. Compute the eigenvalues for each, construct a vector field plot, and on the plot add several trajectories (the path followed by a particle that is dropped into this field).
\begin{enumerate}
 \item $\vec F = (-2y,x)$. 
 \item $\vec F = (-x+y, -x-y)$.
 \item $\vec F = (x-y, x)$ 
\end{enumerate}
Make a conjecture as to why one spirals in, one spirals out, and one just wraps around in ellipses. We'll address this conjecture in class.
\end{problem}



Chemical reaction stoichiometry is the study of balancing chemical equations. A chemical reaction will often transform reactants into by-products. The by products are generally different compounds, together with either an increase or decrease in heat. One key rule in stoichiometry is that a chemical process neither creates nor destroys matter, rather it only changes the way the matter is organized. For simple reactions (with no radioactive decay), this conservation law forces the number of atoms entering a reaction to be the same as the number leaving. The next problem asks you to use this conservation law to create a balanced chemical reaction equation. 
\begin{problem}
 The chemical compound hydrocarbon dodecane ($C_{12}H_{26}$) is used as a jet fuel surrogate (see Wikipedia for more info).  This compound reacts with oxygen $(O_2)$, and the chemical reaction produces carbon dioxide ($CO_2$), water ($H_2 O$), and heat.  Suppose we expose some dodecane to oxygen, and that a chemical reaction occurs in which the dodecane is completely converted to carbon dioxide and water.  
 Conservation requires that the number of atoms ($H$, $C$, and $O$) at the beginning of the chemical reaction must be the exact same as the number at the end. 
 We could write the chemical reaction in terms of molecules as
 $$x_1 C_{12}H_{26} +x_2 O_2 = x_3 CO_2+ x_4 H_2O\quad \text{or} \quad x_1 C_{12}H_{26} +x_2 O_2 - x_3 CO_2- x_4 H_2O=0, $$
 where $x_1$ molecules of dodecane and $x_2$ molecules of oxygen were converted to $x_3$ units of carbon dioxide and $x_4$ units of water.  
 If we look at each atom (carbon, hydrogen, and oxygen) individually, we obtain three equations to relate the variables $x_1, x_2, x_3, x_4$.  The carbon equation is simply
 $$x_1(12) + x_2(0) = x_3(1)+x_4(0) \quad \text{or}\quad x_1(12) + x_2(0) - x_3(1)-x_4(0)=0.$$  
 Your job follows:
\begin{enumerate}
 \item Write the other two conservation equations (for hydrogen and oxygen). 
 \item Solve the corresponding system of equations by row reduction.  As there are only 3 equations with 4 unknowns, you should obtain infinitely many solutions. Write each variable in terms of the free variable.  
 \item If about 10,000 molecules of water are present at the end of the reaction, about how many molecules of dodecane were burned? 
\end{enumerate}
\end{problem}





\section{Prep for Friday May 17}

\begin{hw*}
 See problem 11.57 on page 437. Find the eigenvalues for each matrix. Only find eigenvectors for one of the matrices.  That's the only extra practice for today.
\end{hw*}



\begin{problem}
 We would like to find a fourth degree polynomial $y=a_0+a_1x+a_2x^2+a_3x^3+a_4x^4$ that passes through the points $(1,0)$, $(-1,2)$, $(2,3)$, and $(-3,1)$.  Set up an augmented matrix, and row reduce it, to show that there are infinitely many such polynomials (write each variable in terms of the free variable).  If we want the leading coefficient $a_4$ to equal 1, then what are the other coefficients?  Please use software to obtain your answer. 
\end{problem}


The problem above had infinitely many solutions because we had fewer points that unknowns.  What happens when we have too many points (more than our number of unknowns)?  We'll come back to this problem.  It is directly related to finding the distance between a point and a line. 

\begin{problem}
There are three parts to this problem. In all cases, your job is to find the distance from a point to a line.
\begin{enumerate}
 \item Find the distance from the point $(-1,2)$ to the $x$-axis.
 \item Find the distance from the point $(-1,2)$ to the line through the origin that is parallel to the vector $(0,1)$
 \item Find the distance from the point $(-1,2)$ to the line through the origin that is parallel to the vector $(3,4)$.  [Hint: Draw the two vectors. You might want to find the angle between the two vectors, and then use some right triangle trigonometry.)
\end{enumerate}

\end{problem}




We need one more bit of vocabulary to help us in our study of linear algebra. One of our goals in the next few days is to learn linear regression. You've seen the following concept of a linear function in many settings, without knowing it. 
\begin{definition}[Linear Function]
 When the domain $D$ and range $R$ of a function involves quantities that can be added and multiplied by scalars, we say that the function $f:D\to R$ is linear, provided the following occurs:
\begin{enumerate}
 \item $f(x+y) = f(x)+f(y)$ and
 \item $f(cx)=cf(x)$, where $c$ is a scalar. 
\end{enumerate}
We'll often say that the function preserves addition and scalar multiplication.
\end{definition}
You have seen this concept many times in the past. If you have ever said, ``Just do each part separately (1.), and pull the constants out (2.),'' then you were working with a linear function.


\begin{problem}
 Make sure you read the definition of a linear function above. 
 Three of the following functions are linear functions.  One of them is not.  Which is which, and why?  You may assume that any variable you see below is a real number. 
 \begin{enumerate}
  \item $f(x)=ax$, where $a$ is a constant scalar.
  \item $f(a)=ax$, where $x$ is a constant scalar. 
  \item $f(x)=mx+b$, where $m$ and $b$ are constant scalars. 
  \item $f(m,b)=mx+b$, where $x$ is a constant scalar. [Note: from the definition above, the variable notation $f(x+y)$ means $f( (m,b)+(n,d))$ and also $f(cx)$ means $f(c(m,n))$. ]
 \end{enumerate}
[Hint: Try using a specific value for scalar so for part 3 you could use $f(x) = 2x+3$ and for part 4 you could use $f(m,b) = 2m+b$. Then show that $f(x+y)=f(x)+f(y)$, or that $f(a+b)=f(a)+f(b)$, or $f((m,b)+(n,d)) =f(m,b)+f(n,d)$.]
\end{problem}






We learned in chapter 1 how to use the determinant draw many conclusions about a matrix.  We need to practice finding the determinant on larger matrices. 
Recall that the determinant of a {$2\times 2$} and {$3\times 3$} matrix are the numbers 
\begin{align*}
\det\begin{bmatrix}a&b\\c&d\end{bmatrix} &=\begin{vmatrix}a&b\\c&d\end{vmatrix} = ad-bc\\
\begin{vmatrix}a&b&c\\d&e&f\\g&h&i\end{vmatrix} &= a\det\begin{vmatrix}e&f\\h&i\end{vmatrix} -b\det\begin{vmatrix}d&f\\g&i\end{vmatrix} +c\det\begin{vmatrix}d&e\\g&h\end{vmatrix}\\
&=a(ei-hf)-b(di-gf)+c(dh-ge)
\end{align*}
Notice the negative sign on the middle term of the {$3 \times 3$} determinant. 
Also, notice that we can compute three determinants of 2 by 2 matrices in order to find the determinant of a 3 by 3. We now extend this to give a way to compute determinants of any matrix.


\begin{definition}[Minors, Cofactors, and General determinants]\label{general determinants}
Let {$A$} be an $n$ by $n$ matrix. 
\begin{itemize}
 \item The minor {$M_{ij}$} of a matrix {$A$} is the determinant of the the matrix formed by removing row {$i$} and column {$j$} from {$A$}. 
 \item The cofactor $C_{ij}$ is the product of the minor $M_{ij}$ and $(-1)^{i+j}$, so we have $C_{ij} = (-1)^{i+j}M_{ij}$. So it's either the minor, or the opposite of the minor. 
 \item To compute the determinant, first pick a row or column.
We define the determinant to be $\sum_{k=1}^n a_{ik}C_{ik}$ (if we chose row $i$) or alternatively $\sum_{k=1}^n a_{kj}C_{kj}$ (if we chose column $j$).  
\item You can pick ANY row or ANY column you want, and then compute the determinant by multiplying each entry of that row or column by its cofactor, and then summing the results. 
\item 
\marginpar{
%\begin{wraptable}[7]{r}{0pt}
\small
\begin{tabular}{c}
$\begin{bmatrix}
+&-&+&\cdots\\
-&+&-&\cdots\\
+&-&+&\cdots\\
\vdots&\vdots&\vdots&\ddots
\end{bmatrix}$ 
\\
sign matrix
\end{tabular}%\end{wraptable}
}%
A sign matrix keeps track of the $(-1)^{j+k}$ term in the cofactor. All you have to do is determine if the first entry of your expansion has a plus or minus, and then alternate the sign as you expand.

\end{itemize}

\end{definition}




\begin{problem}
 Compute the determinant of the matrix
$
\begin{bmatrix}
 2 & 3 & -1 \\
 1 & 0 & 0 \\
 4 & 2 & 5
\end{bmatrix}
$
in 3 different ways. First, use a cofactor expansion using the first row (see the definition  above).  Then use a cofactor expansion using the 2nd row.  Then finally use a cofactor expansion using column 3.  Which of them was the quickest, and why?

Note:  A cofactor expansion along the 2nd column would be 
$$(-1)^{1+2}(3)\begin{vmatrix}1&0\\4&5\end{vmatrix}+(-1)^{2+2}(0)\begin{vmatrix}2&-1\\4&5\end{vmatrix}+(-1)^{3+2}(2)\begin{vmatrix}2&-1\\1&0\end{vmatrix}$$
\end{problem}





%\end{document}
\section{Prep for Monday May 20}
Today we spent time discussing making a lesson plan for teaching some concepts of linear algebra to our students. 

Here's the background.
\begin{itemize}
 \item You're teaching the advanced algebra class in 10th grade. The students have moved through the material quickly, and you have an extra week to teach them about vectors and matrices. You want to give them an opportunity to learn the content through inquiry. You would like your class to reach many of the goals stated by the Common Core (see the presentations folder online for the objective).
 \item You have 5 days of class to meet with your students, and 55 minutes with them each day.
 \item You want them to work on problems at home prior to coming to class, and then come to class ready to discuss what they have found. 
 \item You plan to have activities in class that build upon their preparation. Their preparation for class should help them succeed and contribute to the in class activity/discussion.
\end{itemize}
Your job is to put together a collection of problems that the students will be able to complete in a week's time.
\begin{enumerate}
 \item As a group, read through the common core objectives. 
 \item Decide which objectives you think you can reasonably reach in a week of time.
 \item Brainstorm some high level problems that would naturally lead a student to discovering the objectives you listed.
 \item Brainstorm some intermediate problems they'll need to tackle to get understand the higher level problems.  
 \item Divide the problems up into specific days. Then assign out who will write each problem.
 \item When you write each problem, write some instructor notes.  Explain why you think the problem will be interesting to the students. Explain what the problem should teach the students after they have complete it. 
\end{enumerate}




\section{Prep for Tuesday May 21}
\begin{hw*}
 Download the free text {\it Linear Algebra} available at
 \begin{itemize}
  \item \href{https://content.byui.edu/file/c2f91762-7a1e-4d0b-a1ae-8d5f5f548e17/1/341-Book.pdf}{https://content.byui.edu/file/c2f91762-7a1e-4d0b-a1ae-8d5f5f548e17/1/341-Book.pdf}.
 \end{itemize}
 On page 55, please complete problem 4f.  Use software to rapidly get your answer. The answer is on page 60.  
 
 Throughout the semester, we'll swap between this free online text and Schaum's Oultines for extra practice problems.
\end{hw*}

\begin{problem}
 Consider the matrix
$A=\begin{bmatrix}
2&1&-1\\1&2&0\\0&4&3 
\end{bmatrix}.$
 Compute the determinant of $A$.  Then create a matrix $B$ so that the $ij$th entry of $B$ is the cofactor $C_{ij}$ (remove row $i$ and column $j$, compute the determinant, and then times by an appropriate sign).  This will require that you compute nine 2 by 2 determinants.  Finally, compute the inverse of $A$ (feel free to use a computer on this part). Then make a conjecture about the connection between the determinant of $A$, this matrix $B$, and the inverse of $A$.  
 %We'll verify your conjecture is true on a 4 by 4 matrix in class. 
\end{problem}


%Choose a transformation so that the eigenvalues are simple (-5 and 4), but neither is 1 or negative 1, the determinant is negative, 
\begin{problem}
 Sally found the treasure in the corn field.  She's now looking for treasure in a swamp. There's a road through the swamp that runs parallel to the vector $\vec v=(3,4)$. Her current location is $(0,0)$ and the treasure (geocache) is located at the position $\vec b=(2,-4)$ (units are hundreds of yards). When Sally decides to leave the road, she'll have to wade through some swamp water. She would prefer to spend as little time in the swamp as possible. Her goal is to walk along the road until she reaches the point closest to the treasure, and then wade straight to the treasure.  This means she needs to find a scalar $c$ so that $c\vec v$ gets her as close to the treasure as possible. See the picture below. 
\begin{center}	
\begin{tikzpicture}[scale=1]
\draw[thin] (-3,-4) -- (3.3,4.4);
\draw [->,thick] (0,0) -- node [left=3pt]{$\vec v=(3,4)$}(3,4);
\draw [->,thick,red,dashed] (0,0) -- node [right=3pt]{$\vec b=(2,-4)$}(2,-4);
\draw [->,very thick,green] (0,0) -- node [left=3pt]{$c\vec v$}(-1.2,-1.6);
\draw [->,very thick,blue] (-1.2,-1.6) -- node [below=3pt]{$\vec n$}(2,-4);
\end{tikzpicture}
\quad 
\begin{tikzpicture}[scale=1]
\draw [->,thick] (0,0) -- node [left=3pt]{$\vec v$}(3,4);
\draw [->,thick] (0,0) -- node [right=3pt]{$\vec b=c\vec v+\vec n$}(2,-4);
\draw [->,thick] (0,0) -- node [left=3pt]{$c\vec v$}(-1.2,-1.6);
\draw [->,thick] (-1.2,-1.6) -- node [below=3pt]{$\vec n$}(2,-4);
\end{tikzpicture}
\end{center}
The vector $\vec n$ represents the path she must take through the swamp. Her goal is to find a scalar $c$ so that $\vec b=c\vec v+\vec n$ and $\vec n$ is as short as possible. 
\begin{enumerate}
 \item What is the angle between $\vec v$ and $\vec n$? Why does $\vec v\cdot \vec n=0$?
 \item Sally knows that the treasure is at $\vec b = c\vec v+\vec n$.  Since $\vec v\cdot \vec n = 0$, she decides to dot both sides of this equation, on the left, by the vector $\vec v$ to get $\vec v\cdot \vec b = \vec v\cdot (c\vec v+\vec n)$. Show that in general $$c = \dfrac{\vec v\cdot \vec b}{\vec v\cdot \vec v} = \dfrac{\vec v^T\vec b}{\vec v^T\vec v}.$$ Then show that with Sally's specific road vector $\vec v$ and treasure vector $\vec b$, the constant $c$ is $c=-2/5$. 
 \item We know that $c\vec v$ is as close to $\vec b$ as you can get along the road. Since $\vec b = c\vec v+n$ and we know $c\vec v$, solve for $\vec n$. Then find the distance Sally will have to travel in the swamp (what's the length of $\vec n$)? 
\end{enumerate}
 \end{problem}
 
The vector $c\vec v$ above is often called the orthogonal projection of $\vec b$ onto $\vec v$. The word orthogonal means that $\vec v\cdot \vec n=0$, i.e. that there is a 90 degree angle between $\vec v$ and $\vec n$. 
%The scalar $c$ is sometimes called a Fourier coefficient.    


\begin{problem}
 Now assume that Sally is an astronaut in space. She's moving through an asteroid field and knows there is safe passage if she follows the vector $\vec v = (1,-2,-3)$. She needs to get to the point $\vec b=(3,-6,-11)$. She already knows that if she follows $\vec v$ three times, she'll end up pretty close by arriving at $(3,-6,-12)$. However, she wants to follow $\vec v$ until she is as close to $\vec b$ as possible, as leaving the known safe path could be dangerous.  
\begin{enumerate}
 \item 
Determine the scalar $c$ so that $\vec v c$ is as close to $\vec b$ as possible. Your answer should be close to 3.  Use the formula from the previous problem.
  \item 
Let's swap to a different question. 
Suppose we would like to find an equation of a line $y=mx$ through the origin that passes through the three points  $(1,3)$, $(-2,-6)$, and $(-3,-11)$.
To pass through all three points we need to solve the system of equations $3=m(1)$, $-6=m(-2)$, and $-11=m(-3)$. 
Rewrite this system of equations as the vector equation (state $\vec v$ and $\vec b$) 
$$\vec v m = \vec b \quad\quad\quad\Rightarrow\quad\quad\quad \bvec{?\\?\\?}m = \bvec{?\\?\\?}.$$
Explain why there is no solution to this problem. 
  \item
What should we choose the slope $m$ to equal so that $\vec v m$ will be as close to $\vec b$ as possible? [Hint: Multiply both sides on the left by the matrix $\vec v^T$.]
 \end{enumerate}
\end{problem}


\begin{problem}\label{sally in city}
 After getting the treasure in the swamp, Sally moves on to find a treasure located in small town. She has a map of the town that shows the city blocks.  However, when she looks at a satellite image of the city it's slightly different than her map. Here are the two maps (the city map is on the left, the satellite on the right).
 \begin{center}
 \begin{tabular}{cc}
\begin{tikzpicture}
 \clip (0,0) circle (2.5cm);
 \draw[very thick] (0,0) circle (2.5cm);
 \foreach \x in {-3,-2,-1,0,1,2,3}
  \foreach \y in {-3,-2,-1,0,1,2,3}
   \draw[thick,blue] (\x,\y)--(\x+1,\y);
 \foreach \x in {-3,-2,-1,0,1,2,3}
  \foreach \y in {-3,-2,-1,0,1,2,3}
   \draw[thick,blue] (\x,\y)--(\x,\y+1);
 \fill (0,0) circle (.1cm);
 \end{tikzpicture}
&
 \begin{tikzpicture}[scale=.36]
 \clip (0,0) circle (7cm);
 \draw[very thick] (0,0) circle (7cm);
 \foreach \x in {-4,-3,-2,-1,0,1,2,3}
  \foreach \y in {-4,-3,-2,-1,0,1,2,3}
   \draw[thick,blue] (\x+2*\y,3*\x-\y)--(\x+1+2*\y,3*\x+3-\y);
 \foreach \x in {-4,-3,-2,-1,0,1,2,3}
  \foreach \y in {-4,-3,-2,-1,0,1,2,3}
   \draw[thick,blue] (\x+2*\y,3*\x-\y)--(\x+2*\y+2,3*\x-\y-1);  
 \fill (0,0) circle (.3cm);
%Eventually I would like to put the vectors in this problem. at nodes.  I don't know the syntax yet. 
%\draw node at (1,3) {$(0,0)$}
 \end{tikzpicture}
\\
City Map&Satellite View
 \end{tabular}
 \end{center}
 The city grid is not lined up with compass directions. When the city map tells her to go up one block, this really means her $(x,y)$ position should follow the vector $\vec v_1=(1,3)$. To go right 1 block, she follows the vector $\vec v_2=(2,-1)$. She has to learn to work with two different coordinate systems, namely the city coordinates (given in blocks) and the $(x,y)$ satellite coordinates (given in hundreds of yards). Assume that Sally is currently at the origin $(0,0)$. 
%She's currently standing at the point $A$ (which we'll consider the origin). Her GPS unit tells her that the treasure is located at the coordinates (). Our goal on this problem is to determine how she should follow the roads to get to the treasure.
\begin{enumerate}
 \item If Sally goes up 2 blocks, and right 3 blocks, what are here $(x,y)$ coordinates (in hundreds of yards)?
 \item If Sally moves up $c_1$ blocks and right $c_2$ blocks, then what are her $(x,y)$ coordinates. Write your answer as a linear combination of vectors, and then as a matrix product $A\bvec{c_1\\c_2}=\bvec{x\\y}$. You can check if you are correct by computing $A\bvec{1\\0}=\bvec{1\\3}$ and $A\bvec{0\\1}=\bvec{2\\-1}$. 
 \item If the treasure is located at the $(x,y)$ coordinates $(0,7)$, what directions would you give her in terms of blocks? If the treasure is located at $(1,-7.5)$, what directions would you give?
 \item What does the determinant of the matrix $A$ have to do with the maps?
\end{enumerate}

\end{problem}





\note{What to do in class?
\begin{enumerate}
 \item Find $c$ in $\vec v c=\vec b$.  use $(1,2)$ and $(3,5)$.  
 \item Find $m$ in $y=mx$ so that the line is equally close to both $(1,3)$ and $(2,5)$. 
 \item Find large determinant.
 \item If you need to get to (... how will you get there.   
\end{enumerate}

Note, they did not get through problem 2, so today we spent the day doing this prep problem together. Then I sent them to the boards to do #2 and #3. 
}



\section{Prep for Thursday May 23}

\begin{problem}
Jimmy is using a rocket suit to travel out in space. His rocket suit had 4 good boosters that allowed travel in any direction, with a backup booster in case one got damaged.  However, some tiny meteorites happened to pass by and take out two of his boosters, as well as his radio to call for help.  He's now only able to move in the directions $\vec v_1=(1,1,1)$ and $\vec v_2=(-1,1,2)$.  His space ship is sitting at $\vec b=(-1,4,7)$.
\begin{enumerate}
 \item 
 Show that Jimmy cannot arrive at his ship using his two working boosters.  In other words, show that we cannot write $\vec b$ as a linear combination of $\vec v_1$ and $\vec v_2$? Set up an appropriate matrix equation, row reduce the equation, and use your row reduction to give an answer. 
 \item 
 Jimmy has a one shot back up gun.  This gun will propel him towards the ship if he points the gun directly away from the ship and fires.  
 It's easy to miss aim, so he would like to get as close to the ship as possible before he fires the gun. 
 He needs to find $c_1$ and $c_2$ so that $\vec w = \vec v_1 c_1+\vec v_2 c_2$ gets him as close to the ship as possible. The picture below illustrates the general idea. The vectors $\vec v_1$ and $\vec v_2$ give Jimmy a plane of possible movements. 
\begin{center}	
\begin{tikzpicture}[scale=1]
\fill[lightgray] (0,0) -- (-2,2) -- (2,2) -- (4,0) -- (0,0);
\draw[thin] (-1,0) -- (4,0);
\draw[thin] (.5,-.5) -- (-2,2);
\draw [->,thick] (0,0) -- node [below=3pt]{$\vec v_1$}(3,0);
\draw [->,thick] (0,0) -- node [left=3pt]{$\vec v_2$}(-1,1);
\draw [->,thick] (0,0) -- node [left=3pt]{$\vec b$}(2,4) node[right=3pt]{The space ship is up here.};
\draw [->,thick] (0,0) -- node [right=3pt]{$\vec w = \vec v_1 c_1+\vec v_2 c_2$}(2,2) node[right=3pt]{Jimmy wants to get here.};
\draw [->,thick] (2,2) -- node [right=3pt]{$\vec n$}(2,4);

%\draw [->,thick] (-1.2,-1.6) -- node [below=3pt]{$\vec n$}(2,-4);
\end{tikzpicture}
\end{center}
 When Jimmy has arrived at the closest spot to the ship, he'll have the smallest $\vec n$ so that $$\vec v_1 c_1+\vec v_2 c_2+\vec n=\vec b\quad\quad\text{ or }\quad \quad \vec w+\vec n=\vec b.$$ Why must $\vec v_1^T\vec n=0$ and $\vec v_2^T\vec n=0$?  
 \item 
 Since there are two unknown constants $c_1$ and $c_2$, we need two equations.  Multiply both sides of the above equation on the left by $\vec v_1^T$. Why does $\vec n$ vanish from the equation? This gets us one equation.
 \item 
 To get a second equation, we multiply both sides by $\vec v_2^T$. You should now have two equations with two unknowns $c_1$ and $c_2$. Solve and show that $c_1 = 11/7$ and $c_2=37/14$.
% \item 
% Let $A =\bvec{\vec v_1&\vec v_2} = \bvec{1&-1\\1&2\\1&2}$. What does $A^TA$ and $A^T$ 
% You can organize all your work above into a single equation. Show that solving $A^TA\vec x = A^T\vec b$ for $\vec x$. 
\end{enumerate}

\end{problem}

The problem above asked you to find the point in a plane that was closest to a point not on the plane.  This is called the orthogonal projection of $\vec b$ onto the plane formed by the vectors $\vec v_1$ and $\vec v_2$.  If we let $A=\bvec{\vec v_1&\vec v_2}$, then the projection of $\vec b$ onto this plane is $w=\vec v_1c_2+\vec v_2c_2=A\bvec{c_1\\c_2}$. Our goal is to find $\bvec{c_1\\c_2}$ such that $\vec n=\vec b-A\bvec{c_1\\c_2}$ is as short as possible. The next problem shows that you can accomplish this by solving $A^TA\vec x=A^T\vec b$ for $\vec x$. We just take the problem $A\vec x=\vec b$ which has no solution, multiply both sides by $A^T$, and then solve.  


\begin{problem}
 Suppose we would like to find an equation of a line $y=a_0+a_1x$ that passes through the three points 
 $(-1,-1)$, $(1,4)$ and $(2,7)$. If such a line does not exist, we'd like to find a line that passes close to these three points. 
 \begin{enumerate}
  \item The three points give us three equations that involve the unknown constants $a_0$ and $a_1$. Show that we can write these equations in the matrix form $A\vec x = \vec b$ and vector form $\vec v_1a_0+\vec v_2a_1 = \vec b$ 
  $$\bvec{1&-1\\1&1\\1&2}\bvec{a_0\\a_1}=\bvec{-1\\4\\7}\quad\quad\text{or}\quad\quad \bvec{1\\1\\1}a_0+\bvec{-1\\1\\2}a_1=\bvec{-1\\4\\7}.$$
  Then show that there is no solution to this problem.
  \item We now know that no linear combination of $\vec v_1=(1,1,1)$ and $\vec v_2 =(-1,1,2)$ will give us the vector $\vec b=(-1,4,7)$.  We would like to find scalars $a_0$ and $a_1$ so that $\vec v_1a_1+\vec v_2a_1$ is as close to $\vec b$ as possible. This is the exact same question as the previous problem (where Jimmy could not get to his space ship). 
  Multiply both sides of the inconsistent equation $A\vec x = \vec b$ on the left by $\bvec{1\\1\\1}^T = \bvec{1&1&1}$, and then multiply both sides by  $\bvec{-1\\1\\2}^T = \bvec{-1&1&2}$. This should get you two different equations that involve $c_1$ and $c_2$. 
  \item Compute $A^TA$ and $A^T\vec b$.  You should see that both of your equations above are in the matrix equation $A^TA\vec x=A^T\vec b$. 
  \item Now solve $A^TA\vec x = A^T\vec b$ for $\vec x$. Use your answer to state the line  $y=a_0 +a_1x$ that passes nearest these three points. 
 \end{enumerate}
\end{problem}
 
 The transpose of a matrix plays a crucial role in finding projections. When the problem $A\vec x =\vec b$ has no solution, it is impossible to write $\vec b$ as a linear combination of the columns of $A$.  If we multiply both sides on the left by $A^T$, then we have an equation that we can solve to obtain the coefficients $\vec x$ so that $A\vec x$ is as close to $\vec b$ as possible. This is the key idea to regression. 
%You can accomplish all this at once by row reducing $A^T[A|\vec b]$. 


%This needs to get lots of ideas all at once. I want them to get the determinant of each matrix. Have them draw the triangle, but ignore the counterclockwise part.  Have them do several problems. Make some really simple to start with. Do maybe 5 of them.  Include the rotate by 30 degree one.  Come back to this later and ask them to analyze eigenvectors, but only at a later date. 
\subsection*{Linear Transformations}
One way we can use a matrix is to think of the matrix as a map. When Sally was walking through the city in Problem \ref{sally in city}, she had a map of the city in her hands.  This map gave her the coordinates of locations in the city, but did so in a much simplified way. Going right on the map 1 block resulted in following the vector $(2,-1)$.  Going up 1 block resulted in following the vector $(1,3)$. It's much easier to give directions in terms of blocks.  

If Sally walks 2 blocks right, and 1 block up, then she arrives at $\bvec{2\\-1}(2)+\bvec{1\\3}(1) = \bvec{7\\1}$. In the city map, we base our all movement on the vectors $(1,0)$ and $(0,1)$. When looking at actual $(x,y)$ position, we base all our movements on the vectors $(2,-1)$ and $(1,3)$. We call each of these collections of independent vectors a basis.  We call $(c_1,c_2)=(2,1)$ the coordinates of the point $(x,y)=(7,1)$ relative to the basis $\{(2,-1),(1,3)\}$. 
We can describe any point $(x,y)$ using the simplified coordinates $(c_1,c_2)$ relative to this basis.


\begin{definition}[Basis and Coordinates Relative to a Basis]
 If the vectors $\vec v_1, \vec v_2,\ldots,\vec v_n$ are linearly independent, then we'll say these vectors form a basis.  
 We use the word ``basis'' because we can write (base) other vectors uniquely as a linear combination of these basis vectors.  You have been using the standard basis vectors $(1,0)$ and $(0,1)$ your entire life to talk about vectors in the plane. To plot the point $(2,3)$, we think ``right 2, up 3'' which is the same as the vector equation $(2,3)=2(1,0)+3(0,1)$. 

 Suppose $\mathscr{B}=\{\vec v_1, \vec v_2, \ldots, \vec v_n\}$ is a basis, and $\vec x$ is the linear combination
 $$\vec x = \vec v_1c_1+\vec v_2c_2+\cdots +\vec v_n c_n.$$
 Then we call $c_1, c_2, \ldots,c_n$ the coordinates of $\vec x$ relative to the basis $\mathscr{B}$. 
 
 In terms of matrices, when the columns of $A$ are linearly independent and $A\vec c=\vec x$, we say that $\vec c$ is the  coordinates of $\vec x$ relative to the columns of $A$. 
\end{definition}

A matrix $A$ takes each coordinate $(c_1,c_2)$ and transforms it to the point $\bvec{x\\y}=A\bvec{c_1\\c_2}$. You'll see in the next problem that lines get transformed to lines. For this reason, and others we'll soon see,  we call this coordinate transformation map a linear transformation. 

\begin{problem}
 Consider the matrices $A=\bvec{\nvec{1\\2}&\nvec{-1\\4}}$ and $B=\bvec{\nvec{1\\2}&\nvec{3\\-2}}$.  
 \begin{enumerate}
  \item 
  Consider  
  $\bvec{\nvec{1\\2}&\nvec{-1\\4}&\nvec{-1\\10}&\nvec{3\\0}&\nvec{1\\2}&\nvec{1\\0}}
  \xrightarrow{rref}
  \bvec{\nvec{1\\0}&\nvec{0\\1}&\nvec{1\\2}&\nvec{2\\-1}&\nvec{1\\0}&\nvec{2/3\\-1/3}}
  $.
  
  If we want to write $(x,y)=(-1,10)$ as a linear combination of the columns of $A$, what scalars (coordinates) $c_1$ and $c_2$ give $\pvec{1\\2}c_1+\pvec{-1\\4}c_1=\pvec{-1\\10}$?
  
  What are the coordinates of $(x,y)=(3,0)$ relative to the columns of $A$?  

  What are the the coordinates of $(1,0)$ relative to the basis $\{(1,2), (-1,4)\}$?
  \item
 Alice decides to walk around using coordinates relative to the columns of $A$.  She starts at $(0,0)$, and then walks to the $(c_1,c_2)$ coordinates $(1,0)$, then $(1,2)$, then $(0,1)$, and then back to $(0,0)$. Her path in the $(x,y)$ plane is shown below on the right.  
 \begin{center}
\newcommand{\mux}{1}
\newcommand{\muy}{2}
\newcommand{\mvx}{-1}
\newcommand{\mvy}{4}
\begin{tikzpicture}
\node (A) at (0,0) {\begin{tikzpicture}
  axis
  \draw (-1,0) -- coordinate (x axis mid) (2,0);
  \draw (0,-1) -- coordinate (y axis mid) (0,3);
  ticks
  \foreach \x in {-1,...,2}
   \draw (\x,1pt) -- (\x,-3pt)
    node[anchor=north] {};
  \foreach \y in {-1,...,3}
   \draw (1pt,\y) -- (-3pt,\y) 
    node[anchor=east] {}; 
  \fill[opacity=.2] (0,0) -- (1,0) -- (1,2) -- (0,1) -- (0,0);
  \draw[red,->,very thick] (0,0)--(1,0);
  \draw[blue,->,very thick] (0,0)--(0,1);
  \node at (.5,-1.5) {Coordinates $(c_1,c_2)$};
\end{tikzpicture}};
\node[right=of A ] (B) {\begin{tikzpicture}[scale=.5]
  axis
  \draw (-2,0) -- coordinate (x axis mid) (2,0);
  \draw (0,-1) -- coordinate (y axis mid) (0,10);
  ticks
  \foreach \x in {-2,...,2}
   \draw (\x,1pt) -- (\x,-3pt)
    node[anchor=north] {};
  \foreach \y in {-1,...,10}
   \draw (1pt,\y) -- (-3pt,\y) 
    node[anchor=east] {}; 
  \fill[opacity=.2] (0,0) -- (\mux,\muy) -- (\mux+2*\mvx,\muy+2*\mvy) -- (\mvx,\mvy) -- (0,0);
  \draw[red,->,very thick] (0,0)--(\mux,\muy);
  \draw[blue,->,very thick] (0,0)--(\mvx,\mvy);
  \node at (-2,-1.5) {Position $(x,y)$};
 \end{tikzpicture}};
 \draw[->] (A.east) -- node[above=3pt]{\footnotesize $A\bvec{c_1\\c_2} = \bvec{x\\y}$} (B.west);
\end{tikzpicture}
\end{center}
Bob decides to follow the same coordinate path, but he's using coordinates relative to the columns of $B$.  Draw Bob's path in the $(x,y)$ plane.  Remember that since we know coordinates $(c_1,c_2)$, we can get the $(x,y)$ position from $B\bvec{c_1\\c_2}=\bvec{x\\y}$. 

 
 %(How can you tell that Bob got his map by taking a picture of someone else map in a mirror?)
  \item 
 Candice is staring at a treasure map.  She doesn't have a matrix $C$ to help her translate from the treasure map to actual $(x,y)$ points. However, she does have a few bits of information. There are two trees on her map with coordinates $(c_1,c_2)$ at $(2,1)$ and $(-4,-3)$. The actual $(x,y)$ location of these trees is $(-4,5)$ and $(7,-10)$  This means if Candice knew $C$, then she could compute $C\bvec{\nvec{2\\1}}=\bvec{\nvec{-4\\5}}$ and $C\bvec{\nvec{-4\\-3}}=\bvec{\nvec{7\\-10}}$.  Combining these two products together into one matrix means $$C\bvec{\nvec{2\\1}&\nvec{-4\\-3}}=\bvec{\nvec{-4\\5}&\nvec{7\\-10}}.$$  Use this to find $C$.  [Hint: Try using an inverse matrix.]
 \item The treasure on Candice's map has the map coordinates $(-1,5)$.  Give Candice the $(x,y)$ location of the treasure.   
 \end{enumerate}

\end{problem}




%\begin{problem}
%Consider the linear transformation $$T(x,y) = (x+2y,3x-y) = \bvec{1&2\\3&-1}\bvec{x\\y}.$$
%This matrix transforms a square into a parallelogram. To see how, we note that $T(1,0) = (3,-1)$, $T(0,1) = (2,-1)$, and $T(1,1)=(3,2)$.  
%\newcommand{\mux}{1}
%\newcommand{\muy}{3}
%\newcommand{\mvx}{2}
%\newcommand{\mvy}{-1}
%\begin{center}
%\begin{tikzpicture}
%\node (A) at (0,0) {\begin{tikzpicture}
  %axis
%   \draw (-1,0) -- coordinate (x axis mid) (2,0);
%   \draw (0,-1) -- coordinate (y axis mid) (0,2);
%   ticks
%   \foreach \x in {-1,...,2}
%    \draw (\x,1pt) -- (\x,-3pt)
%     node[anchor=north] {};
%   \foreach \y in {-1,...,2}
%    \draw (1pt,\y) -- (-3pt,\y) 
%     node[anchor=east] {}; 
%   \draw (0,0) -- (1,0) -- (1,1) -- (0,1) -- (0,0);
%   \fill[opacity=.2] (1,0) -- (1,1) -- (0,1/2) -- (1,0);
%  \end{tikzpicture}};
% \node[right=of A] (B) {\begin{tikzpicture}[scale=.7]
%   axis
%   \draw (-1,0) -- coordinate (x axis mid) (4,0);
%   \draw (0,-1) -- coordinate (y axis mid) (0,4);
%   ticks
%   \foreach \x in {-1,...,3}
%    \draw (\x,1pt) -- (\x,-3pt)
%     node[anchor=north] {};
%   \foreach \y in {-1,...,3}
%    \draw (1pt,\y) -- (-3pt,\y) 
%     node[anchor=east] {}; 
%   \draw (0,0) -- (\mux,\muy) -- (\mux+\mvx,\muy+\mvy) -- (\mvx,\mvy) -- (0,0);
%  \fill[opacity=.2] (\mux,\muy) -- (\mux+\mvx,\muy+\mvy) -- (\mvx/2,\mvy/2) -- (\mux,\muy);
%  \end{tikzpicture}};
%  \draw[->] (A.east) -- (B.west);
% \end{tikzpicture}
% \end{center}
% \begin{enumerate}
%  \item Where does the function $T$ send the shaded triangle in the picture above? The vertices of the triangle are at $(0,1/2)$, $(1,0)$, and $(1,1)$ in the left diagram. Compute $T$ at each of these points, place these points in the diagram on the right, and then shade in transformed triangle in the diagram on the right.
%  \item For each transformation below, fill in the missing details.
% \begin{center}
%  \begin{tabular}{|c|c|c|c|}
%  \hline
%  Matrix & Transformed image & Determinant & Triangle points\\ \hline
% \renewcommand{\mux}{2}
% \renewcommand{\muy}{1}
% \renewcommand{\mvx}{-2}
% \renewcommand{\mvy}{3}
%  $A=\bvec{\nvec{\mux\\ \muy}&\nvec{\mvx\\ \mvy}}$
%  &
% \renewcommand{\mux}{2}
% \renewcommand{\muy}{1}
% \renewcommand{\mvx}{-2}
% \renewcommand{\mvy}{3}
% \begin{tikzpicture}[scale=.5]
%   axis
%   \draw (-1,0) --  (2,0);
%   \draw (0,0) --  (0,4);
%   ticks
%   \foreach \x in {-1,...,2}
%    \draw (\x,1pt) -- (\x,-3pt);
%    node[anchor=north] {};
%   \foreach \y in {0,...,3}
%    \draw (1pt,\y) -- (-3pt,\y); 
%    node[anchor=east] {}; 
%   \draw (0,0) -- (\mux,\muy) -- (\mux+\mvx,\muy+\mvy) -- (\mvx,\mvy) -- (0,0);
%   \fill[opacity=.2] (\mux,\muy) -- (\mux+\mvx,\muy+\mvy) -- (\mvx/2,\mvy/2) -- (\mux,\muy);
%  \end{tikzpicture}  
%  &
%  8
%  &
%  Counter Clockwise\\\hline
% \renewcommand{\mux}{-2}
% \renewcommand{\muy}{3}
% \renewcommand{\mvx}{2}
% \renewcommand{\mvy}{1}
%  $A=\bvec{\nvec{\mux\\ \muy}&\nvec{\mvx\\ \mvy}}$
%  &
% \renewcommand{\mux}{-2}
% \renewcommand{\muy}{3}
% \renewcommand{\mvx}{2}
% \renewcommand{\mvy}{1}
% \begin{tikzpicture}[scale=.5]
%   axis
%   \draw (-1,0) --  (2,0);
%   \draw (0,0) --  (0,4);
%   ticks
%   \foreach \x in {-1,...,2}
%    \draw (\x,1pt) -- (\x,-3pt);
%    node[anchor=north] {};
%   \foreach \y in {0,...,3}
%    \draw (1pt,\y) -- (-3pt,\y); 
%    node[anchor=east] {}; 
%  \draw (0,0) -- (\mux,\muy) -- (\mux+\mvx,\muy+\mvy) -- (\mvx,\mvy) -- (0,0);
%  \fill[opacity=.2] (\mux,\muy) -- (\mux+\mvx,\muy+\mvy) -- (\mvx/2,\mvy/2) -- (\mux,\muy);
%  \end{tikzpicture}  
%  &
%  
%  &
%  Clockwise\\\hline
% \renewcommand{\mux}{\cos 30^\circ}
% \renewcommand{\muy}{\sin 30^\circ}
% \renewcommand{\mvx}{-\sin 30^\circ}
% \renewcommand{\mvy}{\cos 30^\circ}
%  $A=\bvec{\nvec{\mux\\ \muy}&\nvec{\mvx\\ \mvy}}$
%  &
% \renewcommand{\mux}{cos 30}
% \renewcommand{\muy}{sin 30}
% \renewcommand{\mvx}{-sin 30}
% \renewcommand{\mvy}{cos 30}
% \begin{tikzpicture}[scale=.7]
%   axis
%  \draw (-2,0) --  (2,0);
%  \draw (0,-2) --  (0,2);
%   ticks
%  \foreach \x in {-1,...,1}
%   \draw (\x,1pt) -- (\x,-3pt);
%    node[anchor=north] {};
%  \foreach \y in {-1,...,1}
%   \draw (1pt,\y) -- (-3pt,\y); 
%    node[anchor=east] {}; 
%  \draw (0,0) -- (\mux,\muy) -- (\mux+\mvx,\muy+\mvy) -- (\mvx,\mvy) -- (0,0);
%  \fill[opacity=.2] (\mux,\muy) -- (\mux+\mvx,\muy+\mvy) -- (\mvx/2,\mvy/2) -- (\mux,\muy);
% \end{tikzpicture}  
%  &
%  
%  &
% \\\hline
%  \end{tabular}
% \end{center}
%  \item If we know $T(1,2)=(3,1)$ and we know $T(1,3)=(-1,2)$, can you state the matrix $A$ so that $T(x,y) = A\bvec{x\\y}$?
% \end{enumerate}
% 
% Linear Transformation.  Have them map points to certain spots, using a matrix.  Then give them a transformation and ask them to write the matrix that gave that transformation.  Use the heart problem for the inverse, and the triangle problem for the forward.  Just get the problems from my textbook.  Give them a Mathematica Notebook to check their work.  This is the heart of linear transformations.  They need to visualize them. 
% \end{problem}
%  



\subsection*{Cramer's Rule}
Gabriel Cramer developed a way to solve linear systems of equations by using determinants. For small systems, the solution is extremely fast. When the coefficients in the system are variables, Cramer's rule provides an extremely fast algorithm for obtaining a solution.


\begin{problem}[Cramer's Rule]
Our goal on this problem is to find a quick way to solve the matrix equation $$\begin{bmatrix}\nvec{a_{11}\\a_{21}}&\nvec{a_{12}\\a_{22}} \end{bmatrix}
\begin{bmatrix}\nvec{x_{1}\\x_{2}} \end{bmatrix}
=
\begin{bmatrix}\nvec{b_{1}\\b_{2}} \end{bmatrix}.$$ 
Let's look at an example and from it develop a general rule. 
Let $\vec v_1 = (a_{11},a_{21})=(2,-2)$ and $\vec v_2 = (a_{12},a_{22})= (1,2)$, so $A=\bvec{2&1\\-2&2}$. If we know that $x_1=-3$ and $x_2 = -2$, the we have $\vec b = x_1\vec v_1+x_2\vec v_2=(-8,2)$. In the picture below, the solid red vector is $\vec v_1$, the solid blue vector is $\vec v_2$, and the solid black vector is $\vec b$. Use the picture below, to answer the questions that follow.

%\includegraphics{cramers-visual}

\begin{center}
 \begin{tikzpicture}[scale=.5]
  \fill[lightgray] (0,0) -- (2,-2) -- (3,0) -- (1,2) -- (0,0);
  \fill[color=red!50!blue,opacity=0.2] (0,0) -- ++(1,2) -- ++(-6,6) -- ++(-1,-2) -- ++(6,-6);
  \fill[color=red!50!blue,opacity=0.2] (0,0) -- ++(1,2) -- ++(-8,2) -- ++(-1,-2) -- ++(8,-2);
  \fill[color=green,opacity=0.2] (0,0) -- ++(2,-2) -- ++(-8,2) -- ++(-2,2) -- ++(8,-2);
  \fill[color=green,opacity=0.2] (0,0) -- ++(2,-2) -- ++(-2,-4) -- ++(-2,2) -- ++(2,4);
  %axis
  \draw (-8,0) -- coordinate (x axis mid) (4,0);
  \draw (0,-6) -- coordinate (y axis mid) (0,8);
  %ticks
  \foreach \x in {-8,...,4}
   \draw (\x,1pt) -- (\x,-3pt)
    node[anchor=north] {};
  \foreach \y in {-6,...,8}
   \draw (1pt,\y) -- (-3pt,\y) 
    node[anchor=east] {}; 
  \draw[red,->,very thick] (0,0) -- (2,-2);
  \draw[blue,->,very thick] (0,0) -- (1,2);
  \draw[black,->,very thick] (0,0) -- (-8,2);
  \draw[red,->,very thick,dashed] (1,2) -- ++(2,-2);
  \draw[blue,->,very thick,dashed] (2,-2) -- ++(1,2);
  \draw[red,->,very thick,dashed] (0,0) -- ++(-6,6);
  \draw[red,->,very thick,dashed] (-2,-4) -- ++(-6,6);
  \draw[blue,->,very thick,dashed] (0,0) -- ++(-2,-4);
  \draw[blue,->,very thick,dashed] (-6,6) -- ++(-2,-4);
 \end{tikzpicture}
\end{center}


\noindent[Hint: Each question can be answered by thinking about determinants as areas.]
\begin{enumerate}
 \item 
 \marginpar{Remember that when we put vertical bars on a matrix, that means we compute the determinant.}%
 Explain why $x_1\begin{vmatrix}\vec{v_1}&\vec v_2\end{vmatrix}=\begin{vmatrix}x_1\vec{v_1}&\vec v_2\end{vmatrix}$.  Then explain why $\begin{vmatrix}x_1\vec{v_1}&\vec v_2\end{vmatrix} = \begin{vmatrix}\vec{b_1}&\vec v_2\end{vmatrix}$.  Finally, solve for $x_1$ to show $$x_1 = \frac{\begin{vmatrix}\nvec{b_1\\b_2}&\nvec{a_{12}\\a_{22}} \end{vmatrix}}{\begin{vmatrix}\nvec{a_{11}\\a_{21}}&\nvec{a_{12}\\a_{22}} \end{vmatrix}}.$$
 \item In a similar fashion, show that $$x_2 =\frac{\begin{vmatrix}\nvec{a_{11}\\a_{21}}&\nvec{b_1\\b_2}\end{vmatrix}}{\begin{vmatrix}\nvec{a_{11}\\a_{21}}&\nvec{a_{12}\\a_{22}} \end{vmatrix}}.$$ 
 \item Consider the system of equations $x+2y=3, 4x+5y=6$. Use the formulas you just developed to solve this system. You'll need to compute three determinants.
 \end{enumerate}
\end{problem}


The previous problem is a proof by picture of Cramer's rule in 2D. The proof of the theorem is similar in all dimensions. The key idea is to connect determinants to area.  
Here's a formal statement of Cramer's Rule.
\begin{theorem}[Cramer's Rule]\label{Cramer's Rule}
 Consider the linear system given by $A\vec x = \vec b$, where 
$A=\begin{bmatrix}\vec v_1 &\vec v_2 &\cdots \vec v_n \end{bmatrix}$
is an $n$ by $n$ matrix whose determinant is not zero.  Let $D=|A|$. For each $i$, replace vector $\vec v_i$ with $\vec b$, and then let $D_i$ be the determinant of the corresponding matrix. The solution to the linear system is then 
$$x_1 = \frac{D_1}{D},\quad x_2 = \frac{D_2}{D},\quad \cdots \quad x_n = \frac{D_n}{D}.$$

For the 2 by 2 system
$$
\begin{bmatrix}\nvec{a_{11}\\a_{21}}&\nvec{a_{12}\\a_{22}} \end{bmatrix}
\begin{bmatrix}\nvec{x_{1}\\x_{2}} \end{bmatrix}
=
\begin{bmatrix}\nvec{b_{1}\\b_{2}} \end{bmatrix},
$$
Cramer's rule states the solution is (provided $|A|\neq 0$) 
$$
x_1 = \frac{D_1}{D}=\frac{\begin{vmatrix}\nvec{b_1\\b_2}&\nvec{a_{12}\\a_{22}} \end{vmatrix}}{\begin{vmatrix}\nvec{a_{11}\\a_{21}}&\nvec{a_{12}\\a_{22}} \end{vmatrix}},
\quad 
x_2 = \frac{D_2}{D}=\frac{\begin{vmatrix}\nvec{a_{11}\\a_{21}}&\nvec{b_1\\b_2}\end{vmatrix}}{\begin{vmatrix}\nvec{a_{11}\\a_{21}}&\nvec{a_{12}\\a_{22}} \end{vmatrix}}
.$$
\end{theorem}








\section{Prep for Friday May 24}
\begin{hw*}
 Complete the following.  Remember that every day you are suppose to complete the extra practice problems (as your review HW).  You will report having done this in I-Learn, and get a free 15\% of your grade for doing so. The goal is to just make sure you complete a few quick practice problems. Don't spend a long time on these, rather if you get stuck on one, put it aside and come see me (or try it again after class). 
 \begin{enumerate}
  \item Cramer's rule: \href{\onlinetext}{Online {\it Linear Algebra}}, page 55, problems 3ab. The solutions are on page 60.
  \item Linear transformations: Schaum's Problem 9.29(just c and d) on page 350.  The solution is on page 352.  Part d is very similar to Candice's treasure map problem.
 \end{enumerate}
\end{hw*}

\subsection*{Linear Regression}
When we want to find the coefficients of an equation such as $y=mx+b$ or $y=ax^2+bx+c$ that passes through several points, remember that the key idea is to write the linear system of equations $A\vec x=\vec b$ that we wish to solve.  If the equation has no solution, then we multiply both sides by $A^T$ and then solve the corresponding system.  This gets us the linear combination of the columns of $A$ that is closest to $\vec b$. We call this linear regression. 
%Change this to just 5 points through a parabola.
\begin{problem}
 Consider the 5 points 
$$ 
(-1,  1),
( 0, -1),
( 1, -2),
( 2, -1),
( 2, -2)
$$
\begin{enumerate}
 \item Use linear regression to give an equation of the line $y=a_0+a_1x$ that best fits these 5 points. (Remember to set up the system $A\vec x = \vec b$, and then multiply by the transpose.) 
 \item Use linear regression to give an equation of the parabola $y=a_0+a_1x+a_2x^2$ that best fits these 5 points. 
 For this one, your system $A\vec x=\vec b$ looks like 
 $$\bvec{\nvec{1\\1\\1\\1\\1}&\nvec{-1\\0\\1\\2\\2}&\nvec{?\\?\\?\\?\\?}}\bvec{a_0\\a_1\\a_2}=\bvec{1\\-1\\-2\\-1\\-2}.$$ Just multiply both sides by $A^T$ and then solve the system of equations. 
 \item Use linear regression to give an equation of the cubic $y=a_0+a_1x+a_2x^2+a_3x^3$ that best fits these 5 points. Your answer should have some $1/12$ths in it. You might want to graph this one.   
 \item Why is there no quartic that passes exactly through these points?
\end{enumerate}
When you finish this problem, you should have three setups of the form $A\vec x=\vec b$. You should also show what equation you get after multiplying by $A^T$ on both sides.  Then show the rref of the resulting system, and write the equation of the line, parabola, and cubic that you obtain. 
\end{problem}

You can now use linear regression to find an equation of more than just lines that best fit through several data points. The key is to set up the system which has no solution, multiply both sides by the transpose, and then row reduce. Let's use this idea to obtain a general solution for finding an equation of line that best approximates some arbitrary points. 

%Do 5 points through a line.  Leave them general.
\begin{problem}
 Consider the five points 
 $$
 (x_1,y_1),
 (x_2,y_2),
 (x_3,y_3),
 (x_4,y_4),
 (x_5,y_5).
$$
We would like to find an equation of the least squares regression line $y=a_0+a_1x$ that best fits these points. 
Set up the matrices $A$, $\vec x$, $\vec b$, and $A^T$. Multiply together $A^TA$ and $A^T\vec b$ (your result should involve sums of the form $\sum x_i$, $\sum y_i$, $\sum x_iy_i$, and $\sum x_i^2$). Then solve the equation $A^TA\vec x = A^T\vec b$ and state the coefficients $a_0$ and $a_1$. 

[Hint: Since the system involves variable coefficients, try using Cramer's rule. It should kick out the solution almost instantly with 3 two by two determinants. One of these determinants should be $(5)\left(\sum x_iy_i\right) - \left(\sum x_i\right)\left(\sum y_i\right)$.]
\end{problem}

The formula you developed above is the formula found in software programs.  It's also the formula you'll find in statistic textbooks, high school textbooks, online help sites, etc.  They just change the $5$ to an $n$.  This concept is one that you can help students in high school understand.  Most books just say, ``Multiply by $A^T$,'' but never give a reason why you would do that.  You can help students understand that $A\vec x$ is a linear combination of the columns of $A$, and that regression just asks them to find the linear combination that gets them closest to $\vec b$. 

\subsection*{Linear Transformations}

%A few linear transformations.  Give them software to explore the idea..... Have them type in a few matrices.   Then when they are done, answer some questions.  This problem can easily be done now with software. 
\begin{problem}
 On this problem, you will explore graphs of several linear transformations. Your job is to look for patterns and explanations.  Please head to the following webpage:
\begin{itemize}
 \item \href{\urllineartransformationsinplane}{\urllineartransformationsinplane}
\end{itemize}
You may find this problem easiest if you create your own account at sagemath.org, and then copy the code from the URL above to your own notebook. Then you can put 10+ linear transformation graphs in the same document so you can compare them all side by side. 

Here's your job. In the software link above, change the matrix $A$ to be several different matrices. Look for an answer to each question below.
\begin{itemize}
 \item What does the determinant tell you about the map? Can you see the determinant in the pictures?
 \item If the determinant is zero, what does that mean about your map?
 \item What do the eigenvalues tell you about your map? This is perhaps easiest to tell with the circle map.
 \item Is there a connection between the eigenvalues and the determinant?
 \item What do the eigenvectors tell you?
\end{itemize}
To be prepared for class, write answers to these questions using complete sentences.
There are many great answers to the questions above. There are lots of patterns. 

Here are some matrices that might be useful to look at. Please type each of these in.  As you discover patterns, test them against these matrices. 
$$
\bvec{2&1\\0&3},
\bvec{-2&1\\0&3},
\bvec{-2&1\\0&-3},
\bvec{0&4\\3&1},
\bvec{2&1\\1&2},
\bvec{1&2\\2&4},
\bvec{0&-1\\1&0},
\bvec{-1&2\\2&1},
$$
$$\bvec{\cos(pi/3)&-\sin(pi/3)\\ \sin(pi/3)&\cos(pi/3)},
\bvec{3\cos(pi/6)&-5\sin(pi/6)\\ 3\sin(pi/6)&5\cos(pi/6)}.
$$
\end{problem}


We'll start seeing eigenvalues and eigenvectors playing a major role in most of our work in the next few weeks. We need to make sure we are comfortable computing them with software, even for larger matrices. 
\begin{problem}\label{First example of deficient eigenvalue}
Consider the matrices 
$$
B=
\begin{bmatrix}
 3 & 0 & 0 \\
 0 & 2 & 1 \\
 0 & 1 & 2
\end{bmatrix}
,\text{ and } 
C=
\begin{bmatrix}
 3 & 1 & 0 \\
 0 & 2 & 1 \\
 0 & 1 & 2
\end{bmatrix}
.$$
Feel free to use software on this problem to perform any needed row reductions. 
\begin{enumerate}
\item Show that the characteristic polynomial for both $B$ and $C$ is $$(3-\lambda)(\lambda-3)(\lambda -1).$$  What are the eigenvalues of each matrix?
\item For each eigenvalue of $B$, state all the corresponding eigenvectors. Show the matrix you needed to row reduce, show the rref (from software), and then state the eigenvectors by writing $(x,y,z)$ in terms of any free variable.
\item For each eigenvalue of $C$, repeat the previous step.
\end{enumerate}
When you are done, you will have 4 matrices, each matrix's rref, and the eigenvectors you get by interpreting the rref.  A simple model to follow in sharing this kind of work with others is 
$$\bvec{[ccc|c]*&*&*&*\\ *&*&*&*\\ *&*&*&*}\xrightarrow{\text{rref}} \bvec{[ccc|c]*&*&*&*\\ *&*&*&*\\ *&*&*&*} \Rightarrow \pvec{x\\y\\z}=\cdots.$$ 
\end{problem}



\section{Prep for Monday May 27}
Memorial Day.  Enjoy the break.


\section{Prep for Tuesday May 28}
\begin{hw*}
 Complete the following.  Remember that every day you are suppose to complete the extra practice problems (as your review HW).  You will report having done this in I-Learn, and get a free 15\% of your grade for doing so. The goal is to just make sure you complete a few quick practice problems. Don't spend a long time on these, rather if you get stuck on one, put it aside and come see me (or try it again after class). (Most of this is a repeat of Friday.)
 \begin{enumerate}
  \item Cramer's rule: \href{\onlinetext}{Online {\it Linear Algebra}}, page 55, problems 3ab and 3c (3c is an addition to Friday's). The solutions are on page 60.
  \item Linear transformations: In Schaum's, read 9.7 on page 340. Then complete Problem 9.29(just c and d) on page 350.  The solution is on page 352. You'll need to multiply by an inverse matrix on both sides. Part d is very similar to Candice's treasure map problem.
 \end{enumerate}
 
\end{hw*}


The first two problem for today ask you to develop general formula for polynomials that exactly pass through certain points, and then for polynomials that best fit a set of data. Let's start with exact fits. 

\begin{problem}
Solve the following. [Hint: Because the problem involves variable points, try using Cramer's rule. It will be faster than row reduction.]
\begin{enumerate}
 \item Find the intercept $a_0$ and slope $a_1$ of a line $y = a_0+a_1 x$ that passes through the points $(x_1,y_1)$ and $(x_2,y_2)$. You'll need to solve the system $\bvec{1&x_1\\1&x_2}\bvec{a_0\\a_1}=\bvec{y_1\\y_2}$. Use Cramer's rule. 
 \item Find the coefficients $a_0$, $a_1$, and $a_2$ of a parabola $y = a_0+a_1 x^1+a_2x^2$ that passes through the points $(x_1, y_1)$,  $(x_2, y_2)$, and  $(x_3, y_3)$.
\end{enumerate}
Under what conditions will your solutions above not be valid?
\end{problem}

Now lets develop the linear regression formula for getting a line $y=a_0+a_1x$ that passes through several points.  When you finish, you can check if you are correct by searching online for the general formula. 


\begin{problem}
 Consider the five points 
 $$
 (x_1,y_1),
 (x_2,y_2),
 (x_3,y_3),
 (x_4,y_4),
 (x_5,y_5).
$$
We would like to find an equation of the least squares regression line $y=a_0+a_1x$ that best fits these points. 
Set up the matrices $A$, $\vec x$, $\vec b$, and $A^T$. Multiply together $A^TA$ and $A^T\vec b$ (your result should involve sums of the form $\sum x_i$, $\sum y_i$, $\sum x_iy_i$, and $\sum x_i^2$). Then solve the equation $A^TA\vec x = A^T\vec b$ and state the coefficients $a_0$ and $a_1$. 

[Hint: Since the system involves variable coefficients, try using Cramer's rule. It should kick out the solution almost instantly with 3 two by two determinants. One of these determinants should be $(5)\left(\sum x_iy_i\right) - \left(\sum x_i\right)\left(\sum y_i\right)$.]
\end{problem}

The formula you developed above is the formula found in software programs.  It's also the formula you'll find in statistic textbooks, high school textbooks, online help sites, etc.  They just change the $5$ to an $n$.  This concept is one that you can help students in high school understand.  Most books just say, ``Multiply by $A^T$,'' but never give a reason why you would do that.  If you can help students understand that $A\vec x$ is a linear combination of the columns of $A$, and that regression just asks them to find the linear combination that gets them closest to $\vec b$, you will empower your students.  This one idea leads to most of modern innovations, something we'll study more in Math 242.

We'll start seeing eigenvalues and eigenvectors playing a major role in most of our work in the next few weeks. We need to make sure we are comfortable computing them with software, even for larger matrices. 
\begin{problem}
Consider the matrices 
$$
B=
\begin{bmatrix}
 3 & 0 & 0 \\
 0 & 2 & 1 \\
 0 & 1 & 2
\end{bmatrix}
,\text{ and } 
C=
\begin{bmatrix}
 3 & 1 & 0 \\
 0 & 2 & 1 \\
 0 & 1 & 2
\end{bmatrix}
.$$
Feel free to use software on this problem to perform any needed row reductions. 
\begin{enumerate}
\item Show that the characteristic polynomial for both $B$ and $C$ is $$(3-\lambda)(\lambda-3)(\lambda -1).$$  What are the eigenvalues of each matrix?
\item For each eigenvalue of $B$, state all the corresponding eigenvectors. Show the matrix you needed to row reduce, show the rref (from software), and then state the eigenvectors by writing $(x,y,z)$ in terms of any free variable.
\item For each eigenvalue of $C$, repeat the previous step.
\end{enumerate}
When you are done, you will have 4 matrices, each matrix's rref, and the eigenvectors you get by interpreting the rref.  A simple model to follow in sharing this kind of work with others is 
$$\bvec{[ccc|c]*&*&*&*\\ *&*&*&*\\ *&*&*&*}\xrightarrow{\text{rref}} \bvec{[ccc|c]*&*&*&*\\ *&*&*&*\\ *&*&*&*} \Rightarrow \pvec{x\\y\\z}=\cdots.$$ 
\end{problem}




\begin{problem}
The eigenvalues of the matrix 
$A=\bvec{2&6\\18&5}$ are $\lambda_1 = 14$ and $\lambda_2 = -7$.  An eigenvector corresponding to $\lambda_1 =14$ is  $\vec x_1=(1,2)$. 
An eigenvector corresponding to $\lambda_2 = -7$ is $\vec x_2 = (-2,3)$. 
\begin{enumerate}
 \item What is the product $A\vec x_1$? What is the product $A\vec x_2$? Can you explain how to get these products without actually doing matrix multiplication.
 \item 
\marginpar{We place the eigenvectors of $A$ into the columns of $Q$.}%
What is the product $AQ$ where $Q = \bvec{\vec x_1&\vec x_2} = \bvec{1&-2\\2&3}$. You can do this product by using your answer to the first part. 
 \item 
\marginpar{[There are several ways to do this problem. You could multiply both sides on the left by the inverse of $Q$, and then solve for $D$. Do this, using a calculator.  Another way is to reason about the connection between eigenvalues, eigenvectors, the matrix $A$, and linear combinations.]
}%
Find a matrix $D$ so that $AQ=QD$.  Any idea why we use $D$ for this matrix? See the hint on the side. 

\item 
Suppose $A$ is a 3 by 3 matrix with eigenvectors $\vec x_1$, $\vec x_2$, and $\vec x_3$, corresponding to the eigenvalues $\lambda = 2,4,-5$, respectively. If we let $Q = \bvec{\vec x_1&\vec x_2&\vec x_3}$, then make a guess as to what $D$ should equal so that $AQ=QD$. Explain your guess. 
Guess what $D$ equals if we instead place the eigenvectors into $Q$ in the order $Q = \bvec{\vec x_2&\vec x_3&\vec x_1}$? 





\end{enumerate}
%What do they get if they compute AQ (or explain why we immediatly know AQ).  Does it equal DQ or QD.  Does order matter?
%They have to analyze what matrix multiplication means. 
\end{problem}


In the problem above, we wrote $AQ=QD$ where $D$ is a diagonal matrix whose diagonal entries are the eigenvalues of $A$. The columns of $Q$ are eigenvectors of $A$, which we place in the same order as the eigenvalues on the diagonal of $D$. We can use this idea to obtain a matrix with any desired eigenvalue/eigenvector pairs. In particular, this means we can observe something in nature and look for outward/inward pushes/pulls. From these observations we know $Q$ and $D$, which means we can solve for $A$. 








\section{Prep for Thursday May 30}

\begin{hw*}
 Please complete problems 21-24 (if you have not yet done so yet).
\end{hw*}

















%A few linear transformations.  Give them software to explore the idea..... Have them type in a few matrices.   Then when they are done, answer some questions.  This problem can easily be done now with software. 
\begin{problem}
 On this problem, you will explore graphs of several linear transformations. Your job is to look for patterns and explanations.  Please head to the following webpage:
\begin{itemize}
 \item \href{\urllineartransformationsinplane}{\urllineartransformationsinplane}
\end{itemize}
You may find this problem easiest if you create your own account at sagemath.org, and then copy the code from the URL above to your own notebook. Then you can put 10+ linear transformation graphs in the same document so you can compare them all side by side. 

Here's your job. In the software link above, change the matrix $A$ to be several different matrices. Look for an answer to each question below.
\begin{itemize}
 \item What does the determinant tell you about the map? Can you see the determinant in the pictures?
 \item If the determinant is zero, what does that mean about your map?
 \item What do the eigenvalues tell you about your map? This is perhaps easiest to tell with the circle map.
 \item Is there a connection between the eigenvalues and the determinant?
 \item What do the eigenvectors tell you?
 \item What happens if the matrix is symmetric?
\end{itemize}
To be prepared for class, write answers to these questions using complete sentences.
There are many great answers to the questions above. There are lots of patterns. 

Here are some matrices that might be useful to look at. Please type each of these in.  As you discover patterns, test them against these matrices. 
$$
\bvec{2&1\\0&3},
\bvec{-2&1\\0&3},
\bvec{-2&1\\0&-3},
\bvec{0&4\\3&1},
\bvec{2&1\\1&2},
\bvec{1&2\\2&4},
\bvec{0&-1\\1&0},
\bvec{-1&2\\2&1},
$$
$$\bvec{\cos(pi/3)&-\sin(pi/3)\\ \sin(pi/3)&\cos(pi/3)},
\bvec{3\cos(pi/6)&-5\sin(pi/6)\\ 3\sin(pi/6)&5\cos(pi/6)}.
$$
\end{problem}












\begin{problem}
Suppose you know that the matrix $A$ has eigenvalues $\lambda_1=7$ and $\lambda_2=-14$ with corresponding eigenvectors $\vec x_1=(2,-1)$ and $\vec x_2 = (1,3)$.
\begin{enumerate}
 \item 
\marginpar{Since $AQ=QD$, what does multiplying both sides by $Q^{-1}$ on the right yield?}%
We can write $AQ=QD$ where $Q=\bvec{\nvec{2\\-1}&\nvec{1\\3}}$ and $D=\bvec{7&0\\0&-14}$. Use this information to solve for $A$.  
 \item We could have instead written $AQ=QD$ where $Q=\bvec{\nvec{1\\3}&\nvec{2\\-1}}$ and $D=\bvec{-14&0\\0&7}$ (reversing the order we put things into $Q$ and $D$). Use this information to solve for $A$.
 \item Suppose we know that a vector field $\vec F$ applies the forces $F(4,-2) = (28,-14)$ and $F(-1,-3) = (14,42)$. Explain why we know two eigenvectors are $(4,-2)$ and $(-1,-3)$ with corresponding eigenvalues $\lambda=7$ and $\lambda =-14$.  Use this information to state $Q$ and $D$, and then use $AQ=QD$ to find the matrix $A$ such that $F(x,y)=A\pvec{x\\y}.$
 \item You should have gotten the exact same matrix $A$ in each problem above, though the $Q$ and $D$ used on each part was different. Guess another choice for $Q$ and $D$, different than the three above, so that $AQ=QD$. Why did you make this guess? 
%This problem is most likely best left for a discussion in class.  Let them do the computations. 
% \item We know there are infinitely many eigenvectors corresponding to each eigenvalue of $A$. When we use $AQ=QD$ to find the matrix $A$, does it matter which eigenvectors we choose to put in $Q$?  Does the order we place the eigenvectors in $Q$ make a difference?
\end{enumerate}
\end{problem}


\section{Prep for Friday May 31}


\begin{problem*}[Lesson Plan]
 Here's a written reminder about the lesson plan assignment.  
 
 Imagine that you are teaching Algebra in high school.  You are teaching the accelerated students at school, which means you can cover additional topics that are not required by the Common Core.  These topics are listed in the file \href{https://www.dropbox.com/s/3fkhwosi5xjhl3o/CommonCore.pdf}{CommonCore.pdf} which I handed out in class. You plan to have the students learn most of the content using inquiry based learning.  You will need problems for them to complete out of class each day, and problems to have them complete in class in groups.
 \begin{itemize}
  \item You must decide which objectives you want the students to reach.  With 1 week, you may not have time to reach them all. That's fine.
  \item For each day of class, you should have a few preparation problems that you would like the students to complete prior to coming to class.   Each member of your group should create 3-4 problems.
  \item Type each preparation problem you create. Include instructor notes that tell (1) what objectives this problem should help the student reach, (2) why you believe this problem will be interesting to the student, and (3) how long you estimate it will take an average student to complete this problem. Provide a solution to the problem (you are welcome to hand write the solution.)
  \item As a group, decide which preparation problem will be tackled each day.  Which will they do before the first day, which before the second day, etc.  
  \item When the students come to class each day, what problems do you plan to have the students work on as a group in class. You each should come up with 2-3 simpler problems that you plan to have them tackle in groups.  These can be hand written. Your list does not have to be same as other in your group.
  \item  This should all be complete by Friday June 7 at midnight.
 \end{itemize}

\end{problem*}


\begin{problem}[Google Page Rank](Thanks to David Stowell for this problem) 
The Google Search Engine uses an algorithm called PageRank.
The basic idea is that the world wide web contains a number of documents with links connecting them all.  
Each document is ranked according to its importance.
A document's importance score depends on how many other pages have links pointing to it.
To fix ideas,suppose that we have four pages in our web: $P_1$, $P_2$, $P_3$, and $P_4$. 
Now suppose that this web has the following links:\
\begin{itemize}
 \item $P_1$ has outgoing links to all other pages.
 \item $P_2$ has outgoing links to $P_3$ and $P_4$.
 \item $P_3$ has outgoing links to $P_1$.
 \item $P_4$ has outgoing links to $P_1$ and $P_3$.
\end{itemize}
To determine the importance of a particular page, we simply need to count the number of times all the other pages have voted for that page.  In addition, each page has only one vote, or point, to give. It can give that one point to one page, by voting for only one page, or it can also choose to divide its vote among all the pages it votes for. In our example above, $P_1$ has two incoming links, called backlinks.
Its importance score we'll denote by $x_1$ and we compute it with $x_1 = (1){x_3}+\frac{1}{2}x_4$. Notice that the only links coming into $P_1$ are from $P_3$ and $P_4$. Moreover, $P_3$ only votes once, while $P_4$ splits its vote in two ways -- half of its vote goes to $P_1$, the other half to $P_3$. 
\begin{enumerate}
 \item Obtain an equation for $x_2$, $x_3$, and $x_4$, similar to the one above.  Then write your system of equations in the form 
$$
\bvec{
0&0&1&\frac{1}{2}\\
1/3&0&0&0\\
*&*&*&*\\
*&*&*&*
}
\bvec{x_1\\x_2\\x_3\\x_4}=\bvec{x_1\\x_2\\x_3\\x_4}.
$$
\item Look at the structure of the matrix.  In particular, what do you notice about the columns of the matrix?
\item Notice that the above equation can be written as $A\vec x = \lambda \vec x$. What is the eigenvalue $\lambda$?
\item Compute the eigenvector associated with this eigenvalue.  From your computation, which page is the most important?
\end{enumerate}
The world wide web consists of billion to trillions of pages. Modern computers can find eigenvectors of this size of a matrix extremely quickly.  
\end{problem}


\begin{problem}[Linear Regression with Exponential Data]
 Sometimes we know that data does not follow a polynomial, but rather follows an exponential model of the form $y=ce^{kx}$.  We can still use linear regression to find the unknown coefficients $c$ and $k$.  Let's find the coefficients $c$ and $k$ so that $y=ce^{kx}$ is as close to the points $(1,2)$, $(3,4)$ and $(4,8)$ as we can get.
 \begin{enumerate}
  \item Explain why the equation $y=ce^{kx}$ is the same as $\ln y = \ln c+kx$. We can then let $Y=\ln y$, $a_0=\ln c$, and $a_1=k$, then we need to fit the data to the model $Y=a_0+a_1x$.  
  \item We know that if $x=1$, then $y=2$ which means $Y=\ln 2$.  This means we need the line $Y=a_0+a_1x$ to pass nearest to the points $(1,\ln 2)$, $(3,?)$ and $(4,?)$.  Use linear regression to find an equation of this line. Show how you used matrices.
  \item Once you have $a_0$ and $a_1$, solve for $c$ and $k$. 
  \item Check your work by opening up a spread sheet program, type in the three points, make a scatter plot, and add an exponential trend line. 
 \end{enumerate}
\end{problem}




\section{Prep for Monday June 3}

\begin{hw*}
 There will be 2 problems to do here.  They will involve diagonalizing a matrix, and solving a linear regression problem.
\end{hw*}

\begin{problem}[Markov Process]
Suppose we own a car rental company which rents cars in Idaho Falls and Rexburg. 
The last few weeks have shown a weekly trend that 60\% of the cars which are rented in Rexburg will remain in Rexburg (the other 40\% end up in Idaho Falls). 
About 80\% of the cars which are rented in Idaho Falls will remain in Idaho Falls (the other 20\% end up in Rexburg). 
\begin{enumerate}
 \item If there are currently 60 cars in Rexburg and 140 cars in IF, how many will be in each city next week? If this trend continues, how many will be in each city in 2 weeks?
 \item Let $R_n$ and $I_n$ be the number of cars in Rexburg and Idaho Falls, respectively, at the beginning of the $n$th week, where $R_0=60$ and $I_0=140$. We know that we can compute $R_{n+1}$ by summing of 60\% of $R_n$ and 20\% of $I_n$. This gives us the equation $R_{n+1}=0.6 R_n+0.2I_n$. Write a similar equation for $I_{n+1}$ and then organize your work into the matrix form $$A\pvec{R_{n}\\I_{n}} = \pvec{R_{n+1}\\I_{n+1}}.$$  You can check your work by computing $A\pvec{R_0\\I_0} = \pvec{R_1\\I_1}$, which you computed above.
 \item We would like to know if the number of cars will stabilize in each city. This would mean that if the current week's car totals are $R$ and $I$, then we could find the next week's totals by solving the system $$A\pvec{R\\I} = \pvec{R\\I}.$$  The totals don't change, so we call this a steady state solution. Find the steady state solution by solving $A\pvec{R\\I} = \pvec{R\\I}$. %(What does it have to do with eigenvalues and eigenvectors?)  
 \item In the long run, what proportion of the cars will end up in Rexburg?
 \item Because the system $A\pvec{R\\I} = \pvec{R\\I}$ had a nonzero solution, we know something about the eigenvalues of the matrix $A$.  Can you spot an eigenvalue of $A$ without doing any computations?
\end{enumerate}
(We'll answer 4 and 5 in class if you are unable.  The key parts are 1-3.) 
\end{problem}



In the problem above, each week we could assign a car a state (Rexburg or IF).  The matrix $A$ above helped us get from one state to another.  Other examples of states are ``open'' or ``closed'' in an electrical circuit, or ``working properly'' and ``working improperly'' for operation of machinery at a manufacturing facility.  Stock market analysts use Markov processes and a generalization called stochastic processes to make predictions about future stock values. A car rental company which rents vehicles in different locations can use a Markov Process to keep track of where their inventory of cars will be in the future.  Imagine if you worked for Alamo and had thousands of car rental spots. Knowing where your cars will end up will let you know where to hire drivers, so you can move the cars to where they are needed. 









We call the matrix $A$ in a Markov process a transition matrix.  It's the matrix which tells you how to move from the current state $\vec x_n$ to the next state $\vec x_{n+1}$. This means we have 
\begin{align*}
\vec x_1 &= A\vec x_0\\
\vec x_2 &= A\vec x_1 = A(A\vec x_0) = A^2\vec x_0\\
\vec x_3 &= A\vec x_2 = A(A\vec x_1) =\cdots = A^3\vec x_0\\
\vec x_4 &= A\vec x_3 = A(A\vec x_2) =\cdots = A^4\vec x_0\\
&\vdots
\end{align*}
You can find the $n$th state by computing $\vec x_n = A^n \vec x_0$. We just raise the matrix to a power, and times by the initial state. The next problem has you examine what happens when you raise a matrix to a power. 
%Here is a perfect spot to talk about why eigenvalues are so important, and why having an eigenvalue of 1 is also so crucial. If I could get to AQ=QD here, then this would be really cool.  Maybe.....  
\begin{problem}
 Raising a matrix to a power $A^n$ can be rather time consuming.  There's a really simple way to do it if you know the eigenvalues and eigenvectors. First write $AQ=QD$ and then solve for $A$.  We can then write $A^2 = AA=(QDQ^{-1})(QDQ^{-1})$.
\begin{enumerate}
 \item Let $D=\bvec{2&0\\0&3}$.  Compute $D^2$, $D^3$, and $D^n$. Make a guess for $\bvec{a&0&0\\0&b&0\\0&0&c}^n$.
 \item \marginpar{We know $A^2 = QDQ^{-1}QDQ^{-1}$.  Does anything cancel?}%
Explain why $A^2 = QD^2Q^{-1}$. (See the margin for a hint.) Then explain why $A^3 = QD^3Q^{-1}$ and $A^n = QD^nQ^{-1}$.
 \item Suppose that the eigenvalues of $A$ are $\lambda = 1$ and $\lambda =1/2$, with corresponding eigenvectors $(1,2)$ and $(3,4)$.  Explain why $\ds \lim_{n\to\infty}D^n = \bvec{1&0\\0&0}$, and then compute $\ds\lim_{n\to\infty}A^n$.      
\end{enumerate}

\end{problem}
%end 27




\section{Prep for Tuesday June 4}




\begin{hw*}
Complete the following review problems:
 \begin{itemize}
  \item In Schaum's Chp 11 problem 11.9 (page 413)  and 11.57c (page 437).
  \item In the \href{\onlinetext}{online text}, complete problem 5f in chapter 2 (page 56).
 \end{itemize}
\end{hw*}

This problem is a repeat of yesterdays. Please come to class with a solution.  We worked through one similar to it in class. 
\begin{problem}[Markov Process]
Suppose we own a car rental company which rents cars in Idaho Falls and Rexburg. 
The last few weeks have shown a weekly trend that 60\% of the cars which are rented in Rexburg will remain in Rexburg (the other 40\% end up in Idaho Falls). 
About 80\% of the cars which are rented in Idaho Falls will remain in Idaho Falls (the other 20\% end up in Rexburg). 
\begin{enumerate}
 \item If there are currently 60 cars in Rexburg and 140 cars in IF, how many will be in each city next week? If this trend continues, how many will be in each city in 2 weeks?
 \item Let $R_n$ and $I_n$ be the number of cars in Rexburg and Idaho Falls, respectively, at the beginning of the $n$th week, where $R_0=60$ and $I_0=140$. We know that we can compute $R_{n+1}$ by summing of 60\% of $R_n$ and 20\% of $I_n$. This gives us the equation $R_{n+1}=0.6 R_n+0.2I_n$. Write a similar equation for $I_{n+1}$ and then organize your work into the matrix form $$A\pvec{R_{n}\\I_{n}} = \pvec{R_{n+1}\\I_{n+1}}.$$  You can check your work by computing $A\pvec{R_0\\I_0} = \pvec{R_1\\I_1}$, which you computed above.
 \item We would like to know if the number of cars will stabilize in each city. This would mean that if the current week's car totals are $R$ and $I$, then we could find the next week's totals by solving the system $$A\pvec{R\\I} = \pvec{R\\I}.$$  The totals don't change, so we call this a steady state solution. Find the steady state solution by solving $A\pvec{R\\I} = \pvec{R\\I}$. %(What does it have to do with eigenvalues and eigenvectors?)  
 \item In the long run, what proportion of the cars will end up in Rexburg?
 \item Because the system $A\pvec{R\\I} = \pvec{R\\I}$ had a nonzero solution, we know something about the eigenvalues of the matrix $A$.  Can you spot an eigenvalue of $A$ without doing any computations?
\end{enumerate}
(We'll answer 4 and 5 in class if you are unable.  The key parts are 1-3.) 
\end{problem}

Again, this problem is a repeat of Monday's.

\begin{problem}
 Raising a matrix to a power $A^n$ can be rather time consuming.  There's a really simple way to do it if you know the eigenvalues and eigenvectors. First write $AQ=QD$ and then solve for $A$.  We can then write $A^2 = AA=(QDQ^{-1})(QDQ^{-1})$.
\begin{enumerate}
 \item Let $D=\bvec{2&0\\0&3}$.  Compute $D^2$, $D^3$, and $D^n$. Make a guess for $\bvec{a&0&0\\0&b&0\\0&0&c}^n$.
 \item \marginpar{We know $A^2 = QDQ^{-1}QDQ^{-1}$.  Does anything cancel?}%
Explain why $A^2 = QD^2Q^{-1}$. (See the margin for a hint.) Then explain why $A^3 = QD^3Q^{-1}$ and $A^n = QD^nQ^{-1}$.
 \item Suppose that the eigenvalues of $A$ are $\lambda = 1$ and $\lambda =1/2$, with corresponding eigenvectors $(1,2)$ and $(3,4)$.  Explain why $\ds \lim_{n\to\infty}D^n = \bvec{1&0\\0&0}$, and then compute $\ds\lim_{n\to\infty}A^n$.   %[Hint:  If you can complete $D^n$, then you know what $A^n$. ]   
\end{enumerate}

\end{problem}
%end 27


The next two problems are very similar to the first Markov Process problem.  You can find more problems like this in the \href{\onlinetext}{online text} on page 56, problem 7.  
%28
\begin{problem}
In a certain town, there are 3 types of land zones: residential, commercial, and industrial. 
The city has been undergoing growth recently, and the city has noticed the following 5 year trends.  
\begin{itemize}
 \item Every 5 years, they've notice that 10\% of the residential land gets rezoned as commercial land, while 5\% of the residential land gets rezoned as industrial.  The other 85\% of residential land remains residential.  
 \item For commercial land, 70\% remains commercial, while 10\% becomes residential and 20\% becomes industrial. 
 \item For industrial land, 60\% remains industrial, while 25\% becomes commercial and 15\% becomes residential. 
 \item Currently the percent of land in each zone is 40\% residential, 30\% commercial, and 30\% industrial. 
\end{itemize}
Let's assume that these trends continue over an extended period of time.  
\begin{enumerate}
 \item The current state is $\vec x_0 = (40,30,30)$. After 5 years, what percentage of land will be zoned residential? Commercial? Industrial?  Answering this question should give you the transition matrix $A$ so that $\vec x_1=A\vec x_0$. 
 \item Use software to find $\vec x_2$, $\vec x_3$, and $\vec x_4$ (the land use percentages after 10, 15, and 20 years).  
 \item Find the steady state solution to this Markov Process by solving $A\vec x = 1\vec x$ (i.e., the eigenvector corresponding to the eigenvalue $\lambda =1$.)
\end{enumerate}
\end{problem}
%end 28














\begin{problem}
Consider three occupations, farming, manufacturing, and clothing.  Assume that goods are exchanged between the communities through barter only. Here is how the communities exchange their goods.
\begin{itemize}
 \item The farming community keeps 1/2 of their goods, giving 1/4 to manufacturing and 1/4 to clothing.
 \item The manufacturing community keeps 1/3 of their goods, giving 1/3 to farming and 1/3 to clothing.
 \item The clothing community keeps 1/4 of their goods, giving 1/2 to farming and 1/4 to manufacturing.
\end{itemize}
Let $x_1$ be the value of the goods produced by farming. 
Let $x_2$ be the value of the goods produced by manufacturing. 
Let $x_3$ be the value of the goods produced by clothing. 
Answer the following questions.
\begin{enumerate}
\item Suppose that all the communities have the exact same total value.
\marginpar{Some people might say it's fair to give each group the same value.  You should see why this idea is incorrect after completing this problem.}  
Let's assume the total value of all the goods is 3 billion dollars, so each group starts out with 1 billion. We can write this as $(x_1,x_2,x_3) = (1,1,1)$. After bartering, how much value will each group have? 
In particular, what percent of the total value will the farming community have? 
[Hint: Along the way you should produce a transition matrix $A$ so that $A\pvec{1\\1\\1}$ gives the answer.]
\item We would like to assign a value to each commodity so that each community gets a fair deal when they barter. To do this, we need the value of goods obtained after bartering to match the value of the goods on hand before bartering.  Explain why we can obtain this by solving the equation
$$
\begin{bmatrix}
   \frac{1}{2}& \frac{1}{3}& \frac{1}{2}\\
   \frac{1}{4}& \frac{1}{3}& \frac{1}{4}\\
   \frac{1}{4}& \frac{1}{3}& \frac{1}{4}
  \end{bmatrix}
\begin{bmatrix}
 x_1\\x_2\\x_3
\end{bmatrix}
=
\begin{bmatrix}
 x_1\\x_2\\x_3
\end{bmatrix}
 \quad
\text{or}
\quad 
\begin{bmatrix}
   \frac{1}{2}& \frac{1}{3}& \frac{1}{2}\\
   \frac{1}{4}& \frac{1}{3}& \frac{1}{4}\\
   \frac{1}{4}& \frac{1}{3}& \frac{1}{4}
  \end{bmatrix}
\begin{bmatrix}
 x_1\\x_2\\x_3
\end{bmatrix}
-
\begin{bmatrix}
 x_1\\x_2\\x_3
\end{bmatrix}
=
\begin{bmatrix}
 0\\0\\0
\end{bmatrix}.
$$  
Solve the system. [You should obtain infinitely many solutions.]
\item The equation above is an eigenvalue/eigenvector problem.  From the equation, you can see one of the eigenvalues of $A$. without computing determinants.  What is this eigenvalue? You've already found the corresponding eigenvector. 
\item What percent of the total value should we initially assign to the farming community so that bartering results in a fair deal?
\end{enumerate}
\end{problem}
%end 33












\chapter{Linear Transformations of Vector Spaces}

\section{Prep for Thursday June 6}
We start 242. You can take the exam through Saturday, though the testing center  if the Testing Center will allow it).

\section{Prep for Friday June 7}
I will be out of town this day. I am taking the eleven year old scouts to a 2 day scout camp.  Please use this time to finalize your lesson plan.  You'll need to organize your work into a single document, finalize which prep problems go on each day, and each leave with a copy of this document ready to submit. 


\section{Prep for Monday Jun 10}
Take the exam.  We'll be taking the exam again in small groups in class.

\section{Prep for Tuesday June 11}


Many problems in nature arise from conservation laws.  These laws generally focus on the principle that matter is neither created nor destroyed, rather it is just moved, changed, or something.  Any of the following could be viewed as a conservation law:
\begin{itemize}
 \item What comes in must come out.
 \item Voltage supplied equals voltage suppressed.
 \item Atoms before equal atoms after.
 \item The change in a quantity is how much it increases minus how much it decreases.
 \item Current in equals current out.
 \item The sum of the forces in every direction must match the total force.
 \item The force and moments must sum to zero when an object is at rest.
 \item This list could go on for a while.
\end{itemize}
We'll see that many of these conservation laws can be written in the matrix form $A\vec x=\vec 0$. We'll see that $\lambda=0$ is an eigenvalue, which means that when we follow the eigenvector direction, the underlying vector field neither pushes outward nor inward. In this eigenvector direction, the system is conserving something.
\begin{definition}[Homogeneous System, Kernel]
Because we'll encounter problems of the form $A\vec x = \vec 0$ quite often, we make some definitions. 
\begin{itemize}
 \item We say that the linearly system $A\vec x=\vec b$ is homogeneous if $\vec b=\vec 0$. 
 \item The set of solutions to $A\vec x=\vec 0$ is called the kernel (or null space) of $A$.  
\end{itemize}
\end{definition}


When we perform a partial fraction decomposition, our goal is to rewrite a complicated fraction as the sum of simpler fractions.  We are not changing the quantity that the fraction represents, rather we are just changing how we express the fraction.  This is a conservations law, as the fractional quantity is conserved.  Can we answer this problem by looking for the kernel of some matrix, or an eigenvector corresponding to $\lambda=0$?

\begin{problem}\label{partial fraction general solution}
Consider the partial fraction decomposition 
$$
\frac{8s+7}{(s-2)(s+3)} = \frac{A}{s-2}+\frac{B}{s+3}
$$
which we  can rewrite in the form
$$8s+7 = A(s+3)+B(s-2) = s(A+B)+1(3A-2B).$$
Because each side of the equal sign is a line, we must have $8=A+B$ and $7=3A-2B$.
Let's compare several different ways of solving this problem.
\begin{enumerate}
 \item Complete this partial fraction decomposition. Use any method you like to find $A$ and $B$. 
 \item Now let's solve 
$$
\frac{cs+d}{(s-2)(s+3)} = \frac{A}{s-2}+\frac{B}{s+3}
$$
Rather than thinking of $c$ and $d$ as known constants, let's make them variables in our linear system of equations.  
Our goal is to solve 
$$
(A+B-c)s+(3A-2B-d)=0
$$   
which we can rewrite in the matrix form 
\marginpar{Why did I save the last two columns for $c$ and $d$?}%
$$\bvec{
1 & 1 & -1 & 0 \\
3 & -2 & 0 & -1
}\bvec{A\\B\\c\\d}=\bvec{0\\0}.$$
This is a matrix equation of the form $A\vec x=\vec 0$, so the solutions are the kernel of $A$. Solve this matrix equation (find the kernel of $A$) and write your answer in terms of the free variables. Please use software to row reduce, and just share the key parts of your work (as shown below).
$$\bvec{[cccc|c]*&*&*&*&*\\ *&*&*&*&*}\xrightarrow{\text{rref}}\bvec{[cccc|c]1&0&*&*&*\\ 0&1& *&*&*}\Rightarrow \pvec{A\\B\\c\\d}=\bvec{*\\ *\\ *\\ * }c+\bvec{*\\ *\\ *\\ * }d.$$

\item 
We can rewrite the two equations $c=c$ and $d=d$ as the equations $0=0$ and $0=0$. Adding two rows of zeros to our matrix equation yields
$$\bvec{
1 & 1 & -1& 0 \\
3 &-2 & 0 & -1\\
0 & 0 & 0 & 0\\
0 & 0 & 0 & 0
}\bvec{A\\B\\c\\d}=\bvec{0\\0\\0\\0}.$$
Can you explain, from the definition of eigenvalues, why $\lambda =0$ is an eigenvalue of this matrix? Then find all eigenvectors of this matrix corresponding to $\lambda=0$.

\item 
Change the 4 by 4 matrix above to solve the partial fraction decomposition
$$
\frac{cs+d}{(s-p)(s-q)} = \frac{A}{s-p}+\frac{B}{s-q}.
$$
Then use software to solve, giving $A$ and $B$ in terms of $c,d,p,q$. %Under what conditions will your solution fail?
\end{enumerate}
\end{problem}
%end 12




Whenever I see a problem that involves a conservation law, I think two things. For one, there is probably a homogeneous system $A\vec x = \vec 0$ somewhere in the background whose kernel is the solution. Two, if I make sure $A$ is a square matrix (possibly adding rows of zeros), then I can rephrase ``find the kernel'' as ``find the eigenvectors corresponding to zero.'' To accomplish finding this matrix $A$, we'll often have to think of given constants as variables.  Let's do this with the previous problem. 



\begin{problem}[Traffic Flow]
Consider the following traffic flow grid.
\begin{center}
\begin{tikzpicture}[scale=1.3]
\begin{scope}[very thick, every node/.style={sloped,allow upside down}]
%\draw[step=1cm,gray,very thin] (-2,-2) grid (2,2);
\draw (-2,1)-- node(A) {\midarrow} (-1,1); 
\draw (-1,2)-- node(B) {\midarrow} (-1,1);  
\draw (1,1)-- node(C) {\midarrow} (1,2) ;  
\draw (1,1)-- node(D) {\midarrow} (2,1) ;  
\draw (2,-1) -- node(E) {\midarrow} (1,-1) ;  
\draw (1,-2) -- node(F) {\midarrow} (1,-1) ;  
\draw (-1,-1) -- node(G) {\midarrow} (-1,-2) ;  
\draw (-1,-1) -- node(H) {\midarrow} (-2,-1) ;  
\draw (-1,1) -- node(I) {\midarrow} (1,1) ;  
\draw (-1,1) -- node(J) {\midarrow} (-1,-1) ;  
\draw (1,-1) -- node(K) {\midarrow} (1,1) ;  
\draw (1,-1) -- node(L) {\midarrow} (-1,-1) ;  
\end{scope}
\draw (-1,1)  ++(-.2,.2) node {$A$}; 
\draw (1,1)  ++(-.2,.2) node {$B$}; 
\draw (1,-1)  ++(-.2,.2) node {$C$}; 
\draw (-1,-1)  ++(-.2,.2) node {$D$}; 
\node[left of=A] {100};
\node[above of=B] {200};
\node[above of=C] {100};
\node[right of=D] {150};
\node[right of=E] {50};
\node[below of=F] {50};
\node[below of=G] {50};
\node[left of=H] {100};
\node[label=above:$x_1$] at (I){};
\node[label=right:$x_2$] at (K){};
\node[label=below:$x_3$] at (L){};
\node[label=left:$x_4$] at (J){};
\end{tikzpicture}
\end{center}
The numbers on the edges represent the number of vehicles that either enter or leave the system each hour.  The variables $x_1$, $x_2$, $x_3$, and $x_4$ represent the number of cars on each road. Assume that all streets are one-way streets where the arrows give the direction of traffic flow.
\begin{enumerate}
 \item Find the solution to this traffic flow problem. When you are presenting this kind of information in class, you should use the pattern $B\xrightarrow{\text{rref}}R\Rightarrow\vec x = ...$, so show us the augmented matrix $B$, show us its rref $R$, and then state the solution $\vec x$ as a linear combination of vectors, namely
$$
\bvec{[cccc|c]*&*&*&*&*\\ *&*&*&*&*\\ *&*&*&*&*\\ *&*&*&*&*}
\xrightarrow{\text{rref}}\bvec{[cccc|c]1&0&0&*&*\\ 0&1&0&*&*\\ 0&0&1&*&*\\ 0&0&0&0&0}\Rightarrow \pvec{x_1\\x_2\\x_3\\x_4}=\bvec{*\\ *\\ *\\ * }x_4+\bvec{*\\ *\\ *\\ * }.$$

 \item  
 Let's change the given values to be variables.  Starting in the upper left corner and moving clockwise, replace the numbers 100, 200, 100, 150, etc., with the variables $a$, $b$, $c$, $d$, $e$, $f$, $g$, $h$. We now have 12 unknowns, namely $x_1$, ..., $x_4$, $a$, $b$, ..., $h$. 
At node $A$, our equation is now $x_1+x_4-a-b=0$. Write the other 3 equations from each node, and then express the homogeneous system in the form $A\vec x = \vec 0$ where $A$ is a 4 by 12 matrix.  State the matrix $A$.
 \item Find the kernel of $A$ (solve the system), and write your solution as a linear combination of vectors where the scalars are the free variables (use the $B\xrightarrow{\text{rref}}R\Rightarrow\vec x = ...$ pattern). Your solution should look like 
$$
\bvec{x_1\\ x_2 \\ x_3\\ x_4\\a\\b\\c\\d\\e\\f\\g\\h}=
\bvec{*\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *}x_4+
\bvec{*\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *}b+
\bvec{*\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *}c+
\bvec{*\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *}d+
\bvec{*\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *}e+
\bvec{*\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *}f+
\bvec{*\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *}g+
\bvec{*\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *\\ *}h.
$$ 
%\item Rewrite your solution, ignoring the rows corresponding to the free variables. Your answer should look like
%$$
%\bvec{x_1\\ x_2 \\ x_3\\a}=
%\bvec{*\\ *\\ *\\ *}x_4+
%\bvec{*\\ *\\ *\\ *}b+
%\bvec{*\\ *\\ *\\ *}c+
%\bvec{*\\ *\\ *\\ *}d+
%\bvec{*\\ *\\ *\\ *}e+
%\bvec{*\\ *\\ *\\ *}f+
%\bvec{*\\ *\\ *\\ *}g+
%\bvec{*\\ *\\ *\\ *}h.
%$$ 
\item 
The 4th row of your rref is not zero (which is why $a$ is not a free variable).  
Write the equation given by this 4th row.  Can you interpret this 4th equation as a conservation law?
\end{enumerate}
\end{problem}
%end 13




Have you noticed in every matrix problem we can always write the solution as a linear combination of vectors? 
When the system is homogeneous, the solution to $A\vec x = \vec 0$ (the kernel) is always all linear combinations of a few vectors. We take a vector times a free variable, plus a vector times a free variables, etc. The solution is the set of all linear combinations of a few vectors. It would be nice to say ``all linear combinations of'' in an efficient way. We'll use the word span to talk about forming all linear combinations, the word vector space to talk about the vectors in the span, and then dimension to talk about the geometric size of the span (is it a line, a plane, a 3D space, etc.).

\begin{definition}[Span, Basis, Vector Space, and Dimension]\label{definition span, vector space, dimension}
Consider the set of vectors $S = \{\vec v_1,\vec v_2,\cdots, \vec v_n\}$. 
\begin{itemize}
 \item  
The span of $S$ is the set of all linear combinations of the vectors in $S$. 
 \item 
When the vectors in $S$ are linearly independent, we say that the vectors form a basis for their span.   
 \item 
A vector space is the span of a collection of objects (we'll focus on vectors and functions).  
 \item 
A basis for a vector space is a collection of linearly independent objects whose span is the vector space. 
 \item 
The dimension of a vector space is the number of vectors in a basis for the vector space.
\end{itemize}
\end{definition}




%15
\begin{problem}
We've seen each of the following problems before. On this problem, you'll practice using the words span, vector space, basis, and dimension. 
\begin{enumerate}
 \item When Sally was looking for treasure in a corn field, Sally could move along the road $(-1,1)$ and the rows of corn $(2,1)$. Is the span of these two vectors the entire plane? [Hint: You can row reduce $\bvec{[cc|c]-1&2&x\\1&1&y}$, or you can come up with another explanation as to why any vector $(x,y)$ must be a linear combination of the given two.] 
 \item Suppose our astronaut Jimmy has 4 boosters (see Problem \ref{rocket booster problem}) that allow bidirectional movement in the directions $(1,1,2)$, $(0,1,3)$, $(2,1,1)$, and $(-2,1,0)$. Show that the span of these vectors is all of three dimensional space. Then select from these boosters a basis for $\mathbb{R}^3$. [You'll want to row reduce a matrix to answer this. Show the matrix and its rref.]
 \item If the 4th booster breaks, what kind of object is the span of the remaining three directions? Is it all of space, a plane, a line, a circle, a parallelogram, etc.?  Then state the dimension of and give a basis for the vector space obtained as the span of these three vectors.
\end{enumerate}
\end{problem}
%end 15

The set of vectors $(x,y)$ in the plane forms a vector space of dimension 2.  We know this because the vectors $(1,0)$ and $(0,1)$ are linearly independent and we can obtain any point $(x,y)$ in the plane as the linear combination $(1,0)x+(0,1)y$. This shows that the two vectors $(1,0)$ and $(0,1)$ form a basis for the set of vectors in the plane. We call this vector space $\mathbb{R}^2$.  

\begin{problem}
Read the preceding paragraph (if you have not already). For each vector space below, produce a collection of independent vectors (or functions) whose span is the space. You might need to rref a matrix and obtain a solution first. State the dimension of the vector space. 
\begin{enumerate}
 \item The set of vectors $(x,y,z)$ in space ($\mathbb{R}^3$). 
 \item \marginpar{Your work here generalizes to show that the kernel of any matrix is always a vector space.}% 
 The kernel of the matrix 
$A=\bvec{
1 & 1 & -1 & 0 \\
3 & -2 & 0 & -1
}$ from Problem \ref{partial fraction general solution}. 
 \item 
 The solutions to $B\vec x = 3\vec x$ for 
$
B=
\begin{bmatrix}
 3 & 0 & 0 \\
 0 & 2 & 1 \\
 0 & 1 & 2
\end{bmatrix}
$ from Problem \ref{First example of deficient eigenvalue}.
\item The solutions to $C\vec x = 3\vec x$ for  
$
C=
\begin{bmatrix}
 3 & 1 & 0 \\
 0 & 2 & 1 \\
 0 & 1 & 2
\end{bmatrix}
$ from Problem \ref{First example of deficient eigenvalue}.
\item (Challenge) All polynomials $a_0+a_1x+a_2x^2+a_3x^3$ of degree 3 or less. 
\end{enumerate}
You can present in class if you got the first four. 
\end{problem}

From the examples above, we see that the solutions to $A\vec x = \lambda \vec x$ form a vector space. This is easy to see when we realize that $A\vec x = \lambda\vec x$ is the same equation as $(A-\lambda I)\vec x =\vec 0$, which means that to find eigenvectors, we must find the kernel of $A-\lambda I$. Let's give a name to this vector space of eigenvectors.

\begin{definition}[Eigenspace]
 Let $\lambda$ be an eigenvalue of $A$.  The eigenspace of $A$ corresponding to $\lambda$ is the set of solutions to $A\vec x = \lambda \vec x$.  We write $E_A(\lambda)$ for the eigenspace of $A$ corresponding to $\lambda$. The geometric multiplicity of $\lambda$ is the dimension of $E_A(\lambda)$.  
\end{definition}





\section{Prep for Thursday June 13}


\begin{hw*}
 I'll add some HW Friday. For today, please focus on completing Tuesday's problems and problem 3.8.  Please start with problem 3.8 below (it's the new one), and then do the others. We did much of the work on 3.5-3.7 in class.  
\end{hw*}


\begin{problem}
 Complete problem 3.1 part 4, and problem 3.2 part 3.  
 \begin{enumerate}
  \item For 3.1 part 4, you need to solve 
$$\bvec{
1 & 1 & -1& 0 \\
-q &-p & 0 & -1\\
0 & 0 & 0 & 0\\
0 & 0 & 0 & 0
}\bvec{A\\B\\c\\d}=\bvec{0\\0\\0\\0},$$
where you write your solution in terms of the free variables.  
This is the same as finding the kernel of the coefficient matrix (and since it is square, this is equivalent to finding the eigenvectors corresponding to $\lambda = 0$).
\item For 3.2 part 3, you need to solve the system of equation $x_1+x_4-a-=0$, $x_1+x_2-c-d=0$, $x_2+x_3-e-f=0$, and $x_3+x_4-g-h=0$.  There 12 unknown, so you should have a 4 by 12 coefficient matrix with all 1's and $-1$'s in it (4 by 13 augmented matrix if you include the column of zeros on the right hand side).  Once you have this matrix set up, row reduce it and write each variable in terms of the free variables (in other words, find the kernel of the coefficient matrix $A$).  You should end up with a linear combination of 8 vectors, each vector is 12 components tall. Allysa has the solution to this one done already in the class presentations folder online.
\end{enumerate}

\end{problem}



\begin{problem}
 Complete problem 3.3.  
 
 For the first part, make sure you row reduce $\bvec{[cc|c]-1&2&x\\1&1&y}$ or give another explanation as to why we can write any vector $(x,y)$ as a linear combination of $(-1,1)$ and $(2,1)$ (there are lots of ways to show this).
 
 For the second part, Jimmy has 4 boosters, and we already showed via row reduction that the 3rd booster is a linear combination of the first 2. To get a basis, you need a collection of linearly independent vectors that span all of space. 
 
 For the third part, if the 4th booster breaks, what kind of object is the span of the remaining three directions? Explain why you know the span of the remaining 3 vectors is a plane, and hence 2 dimensional.  Make sure you pick two basis vectors from which you can obtain all three directions via linear combinations.

 \end{problem}


\begin{problem}
 Complete problem 3.4.   You'll want to start by going back up to that problem and reading it, as well as the paragraph before.
 
 To answer part 1, it's almost the same as the paragraph before problem 3.4 where we used $(1,0)$ and $(0,1)$ to span the plane. You need 3 vectors that span all of space.  The most common choice we often call the standard basis. 
 
 To answer part 2, row reduce 
$A=\bvec{
1 & 1 & -1 & 0 \\
3 & -2 & 0 & -1
}$ from Problem \ref{partial fraction general solution}. We basically did this in class on Tuesday, where the answer was all linear combinations of two vectors that are 4 tall.  This means a basis should have 2 vectors in it.  What are these vectors? What is the dimension of the kernel?

 We did part 3 in class on Monday as well.  This is equivalent to finding the eigenvectors corresponding to $\lambda =3$.  Please repeat this problem. You should have 2 free variables, which means 2 linearly independent eigenvectors. Most people miss the free variable $x_1$. Remember to give a basis and state the dimension
 
 Part 4 is similar to part 3. You need to give a basis and state the dimension of the space of eigenvectors corresponding to $\lambda=3$. 
 
 Part 5 is a challenge.  As a suggestion, here we are adding functions, not vectors.  Your basis elements are functions. How many functions are we computing a linear combination of?

\end{problem}



The new few problems will lead us to a method of computing the determinant of matrices that relies on row reduction rather than on a cofactor expansion. For large matrices, this algorithm is much faster.  The algorithm relies on understanding elementary matrices.
\begin{definition}
 An elementary matrix is a matrix formed by starting with the identity matrix and performing one row operation on the identity matrix.  Remember that there are three row operations, namely
 \begin{itemize}
  \item interchange two rows (type 1),
  \item multiply one row by a nonzero contant (type 2), and
  \item add a multiple of a row to another row (type 3).
 \end{itemize}
 For 3 by 3 matrices, some examples of elementary matrices are
$$
\bvec{
 0&1&0\\
 1&0&0\\
 0&0&1
}\text{ (type 1)},
\bvec{
 0&0&1\\
 0&1&0\\
 1&0&0
}\text{ (type 1)},
\bvec{
 1&0&0\\
 0&8&0\\
 0&0&1
}\text{ (type 2)},
\bvec{
 1&0&0\\
 0&1&0\\
 0&0&-7
}\text{ (type 2)},
$$
$$\bvec{
 1&0&0\\
 0&1&0\\
 3&0&1
}\text{ (type 3)},
\bvec{
 1&0&0\\
 0&1&0\\
 0&-2&1
}\text{ (type 3)},
\bvec{
 1&0&5\\
 0&1&0\\
 0&0&1
}\text{ (type 3)},
\bvec{
 1&0&0\\
 0&1&-4\\
 0&0&1
}\text{ (type 3)}.
$$
\end{definition}



\begin{problem}
Consider the matrix
$A=\begin{bmatrix}
1&2&3\\
0&-1&3\\
2&-4&0
\end{bmatrix}$.

\begin{enumerate}
 \item Let $E$ be an elementary matrix (use one of the 8 above). State the row operation used to obtain $E$. 
 Then compute the product $EA$ and describe what happened to $A$.
 \item Repeat the first part with several different examples of elementary matrices (at least one of each type).  With each elementary matrix $E$ you choose, remember to first state the row operation used to obtain $E$, and then describe how the product $EA$ changed $A$.  
 \item Make a conjecture about the relationship between $E$ and $EA$.
 \item Consider the two by two matrix $A=\bvec{1&2\\3&4}$. Let $E_1=\bvec{1&0\\-3&1}$, $E_2=\bvec{1&0\\0&-1/2}$, and  $E_3=\bvec{1&-2\\0&1}$.  What is the product $E_1A$? The product $E_2E_1A$? The product $E_3E_2E_1A$? 
\end{enumerate}
Did you notice the connection between row reduction of matrices and multiplying on the left by elementary matrices?
\end{problem}



Tara will be in class to direct what is happening. At the beginning of class, work on the following problems:
\begin{enumerate}
 \item Let $T$ be the linear transformation $T(x,y,z)=(x+3y+4z, -2x-2z,y+z,2x+y+3z)$ which I'll let you rewrite in the matrix form $T(\vec x)=A\vec x$. 
 \begin{itemize}
  \item 
 Give a basis and the dimension of the span of the columns of $A$.
\item 
 Then give a basis and dimension of the the kernel of $A$.
 \end{itemize}
 \item 
 For the matrix $A=\bvec{2&1&-2\\2&3&-4\\1&1&-1}$, the characteristic polynomial is $$\begin{vmatrix}2-\lambda&1&-2\\2&3-\lambda&-4\\1&1&-1-\lambda\end{vmatrix}=-(\lambda-1)^2(\lambda-2)$$ which means the eigenvalues are $\lambda=1$ and $\lambda=2$.  For each eigenvalue, find the dimension of the corresponding eigenspace by finding a basis for each eigenspace.
 \item Write down a 3 by 4 matrix $A$. Then construct a 3 by 3 elementary matrix $E$.  Compute the product $EA$. Do this several times, with different types of elementary matrices. 

\end{enumerate}



\section{Prep for Friday June 14}

\begin{hw*}
Complete the following problems in Schaum's Outlines.  Many of them have complete solutions already provided, so your job is to complete them on your own, and compare your work with what's provided.
\begin{enumerate} 
 \item Complete 4.18 on page 171%(vectors span r3)
 \item Complete 4.52 on page 179 %(vectors do not span r3)
 \item Complete 5.9  on page 196 %
 \item Complete 5.24 on page 203 %
\end{enumerate} 
\end{hw*}

You may want to start your preparation today by watching the two YouTube videos at 
\begin{itemize}
 \item \href{http://www.youtube.com/watch?v=rOMXjyf7WEw\&list=PLEC089DFB01EECCAD}{http://www.youtube.com/watch?v=rOMXjyf7WEw\&list=PLEC089DFB01EECCAD}.
\end{itemize}


\begin{problem}
 Last time we discovered that $EA$ is the same as performing row reduction on $A$.  How are the determinants of $A$ and $EA$ related? Pick a 3 by 3 matrix $A$ that has a nonzero determinant (you can pick any 3 by 3 matrix you want).  For each of the 8 elementary matrices $E$ listed in Definition 3.4, compute the determinant of $E$.  Then compute the product $EA$ and the determinant of $EA$.  Please use technology to speed this up.
\end{problem}

\begin{problem}
 Please head to the Sage worksheet 
 \begin{itemize}
  \item \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=elementary\_matrices}{http://bmw.byuimath.com/dokuwiki/doku.php?id=elementary\_matrices}.  
 \end{itemize}
 Your job is to explore the connection between the determinant of $A$ and the determinant of $EA$ until you can give a geometric reason as to why the following three facts are true.  
 \begin{enumerate}
  \item  If $E$ is formed by interchanging two rows, then we have $|EA|=-|A|$ (the sign changes),
  \item  If $E$ is formed by multiplying a row by a nonzero constant $k$, then $|EA|=k|A|$.
  \item  If $E$ is formed by adding a multiple of a row to another, then $|EA|=|A|$ (no change). To answer this one, look for parallel lines.
 \end{enumerate}
Come to class with a written explanation for each.

For the first part, there is only one matrix you can choose, namely $E=\bvec{0&1\\1&0}$.  For the second part, try using various matrices such as
$$E=\bvec{2&0\\0&1},
\bvec{3&0\\0&1},
\bvec{-4&0\\0&1},
\bvec{1&0\\0&2}.$$
For the third part, try using various matrices such as
$$E=\bvec{1&0\\1/2&1},
\bvec{1&0\\1&1},
\bvec{1&0\\3/2&1},
\bvec{1&0\\-2&1},$$ 
and then 
$$E=\bvec{1&1/2\\0&1},
\bvec{1&1\\0&1},
\bvec{1&3/2\\0&1},
\bvec{1&-2\\0&1}.$$

\end{problem}

\begin{problem}
Consider the three matrices 
$$A=\bvec{0&1&3\\2&4&6\\3&6&13}
E_1=\bvec{0&1&0\\1&0&0\\0&0&1}
E_2=\bvec{1/2&0&0\\0&1&0\\0&0&1}
E_3=\bvec{1&0&0\\0&1&0\\-3&0&1}
$$  
\begin{enumerate}
 \item What are the inverses of $E_1$, $E_2$, and $E_3$. 
 \item What are the products $B=E_1A$, and then $C=E_2E_1A$, and then $D=E_3E_2E_1A$? You should have a diagonal matrix $D$. 
 \item Since $D=E_3E_2E_1A$, solve for $A$ in terms of $D$ and the inverses of $E_1$, $E_2$, and $E_3$. 
 \item What is the determinant of $D$ (it's a diagonal matrix, so it should be easy to compute). What is the determinant of $A$? How are they related?
\end{enumerate}
\end{problem}



\begin{problem}
Write down a 4 by 4 matrix (with no zeros in it), and use technology to compute the determinant.  Make sure you get a matrix whose determinant is not zero. Then perform row reduction to reduce the matrix to the identity matrix, keeping track of each row operation. Use your row operations to write the identity matrix as a product of $A$ and bunch of elementary matrices (one for each row operation), so that $$I=E_n\cdots E_3E_2E_1A.$$ Then write $A$ as a product of elementary matrices, and state the determinant of $A$ by computing the determinants of each elementary matrix. 
\end{problem}

Tara will be in class to direct what is happening. For the in class group problems today, please work on the following:
\begin{enumerate}
 \item Write down a 3 by 3 matrix $A$.  Take turns creating an elementary matrix $E$ (apply one row operation to the identity matrix) and computing the product $EA$. Also compute $E^{-1}$, $|E|$, and $|EA|$.
 \item If we know that $ABC=I$ and we know $B^{-1}=\bvec{1&2\\3&4}$ and $C^{-1}=\bvec{2&-1\\3&2}$, then find $A$. In particular, explain why $A\neq B^{-1}C^{-1}$?
 \item Pick another 3 by 3 matrix $A$.  Row reduce the matrix (keeping track of each row operation). Then use your row reduction to find the determinant of $A$. 
 \item If there is extra time, end class by computing the determinants of 5 by 5 matrices by performing row reduction.
\end{enumerate}


\section{Prep for Monday June 17}

\section{Prep for Tuesday June 18}
\begin{hw*}
Complete the following problems in Schaum's Outlines. 
\begin{enumerate} 
 \item Complete 4.11 on page 168 %write a polynomial as a linear combo of other polynomials
 \item Complete 4.52 on page 179 %show that 3 polynomials span P2.
 \item Complete 5.9  on page 196 %Basis and dimensions of kernel.
\item Complete 3.82 on page 145 %Write A a a product of elementary matrices.
 \end{enumerate} 
\end{hw*}

Again, here's an outline
\begin{problem}[Fibonacci Numbers]
Please head to the following websites.  Your job for this problem follows: Define the Fibonacci sequence.  Explain a context in which the sequence would naturally appear. Then compute the 40th Fibonacci number. 
\begin{itemize}
 \item \href{http://etereaestudios.com/docs\_html/nbyn\_htm/nbyn\_mov\_youtube.htm}{http://etereaestudios.com/docs\_html/nbyn\_htm/nbyn\_mov\_youtube.htm}
 \item \href{http://library.thinkquest.org/27890/theSeries2.html}{http://library.thinkquest.org/27890/theSeries2.html}
 \item \href{http://www.mathsisfun.com/numbers/fibonacci-sequence.html}{http://www.mathsisfun.com/numbers/fibonacci-sequence.html}
\end{itemize}
\end{problem}



\begin{problem}\label{set up the Fibonacci problem}
 To find the next number in the Fibonacci sequence, we just have to add the two numbers before. We can write this as the rule $$x_{n+1}=x_n+x_{n-1}.$$ We call this rule a recurrence relation.
 Can we use matrices to help us understand this sequence? 
 \begin{enumerate}
  \item Express the recurrence relation in the form
  $$\bvec{x_{n}\\x_{n+1}}=\bvec{*&*\\ *&*}\bvec{x_{n-1}\\x_{n}}.$$
  \item Compute the eigenvalues of $A$.
  \item Find a basis for each eigenspace of $A$. In other words, for each eigenvalue, find a corresponding eigenvector. 
  \item State matrices $Q$ and $D$ so that $AQ=QD$. 
 \end{enumerate}
The Golden Ratio should have appeared as part of your work. Your matrix $A$ should contain three 1's in it, and one zero. [Hint: You know you're right if you get part 3 of the next problem.]
\end{problem}



\begin{problem}\label{recurrence relation example}
Consider the sequence of numbers given by the rule
$$x_{n+1}=2x_{n-1}-x_{n}
\Rightarrow 
\bvec{x_{n}\\x_{n+1}}=
\bvec{0&1\\ 2&-1}\bvec{x_{n-1}\\x_{n}}
,$$
where $x_0=0$ and $x_1=1$.  
Repeatedly applying matrix multiplication will get successive terms, which means 
\begin{align*}
\bvec{x_{1}\\x_{2}}=
\bvec{0&1\\ 2&-1}\bvec{x_{0}\\x_{1}}
\\
\bvec{x_{2}\\x_{3}}=
\bvec{0&1\\ 2&-1}^2\bvec{x_{0}\\x_{1}}
\\
\bvec{x_{3}\\x_{4}}=
\bvec{0&1\\ 2&-1}^3\bvec{x_{0}\\x_{1}}
\end{align*}
\begin{enumerate}
  \item Use this matrix power rule to compute $x_2$, $x_3$, $x_4$, and $x_5$. 
  \item The eigenvalues of $A$ are $\lambda = -2,1$ with corresponding eigenvectors $(-1,2)$ and $(1,1)$. We can hence write $AQ=QD$ using 
  $$\bvec{0&1\\ 2&-1}\bvec{-1&1\\ 2&1}=\bvec{-1&1\\ 2&1}\bvec{-2&0\\ 0&1}.$$
  We know that $A^n=QD^nQ^{-1}$ and we know that $\bvec{x_{n}\\x_{n+1}}=
A^n\bvec{x_{0}\\x_{1}}$.  Use this to explain why $x_n=\dfrac{1-(-2)^n}{3}$. [Hint: Compute $A^n\bvec{0\\1}$.] 
\item For the Fibonacci sequence we have 
$$\bvec{0&1\\ 1&1}\bvec{\frac{1-\sqrt5}{2}&\frac{1+\sqrt5}{2}\\ -1&-1}=\bvec{\frac{1-\sqrt5}{2}&\frac{1+\sqrt5}{2}\\ -1&-1}\bvec{\frac{1+\sqrt5}{2}&0\\ 0&\frac{1-\sqrt5}{2}}.$$
Obtain a formula for the $n$th Fibonacci number that involves powers of $\frac{1+\sqrt5}{2}$ and $\frac{1-\sqrt5}{2}$, and use your formula to compute the 40th Fibonacci number.
 \end{enumerate}
\end{problem}

We need to practice with the words span, vector space, dimension, and basis.  Please complete the next problem. 

\begin{problem}
The set of $2$ by $2$ matrices is a vector space. We can write any matrix as the linear combination
$$\bvec{a&b\\c&d} 
= 
a\bvec{1&0\\0&0}
+b\bvec{0&1\\0&0}
+c\bvec{0&0\\1&0}
+d\bvec{0&0\\0&1}
.
$$
\begin{enumerate}
 \item Are the matrices 
$$
 \bvec{1&1\\1&1}, 
 \bvec{0&1\\1&1}, 
 \bvec{1&0\\1&1}, 
 \bvec{1&1\\0&1}, 
$$
linearly independent or linearly dependent. 
 \item Show that the matrices
$$
 \bvec{1&2\\0&-1}, 
 \bvec{3&0\\1&1}, 
 \bvec{-2&4\\0&1}, 
 \bvec{-7&14\\2&10}. 
$$
are linearly dependent. Do these matrices span a vector space of dimension 2 or 3? From these matrices, give a basis for their span, and then write any matrix not in your basis as a linear combination of your basis vectors. [Hint: Think of each matrix as a column vector that is 4 tall.]
 \item What is the dimension of the vector space spanned by the matrices
$$
 \bvec{1&2\\3&-1}, 
 \bvec{2&4\\6&-2}, 
 \bvec{-3&-6\\-9&3}? 
$$
Explain.
\end{enumerate}

\end{problem}




\section{Prep for Thursday June 20}


 
 Once we have a collection of vectors in the kernel of a matrix, or a collection of eigenvectors corresponding to the same eigenvalue, the span of these vectors gives us an entire vector space full of vectors that will still be in the kernel. The next problem asks you to show why.
 
 Recall that the kernel of $A$ is the set of solutions $\vec x$ to $A\vec x = \vec 0$.  In set notation, we would write 
$$\ker A = \{\vec x \mid A\vec x=\vec 0\},$$
and read this as ``The kernel of $A$ equals the set of $\vec x$ such that $A\vec x = \vec 0$.''

\begin{problem}

Suppose that $\vec y$ and $\vec z$ are both in the kernel of a matrix $A$. Show that any linear combination of $\vec y$ and $\vec z$ is also in the kernel of $A$. In other words, show that $a\vec y+b\vec z$ is also in the kernel of $A$. 

[Hint: Why does $A\vec y=\vec 0$? What is $A\vec z$? Then compute $A(a\vec y+b\vec z)$ (distribute and simplify). Make sure you show each step of your work.]  
\end{problem}

Because of the previous problem, we say that the kernel is closed under linear combinations. We can't get out of the kernel by performing linear combinations of things that are in the kernel. This fact is true in any vector space. \begin{quote}
Any linear combination of vectors in a vector space will still be in the vector space. Vectors spaces are closed under linear combinations.   
\end{quote}
 
 
 

 
We've been using linear combinations to organize almost all our work.  
 \begin{itemize}
  \item The solutions to $A\vec x = \vec b$ are always a linear combination of some vectors.  
  \item The matrix product $A\vec x$ is a linear combination of the columns of $A$. 
  \item We can use the rref of a matrix to write each column as a linear combination of the pivot columns. 
  \item Once we have a basis for the kernel, every other solution is a linear combination of these basis vectors. 
  \item The list goes on.
 \end{itemize}
What we would like to do now is notice that many operations that you have used your entire life can be done either before or after a linear combination.  These operations preserve linear combinations.   This next problem has you explore this.
\begin{problem} Complete the following:\label{linear function examples}
\begin{enumerate}
 \item If we think of $A$ as a coordinate map $T(\vec x) = A\vec x$, then does $$A(c_1\vec x_1+c_2\vec x_2) = c_1A(\vec x_1)+c_2A(\vec x_2)?$$ Explain. (Your answer can be really short). This shows that a matrix coordinate transformation preserves linear combinations of vectors. 
 \item Explain why $\ds\frac{d}{dx}(c_1f_1(x)+c_2f_2(x)) = c_1\frac{d}{dx}(f_1)+c_2\frac{d}{dx}(f_2)$. What two differentiation rules are needed to explain why this is true?  Once you are finished, you'll have shown that the derivative operator preserves linear combinations of functions.
 \item Explain why $\ds \int_a^b c_1f_1+c_2f_2 dx = c_1\int_a^b f_1dx+c_2\int_a^b f_2dx$. Again, this shows that the integral operator preserves linear combinations of functions.
 \item Can you think of another operation that preserves linear combinations.
 %shift right, then shift up.
 %stretch right, then stretch up.
\end{enumerate}

\end{problem}

Each of the examples above provided an example of a function, operation, or transformation that preserved linear combinations. When this occurs, we can perform the linear combination either before or after we perform the operation.  Let's make a definition to isolate this pattern. 

\begin{definition}[Function, Transformation, Operator]
 A function $f$ has a domain $D$ and range $R$. The domain $D$ is the set of inputs to the function.  The range (or comdomain) is the set that we are mapping towards.\marginpar{The words function, transformation, and operator are all synonyms. We just typically use transformation to talk about functions when the domain is vectors, and operator to talk about functions when the domain is functions.  }%
\begin{itemize}
 \item When the domain $D$ is a collections of vectors, we'll often say that $f$ is a transformation of vectors and write $T(\vec x)$ instead of $f(x)$. An example is $T(\vec x)=A\vec x$ where $A$ is a matrix. 
 \item When the domain $D$ is a collection of functions, we'll often say that $f$ is an operator on functions and write $L(g)$ instead of $f(g)$. An example is $L(g)=\frac{d}{dx}g$ of $L(g) = \int_a^b gdx$.
\end{itemize}
\end{definition}
\begin{definition}[Linear function, Linear Transformation, Linear Operator]
 When the domain $D$ and range $R$ of a function (transformation, operator) are vector spaces (so we can perform linear combinations), then we say that the function $f$, transformation $T$, or operator $L$ is linear if it preserves linear combinations. This means that 
\begin{align*}
f(c_1x_1+c_2x_2) &= c_1f(x_1)+c_2g(x_2) \quad \text{or}\\
T(c_1\vec x_1+c_2\vec x_2) &= c_1T(\vec x_1)+c_2T(\vec x_2) \quad \text{or}\\
L(c_1 f_1+c_2 f_2) &= c_1L( f_1)+c_2L( f_2). 
\end{align*}
We can apply linear combinations either before or after we apply the function. 
\end{definition}

In problem \ref{linear function examples}, we showed that $T(\vec x)=A\vec x$ is a linear transformation and that the derivative and integral are linear operators. 
We can differentiate a sum by differentiating each piece separately (term-by-term differentiation) and we can pull constants out.  Similarly, we can integrate term-by-term, and pull constants come out.  These are precisely the key properties behind a linear function. 
\begin{quote}
If you ever find yourself saying, ``Just do each part individually,'' chances are pretty high that you are using linearity.  
\end{quote}

%end 25










%26
If $A$ is a matrix, then the product $A\vec x$ is a linear transformation.  We'll often write this as $T(\vec x) = A\vec x$. Do you remember Candice's treasure map?  Once she knew how to locate 2 linearly independent object on her map (the two trees), she could translate the entire map. Once we understand how the map transforms a basis for the domain, we understand the entire linear transformation.  

\begin{problem}
 Suppose that we have a linear transformation $T:\mathbb{R}^3\to \mathbb{R}^2$. Since we are mapping vectors from 3D to 2D, we could think of this as a way of portraying a three dimensional world on a flat 2D screen (so computer animation). 
 
 We've been told that $T(1,0,0) = (1,3)$, $T(0,1,0) = (-2,4)$, and that $T(1,1,1)=(3,1)$. 
\begin{enumerate}
 \item Show that $(1,0,0)$, $(0,1,0)$, and $(1,1,1)$ are a basis for $\mathbb{R}^3$. 
 \item Write $(0,0,1)$ as a linear combination of $(1,0,0)$, $(0,1,0)$, and $(1,1,1)$.
 \item Use the fact that $T$ is linear to compute $T(0,0,1)$. [Hint: You've already got 
 $(0,0,1) = c_1(1,0,0)+c_2(0,1,0)+c_3(1,1,1)$, so what is $T(c_1(1,0,0)+c_2(0,1,0)+c_3(1,1,1))$?]
 \item Since $(x,y,z) = (1,0,0)x+(0,1,0)y+(0,0,1)z$, and we know $T$ at each of these three vectors, compute $T(x,y,z)$. 
 \item Reorganize the previous part to state a matrix $A$ so that $$T(x,y,z)= A\pvec{x\\y\\z}.$$ 
% \item Find the kernel of the linear transformation $T$. Ask me in class to talk about what this means in terms of 3D animation.
\end{enumerate}
    
\end{problem}
%end 26



If we know that a map between two vector spaces is linear, then the problem before is a prototype that shows us how to obtain a matrix $A$ to represent the transformation. The kernel of this matrix is the same as the kernel of the linear transformation.  The word kernel  means ``the central or most important part of anything; essence; gist; core.''    Once we know the kernel of a linear transformation, we know quite a bit about the linear transformation. This next example connects the kernel to 3D animation.

\begin{problem}
 Consider the two matrices 
 $$
 A = \bvec{-1&0&0\\0&2&1\\0&1&2} 
 \quad\text{and}\quad 
 B = \bvec{-1&1&0\\0&2&4\\0&1&2} 
 $$
 \begin{enumerate}
  \item Click on this link to open the \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=3d_linear_transformations}{3D Linear Transformation Sage visual}. Evaluate the sage code for both matrix $A$ and matrix $B$ (I suggest having two tabs open, with one in each). 
  \item Compute the kernel of both matrices.  Show that the kernel of $A$ is a single point, but that the kernel of $B$ is one dimensional (give a basis for the kernel).
 \item Make a conjecture about the connection between the kernel of a matrix, and the Sage visual.
 \item Consider the matrix
  $$ C = \bvec{1&-2&3\\2&-4&6\\-3&6&-9} $$.  Type this matrix into the Sage visual. Use the visual to guess the dimension of the kernel.  Then find a basis for the kernel of $C$. 
  \end{enumerate}

\end{problem}











 
 
 
 
 








\section{Prep for Friday June 21}



\begin{hw*}
 I need you to practice the ideas we learned on Tuesday about recurrence relations. Please complete the following.
 \begin{enumerate}
  \item Complete Problem \ref{set up the Fibonacci problem}. Make sure you can show that $AQ=QD$ yields the equation
$$\bvec{0&1\\ 1&1}\bvec{\frac{1-\sqrt5}{2}&\frac{1+\sqrt5}{2}\\ -1&-1}=\bvec{\frac{1-\sqrt5}{2}&\frac{1+\sqrt5}{2}\\ -1&-1}\bvec{\frac{1+\sqrt5}{2}&0\\ 0&\frac{1-\sqrt5}{2}}.$$
  \item Complete parts 1 and 2 of Problem \ref{recurrence relation example}.
 \end{enumerate}
\end{hw*}



\begin{problem}
Sally and her friends Amanda and Mark have decided to go geocaching together.  They return to the corn field.  They are both currently standing at the origin (0,0).  The location of the treasure is at $(-7,12)$ hundred yards. A road runs through this corn field following the vector $(-1,1)$.  The rows of corn follow the vector $(2,1)$. The irrigation pipes follow the vector $(0,1)$.  
\begin{enumerate}
 \item Explain why the span of the three vectors $\vec v_1=(-1,1)$, $\vec v_2=(2,1)$, and $\vec v_3=(0,1)$ is the plane $\mathbb{R}^2$.
 \item Explain why these three vectors are not a basis for $\mathbb{R}^2$, but any pair of these two vectors is a basis for the plane.
 \item
 \marginpar{It's not a coincidence that we use $c_1$ and $c_2$  to stand for the first and second {\it c}oordinates.}%
 Sally decides to stick to the road and rows of corn. She does a quick matrix computation and discovers that the coordinates of the treasure relative to her vectors $\vec v_1$ and $\vec v_2$ are $31/3$ and $5/3$. This is because Sally computed the coordinates $c_1$ and $c_2$ in the linear combination equation $c_1\vec v_1+c_2\vec v_2=(-7,12)$ to be $c_1=31/3$ and $c_2=5/3$.
 
 Amanda decides to stick to the road and irrigation pipes. Mark decides to completely go off road and stick to the rows of corn and the irrigation pipes. Compute the coordinates of the treasure relative to Amanda's basis, and relative to Mark's basis. 
 \item We've already shown in the past that the matrix $A = \bvec{3&0&0\\ 0&2&1\\ 0&1&2}$ has eigenvectors $(1,0,0)$, $(0,1,1)$ and $(0,-1,1)$.  Show that these three vectors are a basis for $\mathbb{R}^3$ (are the independent), and then find the coordinates of the vector $(2,3,5)$ relative to this basis. 
\end{enumerate}
\end{problem}





We've been talking about vector spaces, spans, bases, dimension, and linear functions.  Recall that we defined a vector space as the span of some objects for which is makes sense to perform linear combinations. We showed before that the span of the polynomials $1$, $x$, and $x^2$ gives us all polynomials of the form $a+bx+cx^2$, which means the set of polynomials of degree 2 or less is a vector space. The next problem has you explore this idea a little more. 
\begin{problem}
Please read the preceding paragraph.  For each set below, show that the set is a vector space by showing that the set is the span of some collection of objects (name the objects). Obtain a basis for the vector space and state its dimension.
\begin{enumerate}
 \item The set $P_3$ of polynomials of degree 3 or less.
 \item The set $P_5$ of polynomials of degree 5 or less. 
 \item The set $M_{2,3}$ of 2 by 3 matrices. [Hint: Look at problem 3.16.]
 \item For the matrix $A = 
 \bvec{
 1&2&1&0&1\\
 1&2&2&1&3\\
 3&6&6&2&7\\
 2&4&1&-1&0
 }$, consider the set that is the span of the columns.  We call this set the  column space of $A$.
 \item Now consider the set of vectors in the kernel of $A$. 
 \item (Challenge) The set of all polynomials of any degree.
\end{enumerate}

\end{problem}




Now that we have practiced the language of vector spaces, bases, and dimension, let's focus on linear transformations.  Recall that we say a function is a linear transformation between vectors spaces if the function preserves linear combinations, namely you can apply the linear transformation either before, or after, you perform the linear combination. 
When we talk about linear transformations, there is almost always an underlying matrix that helps us perform this linear transformation.


\begin{problem}
 Each problem below is a linear transformation from one vector space to another.  Your job is to create an appropriate matrix to represent this linear transformation. All you'll need to do is ask, ``What does the transformation do to the standard basis vectors.''  As an example, reflection about the $x$-axis is a linear transformation $T$ such that $T(1,0)=(1,0)$ and $T(0,1)=(0,-1)$. Because $(x,y)=x(1,0)+y(0,1)$, we can write $T(x,y) = xT(1,0)+yT(0,-1) = x(1,0)+y(0,-1) = (x+0y,0x-y) = \bvec{1&0\\0&-1}\bvec{x\\y}$.  We now have our matrix.  
 \begin{enumerate}
  \item Obtain a matrix to represent the transformation that has $T(1,0) = (3,4)$ and $T(0,1)=(5,6)$. 
  \item Obtain a matrix to represent reflection about the $y$-axis.  
  \item Obtain a matrix to represent dilation by $2$ in the $x$ direction (so $T(1,0)=(2,0)$), and dilation by 3 in the $y$ direction. 
  \item Obtain a matrix that reflects objects in the plane about the line $y=x$. 
  \item Obtain a matrix that causes a 30 degree rotation about the origin. What if you wanted a 60 degree rotation?  [Hint, Ask yourself where the vector $(1,0)$ would be moved to if you rotated things 30 degrees counter clockwise.] 
 \end{enumerate}
\end{problem}





















\section{Prep for Monday June 24}

\begin{hw*}
\begin{enumerate}
 \item Complete Schaum's 5.70.  
 \item Please complete problem 3.21.  You should get the following answers.  (1) The first two vectors are independent, so they span the plane. (2) Since the third vector depends on the first two, the three are not linearly independent, hence not a basis.  However, any pair of them is linearly independent and spans the plane. (3)  Amanda's coordinates are $(7,5)$.  Mark's coordinates are $(-7/2,31/2)$. (4) Since $\bvec { 1 & 0 & 0 & 2 \\
 0 & 1 & -1 & 3 \\
 0 & 1 & 1 & 5 }
 \xrightarrow{rref}
 \bvec{
  1 & 0 & 0 & 2 \\
 0 & 1 & 0 & 4 \\
 0 & 0 & 1 & 1 
 }$, the coordinates are $(2,4,1)$. 
 \item Please complete problem 3.23. You should get the matrices 
 (1) $\bvec{3&5\\4&6}$,
 (2) $\bvec{-1&0\\0&1}$,
 (3) $\bvec{2&0\\0&3}$,
 (4) $\bvec{0&1\\1&0}$,
 (5) $\bvec{\cos(30)&-\sin(30)\\\sin(30)&\cos(30)}$,
\end{enumerate}
 
\end{hw*}


Not every function, transformation, or operator is linear. The next problem has you distinguish between a few examples.


\begin{problem}
 Complete the following. When a variable is not listed as part of the domain, we assume it is constant. 
\begin{enumerate}
 \item Show that $f(x)=ax^2$ is not linear ($a$ is a constant). [Does $f(c_1x_1+c_2x_2) = c_1f(x_1)+c_2f(x_2)$?]
 \item Show that $f(a)=ax^2$ is linear ($x$ is a constant). [Does $f(c_1a_1+c_2a_2) = c_1f(a_1)+c_2f(a_2)$?]
 \item Consider $f(x)=mx+b$. Show that $f$ is not a linear function of $x$. \marginpar{Wait! So $f(x)=mx+b$ is not linear? Ask me about this in class.}%
 \item Consider $f(m,b)=mx+b$.  Show that $f$ is a linear function of $m$ and $b$. 
[Does $f(c_1(m_1,b_1)+c_2(m_2,b_2)) = c_1f(m_1,b_1)+c_2f(m_2,b_2)$? Carefully explain each step of your computation.]
 \item \marginpar{This last examples explains why we use the phrase ``linear'' regression to find the coefficients of any degree polynomial that passes through some given data points.}%
Which do you think is linear, $f(x) = ax^2+bx+c$ or $f(a,b,c) = ax^2+bx+c$?
\end{enumerate}

\end{problem}
  

We'll be coming back to linear transformations all semester long. We've been using them all semester long without knowing the vocabulary. 
Almost all of our work up to this point in the semester has dealt with linear transformations between finite dimensional vector spaces. To get to modern applications of linear algebra, we need to learn to work with infinite dimensional linear transformations. 


\begin{problem}
Ashley and Tyrell are both out looking for the same treasure. They decide to work together and share the treasure when they find it.  They each have a treasure map, but each map is incomplete. In addition, the treasure maps were drawn by different people, with very different scales. When Ashely looks at her map, she notices that moving right one unit on her map results in following the GPS vector $(2,1)$. Similarly, moving up one on her map results in following the GPS vector $(-1,2)$.  For Tyrell, moving right 1 on his map has him follow the GPS vector $(3,-2)$, while moving up one has Tyrell following the GPS vector $(-2,-3)$. Our main goal on this problem is to find a way for Ashley and Tyrell to communicate, namely if Ashley notices something on her map with Ashley coordinates $(a,b)$, then what are the coordinates $(c,d)$ of that object on Tyrell's map? 
\begin{enumerate}
 \item Let's focus on Ashley's map first. Ashley notices a tree on her map located at the coordinates $(2,3)$. Explain why the GPS location of this tree is $\vec x = (1,8)$. 
 \item The vectors $(2,1)$ and $(-1,2)$ form a basis for $\mathbb{R}^2$. We could write this as $\mathscr{B} =\{(2,1),(-1,2)\}$. In the first part, we showed that the coordinates of $\vec x = (1,8)$ relative to this basis are $(2,3)_{\mathscr{B}}$, where the subscript after the vector $(2,3)$ just reminds us that these are coordinates relative to a particular basis. Show that we can write our work from part 1 in the form $B\bvec{2\\3}_{\mathscr{B}}=\bvec{1\\8}$ by stating the matrix $B$. We call this Ashley's coordinate matrix, since the GPS vector $(x,y)$ has coordinates $(a,b)_{\mathscr{B}}$ and the two are related via the equation $B\bvec{a\\b}_{\mathscr{B}}=\bvec{x\\y}$. 
 \item Tyrell's map uses a different basis, namely $\mathscr{C} = \{(3,-2),(-2,-3)\}$. State Tyrell's coordinate matrix $C$ so that the GPS vector $(x,y)$ has coordinates $(c,d)_{\mathscr{C}}$ where the two vectors satisfy  $C\bvec{c\\d}_{\mathscr{C}}=\bvec{x\\y}$. Use an inverse matrix to state the coordinates $(c,d)_{\mathscr{C}}$ of the GPS vector $(1,8)$ relative to Tyrell's basis.
 \item We now have two matrix equations $B\bvec{a\\b}_{\mathscr{B}}=\bvec{x\\y}$ and $C\bvec{c\\d}_{\mathscr{C}}=\bvec{x\\y}$. Why must we have 
 $$B\bvec{a\\b}_{\mathscr{B}}=C\bvec{c\\d}_{\mathscr{C}}?$$
 Use this to solve for $\bvec{c\\d}_{\mathscr{C}}$ in terms of $B$, $C^{-1}$, and $\bvec{a\\b}_{\mathscr{B}}$. 
 \item Ashley and Tyrell can now communicate. Part 1 told us that Ashley's coordinates $(2,3)_{\mathscr{B}}$ yielded the GPS location $(1,8)$.  Part 2 confirmed this with matrix multiplication. In part 3 you used an inverse matrix to get from $(1,8)$ to Tyrell's coordinates $(c,d)_{\mathscr{C}}$. In part 4, you combined this all together to give a quick formula for translating from Ashley's coordinates to Tyrell's. 
 
 Ashley notices that the next spot they need to be at on her map is at $(13,26)_{\mathscr{B}}$.  What point should Tyrell head to on his map?
\end{enumerate}
\end{problem}

\begin{definition}[Coordinates of a vector relative to a basis]
 If $\mathscr{B} = \{v_1,v_2,v_3,\ldots,v_n\}$ is an ordered basis for a vector space $V$, and $x = c_1v_1+c_2v_2+\cdots+c_nv_n$, then we call $(c_1,c_2,\ldots,c_n)$ the coordinates of $x$ relative to $\mathscr{B}$. We may write $[x]_{\mathscr{B}}=(c_1,c_2,\ldots,c_n)_{\mathscr{B}}$ to emphasize that the coordinates are relative to a basis, most often when there are multiple bases to consider. 
\end{definition}


We need some practice with the language of coordinates relative to a basis. 

\begin{problem}
 Complete the following:
 \begin{enumerate}
  \item 
 The coordinates of the polynomial $3+4x+x^2$ relative to the standard (ordered) basis $\mathscr{B}_1=\{1,x,x^2\}$ are $(3,4,1)$. 
 What are the coordinates of the polynomial $3+4x+x^2$ relative to the (ordered) basis $\mathscr{B}_2=\{x^2,x,1\}$?
  \item 
 What are the coordinates of the polynomial $3+4x+x^2$ relative to the basis $\mathscr{B}_3=\{x+x^2,2+3x,1-x^2\}$?
  \item 
 Consider the two bases $\mathscr{B}_1=\{1,x,x^2\}$ and $\mathscr{B}_3=\{x+x^2,2+3x,1-x^2\}$. The coordinates of a polynomial $p(x)$ relative to $\mathscr{B}_3$ are $(2,-1,3)_{\mathscr{B}_3}$. State the polynomial $p(x)$ and then find the coordinates of this polynomial relative to the standard basis $\mathscr{B}_1$.
  \item 
  Consider the two bases  $\mathscr{B}_3=\{x+x^2,2+3x,1-x^2\}$ and $\mathscr{B}_4=\{1,1+x,1+x+x^2\}$. The coordinates of a polynomial $p(x)$ relative to $\mathscr{B}_3$ are $(2,-1,3)_{\mathscr{B}_3}$ (the same polynomial as the last part). Find the coordinates of this polynomial relative to the basis $\mathscr{B}_4$.
 \end{enumerate}
\end{problem}


\begin{problem}
Consider the vector space $P_2(x)$, the set of polynomials of degree 2 or less, and the vector space $M_{2,2}$, the set of 2 by 2 matrices. Let's create a map $L$ from $P_2(x)$ to $M_{2,2}$ by writing $L(a+bx+cx^2)=\bvec{a-2b+7c&b-2c\\2a-b+8c&3a+2b+5c}$. 
\begin{enumerate}
 \item What are the coordinates of the polynomial $a+bx+cx^2$ relative to the standard basis $S=\{1, x, x^2\}$?  
 \item Similarly, what the the coordinates of $\bvec{a-2b+7c&b-2c\\2a-b+8c&3a+2b+5c}$ relative to the standard basis 
 $$T=\left\{\bvec{1&0\\0&0}, \bvec{0&1\\0&0}, \bvec{0&0\\1&0}, \bvec{0&0\\0&1}\right\}?$$
 \item What is a basis for the kernel of $L$? What is the dimension? [Hint: Remember to be in the kernel, we want the polynomials that map to the zero matrix. You should end up with four equations with three unknowns, and then need to row reduce a matrix.]
 \item The images of the three basis polynomials are $L(1) = \bvec{1&0\\2&3}$, $L(x) = \bvec{-2&1\\-1&2}$, and $L(x^2)=\bvec{7&-2\\8&5}$. If we write these equations by expressing each vector using its coordinates, then we have 
 $$L(1,0,0)_S = (1,0,2,3)_T, \quad L(0,1,0)_S = (-2,1,-1,2)_T,\quad L(0,0,1)_S=(7,-2,8,5)_T.$$
 Find a matrix $A$ so that we can multiply $A$ on the right by the coordinates of a polynomial $a+bx+cx^2$ and get out the coordinates of $L(a+bx+cx^2)$, namely find $A$ so that 
 $$A[a+bx+cx^2]_S=\left[\bvec{a-2b+7c&b-2c\\2a-b+8c&3a+2b+5c}\right]_T\quad\Rightarrow\quad A\bvec{a\\b\\c}_S = \bvec{a-2b+7c\\b-2c\\2a-b+8c\\3a+2b+5c}_T.$$
 [Hint: You should have seen this matrix when you were finding the kernel of the transformation.]
\end{enumerate}
\end{problem}





\section{Prep for Tuesday June 25}

\begin{hw*}
Complete the following:
\begin{enumerate}
%dimension and basis of a subspace of polynomials.
 \item Schaum's 5.67 on page 217.  
 \item Schaum's 6.22 on page 240.
 \item Schaum's 6.25 on page 240. 
\end{enumerate}
\end{hw*}



We've been using the words vector space to talk about the span of a collection of vectors. Let's see if we can identify some key properties of vector spaces. We'll use these properties to carefully define a vector space using axioms at some point.
\begin{problem}
 Let $V$ be the set of real valued functions $y = f (x)$ defined on the entire real number line. Define
vector addition as function addition $(f +g)(x) = f (x)+g(x)$, and scalar multiplication as $(cf )(x) =
c(f (x))$.  In other words, the set $V$ is just any possible function you could define on the entire real line (so $e^x$,  $\sin x$, $\cos x$, $x$, $x^{1/3}$, etc.). 
\begin{enumerate}
 \item Is the sum of two function another function?
 \item If you times a function by a constant, do you get another function?
 \item Is function addition associative? (What does this mean?)
 \item Is function addition commutative? (What does this mean?)
 \item Is there a zero function $0$ such that $f(x)+0=0+f(x)=0$? In other words, is there an additive identity?  What is this function (namely state $i(x)=?$ for each $x$).
 \item Does every function have an additive inverse, i.e. if $f(x)$ is a function, is there a function $h(x)$ such that $f(x)+h(x)=0$?  What is this function  $h(x)$?
 \item Does scalar multiplication distribute across function addition (i.e. does $c(f(x)+g(x))=cf(x)+cg(x)$)?
 \item Does scalar multiplication distribute across scalar addition (i.e. does $(c+d)f(x)=cf(x)+df(x)$)?
 \item Is scalar multiplication associative? (What does this mean?)
 \item Does scalar multiplication by 1 do nothing, i.e. does $1f(x)=f(x)$?
 \item Is $V$ the span of some functions (hence a vector space)? What functions should we use so that their span is $V$?
\end{enumerate}
Parts 1-10 above are called the vector space axioms. If 1-10 hold, then 11 holds as well. 
\end{problem}

Suppose we have two bases $\mathscr{B}$ and $\mathscr{C}$, with coordinate matrices $B$ and $C$.  If $\vec v$ is a vector and $[\vec v]_\mathscr{B}$ and $[\vec v]_\mathscr{C}$ are the coordinates of $\vec v$ relative to these two bases, then last time we showed that 
$$B[\vec v]_\mathscr{B} = C[\vec v]_\mathscr{C}. $$  
Hence, if we know either 
$[\vec v]_\mathscr{B}$ or $[\vec v]_\mathscr{C}$, then we can use equations 
$$[\vec v]_\mathscr{B} = B^{-1}C[\vec v]_\mathscr{C}
\quad\text{and}\quad 
C^{-1}B[\vec v]_\mathscr{B} = [\vec v]_\mathscr{C}
$$  
to get from on coordinate system to the other. This allows us to quickly translate between coordinates.  The matrices $C^{-1}B$ and $B^{-1}C$ are called change of basis matrices.  
\begin{problem}
 Consider the three bases $R = \{(1,0,0), (1,1,1) , (1,1,0)\}$, $S=\{(2,1,0),(-1,2,3),(0,2,-1)\}$, and $T = \{(0,1,2),(1,0,3),(1,4,0)\}$. 
 \begin{enumerate}
  \item The basis $R$ has coordinate matrix $A = \bvec{1&1&1\\0&1&1\\0&1&0}$.  For the other two bases, obtain a coordinate matrix and call them $B$ and $C$. 
  \item The coordinates $(2,-1,3)_R$ represents the vector $A(2,-1,3)_R = (4,2,-1)$. What vectors do $(2,-1,3)_S$ and $(2,-1,3)_T$ represent? 
  \item Nathan, Kenna, and Naomi all plan to meet in space at the position $\vec x = (10,2,-4)$.  However, they all have different computer systems aboard their space ships.  Nathan's ship uses the basis $R$ for giving direction, Kenna's uses the basis $S$, and Naomi's uses the basis $T$.  Find the coordinates of $\vec x$ relative to each basis. (If you get Kenna's coordinates as $[(10,2,-4)]_S=(74/17, -(22/17), 2/17)_S$, then you're on the right track.)
  \item After the rendezvous at $(10,2,-4)$, Nathan has to leave.  Kenna tells Naomi about a cool space restaurant at $(-4,12,7)_S$ and they plan to meet up again in a few hours.  What are the coordinates of this restaurant relative to Naomi's basis? What is the change of basis matrix you used?
 \end{enumerate}
\end{problem}



\begin{problem}
Consider the set of functions $S=\{e^{5t}, te^{5t}, t^2e^{5t}\}$.  These three functions form a basis for a three dimensional subspace of the vector space of all differentiable functions.
\begin{enumerate}
 \item What are the coordinates of $f(t) = ae^{5t}+bte^{5t}+ct^2e^{5t}$ relative to $S$?
 \item What is the derivative of $f(t) = ae^{5t}+bte^{5t}+ct^2e^{5t}$?  What are the coordinates of $f'(t)$ relative to $S$?
 \item The derivative is a linear transformation between vector spaces (it preserves linear combinations).  Because the space spanned by $S$ is 3 dimensional, we should be able to find a 3 by 3 matrix so we can write $[f'(t)]_S = A[f(t)]_S$.  In other words, we want a matrix $A$ so that after you give me the coordinates of a function relative to $S$, you can find the coordinates of the derivative by just multiplying by $A$.  What is the matrix $A$.
 \item (Challenge) What is the inverse of $A$.  Use your answer to compute the integral of $f_1(t)=e^{5t}$, $f_2(t)=te^{5t}$ and $f_3(t)=t^2e^{5t}$. You can check if you are correct by performing integration by parts. 
\end{enumerate}
\end{problem}





\begin{problem}
 Recall that we say a function is linear if it preserves linear combinations, namely that $f(c_1x_1+c_2x_2) = c_1f(x_1)+c_2f(x_2)$.  Consider the function $G(x,y) = (2x+3y,x-4y)$.  Carefully show that this function is linear.  
 
 To get you started, you might want to let $x_1 = (x,y)$ and $x_2=(u,v)$. Then you need to show that
 $$G(c_1(x,y)+c_2(u,v)) = c_1G(x,y)+c_2G(u,v).$$
 You'll need to start with the left hand side above, simplify the part inside the function $G$ to $(c_1x+c_2u,c_1y+c_2v)$, and then apply $G$. If you are completely stuck, try reading example 4.9 on page 102 of the \href{\onlinetext}{online text}.
\end{problem}





\section{Prep for Thursday June 27}

\begin{hw*}
 Complete the following:
 \begin{enumerate}
  \item Schaum's 6.30 and 6.31 on page 241.  Don't worry if you get the language backwards (just make sure you can find both matrices).  The language ``from $S$ to $S'$'' is interpreted differently by different groups.  The key question is, ``Can you get the two matrices that allow you to convert between coordinate systems?''
  \item Schaum's 9.7 (page 340) and 9.29 (page 350).  
 \end{enumerate}
\end{hw*}




\begin{problem}
Consider the linear transformation $L(x,y) = (2x+3y,5x+4y)$.  Consider the bases $S=\{(1,0),(0,1)\}$ and $T=\{(1,2),(1,3)\}$.
\begin{enumerate}
 \item Let $\vec x=(x,y)$. Obtain a matrix $A$ so that $L(\vec x)=A\vec x$. This matrix $A$ is often called the standard matrix representation of $L$.
 \item What is the coordinate matrix $B$ so that $B[(x,y)]_T=(x,y)$ where $[(x,y)]_T = (c_1,c_2)_T$? Use this matrix to explain why the coordinates of $\vec x = (x,y)$ relative to $T$ are $[\vec x ]_T = (3x-y,-2x+y)_T$ and the coordinates of $L(\vec x )$ relative to $T$ are $[L(\vec x)]_T=(x+5y,x-2y)_T$.
 \item Compute $L(1,2)$ and $L(1,3)$. Show that the coordinates of $L(1,2)$ relative to $T$ are $[L(1,2)]_T=(11,-3)_T$. Also find $[L(1,3)]_T$.
 \item The matrix $A$ maps vectors to vectors (or coordinates relative to $S$ to coordinates relative to $S$).  We currently know that $L(\vec x ) = A\vec x$.  However, we also know that we can swap from standard coordinates to coordinates relative to $T$ using $B[\vec x]_T=\vec x$.  Explain why 
 $$B[L(\vec x)]_T = AB[\vec x]_T\quad \Rightarrow \quad [L(\vec x)]_T =B^{-1}AB[\vec x]_T.$$ 
 \item Compute the matrix product $B^{-1}AB$. We call this the matrix representation of $L$ relative to $T$ and write $[L]_T = B^{-1}AB$ where $A$ is the standard representation, and $B$ is the coordinate matrix for $T$.
\end{enumerate}
Did you see any common answers on your work above? Can you explain why part 3 and part 5 have very similar answers?
\end{problem}



\begin{problem}
Consider again the linear transformation $L(x,y) = (2x+3y,5x+4y)$.  We already know that the standard matrix representation of $L$ is $A = \bvec{2&3//5&4}$. By selecting a different basis, how simple can we make the matrix representation relative to our basis?  Recall that $[L]_T = B^{-1}AB$ where $B$ is the coordinate matrix of the basis.  Let's look at some examples.
\begin{enumerate}
 \item Let $T=\{(2,1),(-1,2)\}$.  Compute $[L]_T$. 
 \item Let $T=\{(1,0),(3,-3)\}$.  Compute $[L]_T$. 
 \item Let $T=\{(1,2),(3,5)\}$.  Compute $[L]_T$. 
 \item Let $T=\{(3,5),(-1,1)\}$.  Compute $[L]_T$. 
 \item Which of the bases above results in the simplest matrix $[L]_T$?
 \item What role do eigenvalues and eigenvectors play in this problem? Compute them, and then give an answer. 
\end{enumerate}

\end{problem}




\begin{problem}
 Consider the set $P_3(x)$ of polynomials of degree 3 or less.  Consider the function $D(a+bx+cx^2+dx^3) = b+2cx+3dx^2$.
 \begin{enumerate}
  \item Let's focus on the standard basis for $P_3(x)$ given by $S=\{1,x,x^2,x^3\}$.  For each function in this basis, compute $D(p(x))$ and state the coordinates of $D(p(x))$ relative to $S$. Notationally we write $D(p(x))$ and $[D(p(x))]_S$. For example the 3rd basis function gives $D(x^2) =2x$ which has coordinates $[D(x^2)]_S=(0,2,0,0)_S$ since $2x = 0(1)+2(x)+0(x^2)+0(x^3)$.  
  \item Obtain a 4 by 4 matrix $A$ so that $A[p(x)]_S = [D(p(x))]_S$. We call $A$ the matrix representation of $D$ relative to $S$ and write $[D]_S$. Recall that we use the notation $[\ ]_S$ to talk about coordinates relative to a basis. With this notation, we have $[D]_S[p(x)]_S = [D(p(x))]_S$. 
  \item Now let's use a different basis, namely $T=\{1,x,\frac{1}{2}x^2,\frac{1}{6}x^3\}$. Using this basis, explain why
  $$\bvec{0&1&0&0\\0&0&1&0\\0&0&0&1\\0&0&0&0}[p(x)]_T=[D(p(x))]_T.$$ The 4 by 4 matrix above is $[D]_T$, the matrix representation of $D$ relative to $T$. 
  \item To change from basis $S$ to basis $T$, explain why $B[p(x)]_T = [p(x)]_S$ where $B=\bvec{1&0&0&0\\0&1&0&0\\0&0&1/2&0\\0&0&0&1/6}$. Then show that $[D]_T =B^{-1}[D]_SB$.  
  \item If we wanted to focus on polynomials of degree 6 or less, then we could still use $D$ to represent the derivative transformation. 
  If we let $S=\{1,x,x^2,x^3,x^4,x^5,x^6\}$ and $T=\{1,x,\frac{1}{2!}x^2,\frac{1}{3!}x^3,\frac{1}{4!}x^4,\frac{1}{5!}x^5,\frac{1}{6!}x^6\}$, then what are $[D]_S$ and $[D]_T$?  
 \end{enumerate}

\end{problem}







\begin{problem}
 Let's practice making sure we can show a function (map, operator, transformation) is linear by using the definition of linear.  Remember, you must show that the function preserves linear combinations. 
 \begin{enumerate}
  \item Show that $f(m,b) = mx+b$ is a linear transformation. Assume that $x$ is a constant.
  \item Show that the derivative is a linear operator. 
  \item Show that $G(x,y) = (3x+2y,x-y)$ is linear.
 \end{enumerate}
\end{problem}



\section{Prep for Friday June 28}

\begin{hw*}
 Sorry these are here so late. The following problems are not required (I will not ask you to report that you've done these), but you'll find that these problems are a great review of the things that we've done. You'll want to make sure you complete these problems before you take the test.
 \begin{enumerate}
  \item Schaum's 9.9 on page 341, as well as 9.20 and 9.33 (These review all the matrix derivative problems.) 
  \item Schaum's 9.11 on page 342 and 9.36. (These review finding a matrix relative to a basis, and the $B^{-1}AB$ idea.) 
  \item Schaum's 9.30-32 are great as well. They ask you to find matrix representations of a linear transformation relative to different bases. 
 \end{enumerate}
\end{hw*}

We'll be reviewing for the exam.  My best guess as to what we'll do for prep is to have you finish all the problems in Schaum's that you have not yet done. In the wiki, I'll ask you to tell me which problems you would like to share, and ask questions on the ones that you do not feel like you have down.  Then we'll use class time to let you all share.


\subsection*{Main Outcomes from the 35 Problems}
We've covered a lot of ideas this chapter.  Here is a summary of what each problem has asked you to do.  Can you summarize this to 10 or so key ideas?  Those are the ideas you'll find on the exam.
\begin{enumerate}
 \item Solve infinitely many partial fraction decomposition problems all at once by finding the kernel of a matrix.
 \item Solve infinitely many traffic flow problems all at once by finding the kernel of a matrix.
 \item Use the words span, basis, and dimension to talk about Sally in rows of corn and Jimmy in space.
 \item Obtain a basis for space, the kernel, and eigenspaces.  State the dimension of the corresponding vector space.
 \item Repeat 1 and 2
 \item Repeat 3
 \item Repeat 4
 \item Show that $EA$ is the same as row reduction where $E$ is an elementary matrix.
 \item Show that $|EA| = |E||A|$, namely the determinant of a product of $E$ and $A$ is the same as the product of the determinants.
 \item Explain visually why the previous fact is true.
 \item If you row reduce a matrix to a diagonal matrix and keep track of the row operations, you can quickly compute the determinant of $A$. 
 \item Show how to write a matrix as a product of elementary matrix. From this you can also quickly deduce the determinant.
 \item Define the Fibonacci numbers
 \item Show how to write a recursive sequence as a matrix product, and then obtain $Q$ and $D$ in $AQ=QD$. 
 \item Using a simpler setup than the Fibonacci numbers, obtain a quick formula for the $n$th term in sequence that does not require you to compute all the numbers before it. The example I gave you here has some nice eigenvalues and eigenvectors. The key was that $A^n=QD^nQ^{-1}$.  You'll see this same idea show up again near the end of this chapter.
 \item How do you show that matrices are linearly independent (swap them to tall vectors, and then do what we've done all semester). Use this to determine the dimension of the span of a collection of matrices.
 \item Show that any linear combination of things in the kernel is still in the kernel.  In other words, the span of the kernel is itself (which means its a vector space).
 \item Show that matrix multiplication, differentiation, and integration, all preserve linear combinations.  This was our introduction to linear maps.
 \item Show how to obtain a matrix $A$ to represent a linear transformation.  The key is to figure out what $T$ does to the basis vectors $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$. 
 \item The dimension of the kernel is the size of the space that gets squashed out of a problem. If the kernel has dimension zero, then nothing gets squashed out.  If the kernel has dimension 1, then one dimension gets flattened (which is why the 3D object got flattened to a plane).  If the kernel has dimension 2, then two dimensions get flattened (which is why the 3D object got flattened to a line).
 \item Write the coordinates of a position relative to a basis. We did this in the context of geocaching. 
 \item Obtain a basis for a vector space, and state the dimension of the space. We looked at sets of polynomials, sets of matrices, the span of a the columns of a matrix, and the kernel of a matrix.
 \item Obtain a matrix to represent some common operations done in highschool algebra.  The include reflecting about an axis, reflecting about a line, dilating in the $x$ and/or $y$ direction, and rotating an object. 
 \item Show that some functions are linear, while some are not.  This requires that you become comfortable working with a definition.
 \item How you take Ashley's coordinates on her map, and translate them to Tyrell's coordinates on his map.  The key equation is $B[\vec v]_A = C[\vec v]_T$, where $B$ and $C$ contain the basis vectors in their columns.
 \item Write the coordinates of polynomials relative to the standard basis and other bases. Given the coordinates of a polynomial relative to one basis, find the coordinates relative to another basis.  This is the same as the previous problem, except we are now talking about polynomials instead of location of treasure.  When it comes to satellite communication and JPEG compression, these are functions are the treasure!
 \item We created a map from polynomials to matrices. This is the same as making a map from 3D to 4D if you start by just writing each polynomial as a vector $(a,b,c)$, and each matrix as a vector $(x,y,z,w)$.  Then we are just trying to find a 4 by 3 matrix.  The kernel of this matrix tells us which polynomials are in the kernel.
 \item We discussed the 10 axioms of a vector space.  If the 11th part of this problem holds, so do the first 10 parts.  We defined vector spaces as the span of some object. We'll stick with this definition.  With this problem, I just wanted you to see what the 10 axioms of a vector space are.  If you pursue graduate study in math, you'll see these axioms again.
 \item Given coordinates, how do you find a location?  Given a location, how do you find coordinates? Given coordinates relative to Kenna, how do you find Naomi's coordinates?  Again, the key is the equation $B[\vec v]_S = C[\vec v]_T$. 
 \item The derivative is a linear transformation, so we should be able to represent it with a matrix. The key is to start by writing each object in our vector space in terms of its coordinates.  Then we don't have to think about the functions anymore. The derivative of $(a,b,c)$ is $(5a,a+5b,2b+5c)$.  More importantly, the derivative of $(1,0,0)$ is $(5,0,0)$, the derivative of $(1,5,0)$, and the derivative of $(0,0,1)$ is $(0,2,5)$.  These three vectors are the columns of our matrix (relative to the given basis). Amanda will show us how to do this.
 \item How do you show something is linear?  Use the definition. We need to practice this.
 \item Show how to obtain a matrix representation of a linear transformation relative to another basis. 
 \item Use previous examples to study differentiation (a linear transformation) of polynomials. The right basis makes the matrix really simple. The right basis is the basis you see showing up in Math 114 when you study Taylor series. There's a lot more connections we could make.
 \item Find the matrix representation of a linear transformation relative to a basis.  You should find that if we use eigenvalues and eigenvectors, then the matrix is diagonal.  We just use the key equation $B^{-1}AB$. Do this 4 times.  Does this look like what we did near the beginning of the chapter?  Our key goal in this chapter was to learn how to work with different bases, and understand linear transformations.  The key equations show up all throughout.  
 \item Show something is linear.  We need to practice this. 
\end{enumerate}


Here's a summary of my list of big ideas.  (1) What's a kernel? (2) Correctly use the words span, basis, and dimension. (3) Use elementary matrices to find determinants and write a matrix as a product of elementary matrices. (4) Use eigenvalues and eigenvectors to find formulas for sequences defined recursively. (5) Show that matrices, polynomials, functions, etc. are linearly independent. (6) What does it mean to be linear? (7) How do you find coordinates of a vector relative to a basis? (8) How do you change from coordinates relative to one basis to coordinates relative to another basis? (9) How do you obtain the standard matrix for representing a linear transformation? (10) How do you obtain a matrix representation of a linear transformation relative to a basis, and how are eigenvalues/eigenvectors related to this? (11) Be able to work with polynomials, matrices, and functions, instead of just vectors, to do all of the above. 



\chapter{Fun Applications}
In this chapter we'll pull together everything we have learned, and use the language of linear algebra to tackle some fun applications. On Monday, we'll discuss some of these ideas and decide which ones we want to focus our time on.  Your project for this block is to write a document that you could use to share these ideas with a high school audience.  We'll use the full language of linear algebra as we discuss these ideas.  Your project will be to translate these ideas into words that would make sense to a high school audience.

Here are some of the ideas.  We won't have time to explore them all.  Which are the most interesting to you?  Which do you think students will prefer?
\begin{itemize}
 \item Making money with a bakery (lemonade stand or any business). We'll learn how to maximize profit subject to physical limitations such as money and labor. (Inequalities, Linear Programming, Level Curves, Gradients, The Second Derivative Test, Lagrange Multipliers.)
 \item How do we send information via radio waves? Why does my car open when I click the button on my key chain? What's the difference between analog and digital TV? How do they jam communications in spy movies? Could I build my own jammer? What does the FCC notice you see on almost every electronic device mean? (The cross product, orthogonal bases, revisit projections and linear regression, inner products on infinite dimensional vector spaces, Fourier series, and more.)
 \item What's the difference between a RAW camera file and a JPEG.  Why are JPEG's so much smaller, and how does this compression work? Why can we fit 100+ MP3's in the same space as 1 CD audio file?  (Generalize Fourier series.  Learn about the Fast Fourier Transform and the Discrete Cosine Transform. Study the Singular Value Decomposition (SVD), Apply it to satellite and long range probe communications.)
 \item Using vectors to determine movie preferences (usable for your own personal library) and web advertising preferences (to make money as a business on the web). (Projections, Fast computation of Eigenvalues/Eigenvectors, QR decomposition, Grahm Schmidt Orthogonalization process...) 
 \item Chronological ordering of graves...
\end{itemize}



\section{Prep for Monday July 1}

\begin{hw*}
 Complete Schaum's 11.12 on page 415 and 11.22 on page 421. These have to do with obtaining a basis that diagonalizes a linear transformation.   
\end{hw*}

%First
When to vectors are orthogonal, their dot product is zero.  We're going to use this fact to start selecting bases that will make many of our computations really quick. We're going to be working with infinite dimensional vector spaces, and adding up infinitely many things. If we know that most of the vectors are orthogonal, then we'll be able to simplify a ton of computations (reducing infinitely many down to a single computation).  We'll soon see that this is directly related to radio communication.
\begin{problem}
 Recall that we say two vectors are orthogonal if their dot product is zero.  
 In 2D and 3D, this means the vectors meet at a 90$^\circ$ angle. Lots of simplifications happen when vectors are orthogonal.
 \begin{enumerate}
  \item Consider the vectors $\vec v_1=(1,1,1)$, $\vec v_2 = (-3,1,2)$, $\vec v_3 = (0,2,-1)$, and $(4,0,6)$. Which pairs of vectors are orthogonal (there are 6 pairs to check).
  \item To find the best line to fit the data $(2,3)$, $(1,4)$, $(-3,9)$, we need to solve the matrix equation $A^TA\vec x = A^T\vec b$, where $A=\bvec{1&2\\1&1\\1&-3}$ and $\vec b = \bvec{3\\4\\9}$. Compute $A^TA$ and $A^T\vec b$, and then solve for $\vec x$.
  \item Let $A$ be any matrix of any size.  If the columns of $A$ are pairwise orthogonal, make a conjecture about what the product $A^TA$ will be. Create a 4 by 3 matrix whose columns are pairwise orthogonal, and then compute $A^TA$.
 \end{enumerate}
\end{problem}



%Second
The previous problem showed that orthogonal vectors can greatly simplify computations. Is there a simple way to find vectors that are orthogonal to some given vectors?  The answer is yes, and we've been doing this all semester long when we find the kernel.
\begin{problem}
Complete the following:
\begin{enumerate}
 \item If we want to find all vectors $(x,y)$ that are orthogonal to $(3,4)$, then we need to solve $(3,4)\cdot (x,y) = 0$.  This means we need to solve $$\bvec{3&4}\bvec{x\\y}=\bvec 0,$$ which is the same as finding the kernel of $\bvec{3&4}$.  Find a basis for the kernel of $\bvec{3&4}$. 
 \item Generalize the previous part to find all vectors that are orthogonal to $(a,b)$.  You should be able to show that a basis for the set of vectors that are orthogonal to $(a,b)$ is the vector $(-b,a)$. [What does this have to do with the slopes of perpendicular lines?]
 \item If we want to find a vector in 3D that is orthogonal to both $(a,b,c)$ and $(d,e,f)$, explain why we need to solve the matrix equation
 $$\bvec{a&b&c\\d&e&f}\bvec{x\\y\\z}=\bvec{0\\0}.$$
 Row reduce this matrix (multiply the top row by $d$ and the bottom row by $a$ to start with, and then subtract row 1 from row 2). 
 \item Obtain a basis for the set of vectors that are orthogonal to both $(a,b,c)$ and $(d,e,f)$. If you pick a vector that does not have fractions, you should obtain $(bf-ce,cd-af, ae-bd)$.  This vector is called the cross product of $(a,b,c)$ and $(d,e,f)$.  
\end{enumerate} 
\end{problem}

Make sure you ask me in class to talk about the connection between the length of the cross product and the area of the parallelogram formed using the two vectors.  It's another pretty cool application, and we can use determinants to access it all.

%Third
Radio waves are sent using linear combinations of sines and cosines. How do we know if two functions are orthogonal? We have a way to determine if two vectors are orthogonal, but we don't (yet) have a way to determine if two functions are orthogonal. Fourier originally discovered these ideas while studying cannons and how to prevent them from exploding on the men firing the cannon. Napolean hired Fourier to study the spread of heat and its connection to cannons.  Because of Napolean's war and Fourier's work in relation to cannons, today we have radio communication, digital cameras, and a whole lot more. It's not uncommon to find that the source of new technology began as a result of military intelligence during a war. My wife recently had me read a short story (5 minutes) that's relate to this idea.  It's a fun read at \href{http://www.tor.com/stories/2011/08/wikihistory}{http://www.tor.com/stories/2011/08/wikihistory}.

\begin{problem}
How could we define the dot product of two functions? This problem has you make a conjecture. Please answer the following:  
\begin{enumerate}
 \item The dot product of $(u_1,u_2,u_3)$ and $(v_1,v_2,v_3)$ is $u_1v_1+u_2v_2+u_3v_3$.  What is the dot product of $(u_1,u_2,u_3, u_4, \ldots, u_{10})$ and $(v_1,v_2,v_3, v_4,\ldots, v_{10})$?
 \item Write a sentence (using words, instead of notation) that explains how to compute the dot product of the two vectors $(u_1,u_2,u_3, u_4, \ldots, u_{10})$ and $(v_1,v_2,v_3, v_4,\ldots, v_{10})$.
 \item Use summation notation to express the dot product of $(u_1,u_2,u_3, u_4, \ldots, u_n)$ and $(v_1,v_2,v_3, v_4,\ldots, v_n)$.  
 \item The functions $f(x) = x^2$ and $g(x)=x^3$ for $0\leq x\leq 1$ have infinitely many values between 0 and 1. Can you think of a way to express the same concepts of multiplying together and summing all the products that would allow us to work with these infinitely many values? Make a conjecture about how to define the dot product of two functions. You might be wrong (it's OK). Use your definition to compute the dot product of $f(x)=x^2$ and $g(x)=x^3$ for $0\leq x \leq 1$.
\end{enumerate}
Did you see integrals appear in your work above?  When we want to move from finite sums to infinite sums, integrals are often the key tool.
\end{problem}







%Fourth



\section{Prep for Tuesday July 2}

\begin{hw*}
 
\end{hw*}

Based off the last problem from the day before, we now generalize the dot product to functions.
\begin{definition}[The Inner Product of Two Functions]
 If $f$ and $g$ are two functions that are integrable on $[a,b]$, then we define the inner product over $[a,b]$  of the two functions to be the integral 
 $$\left<f,g\right> = \int_a^b f g dx.$$ 
 We multiply each $f(x)$ by the corresponding $g(x)$ and then add them all up.  It's the same idea as the dot product. 
 We use the notation $\left<f,g\right>$ instead of $f\cdot g$ to talk about the inner product of functions, because $f\cdot g$ represent multiplication.
\end{definition}

\begin{problem}
 Consider the two functions $f(x) = x^2$ and $g(x) = x^4$ defined on $[0,1]$. Also consider the two vectors $\vec u = (1,2,3)$ and $\vec v = (0,2,-4)$.  
 \begin{enumerate}
  \item Compute $\vec u\cdot \vec v$ and $\left<f,g\right>$. 
  \item Compute the length of $\vec u$ (so $|\vec u|$). Show that $|\vec u|^2 = \vec u\cdot \vec u$.
  \item Compute $\left<f,f\right>$. Generalize the previous part to give a definition of the ``length'' of the function $f$ in terms of the inner product, and then compute the length of $f$.  We often write $||f||$ to stand for this length.
  \item We know that $\cos\theta = \dfrac{\vec u\cdot \vec v}{|\vec u||\vec v|}$. This allows us to find the angle between $\vec u$ and $\vec v$. 
  Using the exact same idea, we define the angle between to functions to be $\cos \theta = \dfrac{\left<f,g\right>}{||||||g||}$. Compute the angle between $f$ and $g$. 
 \end{enumerate}


\end{problem}


Now that we have the ability to define lengths and angles of functions, let's also generalize the concept of orthogonality. This is the crucial piece we need to understand radio wave transmission.
\begin{definition}[Orthogonal]
We say that two functions $f$ and $g$ are orthogonal over $[a,b]$ if their inner product over $[a,b]$ equals zero.   
\end{definition}


\begin{problem}
 Complete each of the following:
 \begin{enumerate}
  \item Show that $f(x) = x$ and $f(x)=1$ and $g(x) = x$ are orthogonal over $[-3,3]$. Can you think of any other functions $h$ so that $f(x)=1$ and $h$ are orthogonal over $[-3,3]$?
  \item Show that $f=\cos(3x)$ and $g=\cos(4x)$ are orthogonal over $[-\pi,\pi]$.
  \item By hand, compute the integral $\int_{-\pi}^{\pi}\cos(ax)\cos(bx)dx$.  Hint: You might want to use a trig identity.  The product-to-sum identities will help.  I always head to Wikipedia and search for a list of trigonometric identities when I need to look one up.
  \item In the previous part, you should have obtained $$\left<\cos(ax),\cos(bx)\right>=\frac{2 a \sin (\pi  a) \cos (\pi  b)-2 b \cos (\pi  a) \sin (\pi 
   b)}{a^2-b^2}.$$
   If $a$ and $b$ are both integers, how does this simplify?
  \item If $a=b$, the previous formula does not work. Use a calculator to compute $\left<\cos(ax),\cos(ax)\right>$ if $a$ is an integer.
 \end{enumerate}

\end{problem}


For the next two problems, consider the following scenario, taken from the Interactive Mathematics Program (IMP) Year 2 book titled ``Cookies.'' This series of texts is an inquiry based approach to the entire high school curriculum.  This example (from page 5) is the opening examples from which they build an entire unit on inequalities, systems of equations, and more.  It's the teaser problem that opens the entire unit, and to which every idea in the unit can be tied.  For more information, please see the Interactive Mathematics Program website at \href{http://mathimp.org/}{http://mathimp.org/}.
\begin{center}
\begin{tikzpicture}
\draw node[rounded corners,fill=blue!10,inner sep=1ex,text width=6.5in]
{
 Abby and Bing Woo own a small bakery that specializes in cookies. They make only  two kinds of cookies -- plain and iced. They need to decide how many dozens of each kind of cookie to make for tomorrow.

 \bigskip
 The Woos know that each dozen of their plain cookies requires 1 pound of cookie dough (and no icing), and each dozen of their iced cookies requires 0.7 pounds of cookie dough and 0.4 pounds of icing.  The Woos also know that each dozen of the plain cookies requires about 0.1 hours of preparation time, and each dozen of the iced cookies requires about 0.15 hours of preparation time. Finally, they know that no matter how many of each kind they make, they will be able to sell them all. 

 \bigskip
 The Woo's decision is limited by three factors.
 
 
 \begin{itemize}
  \item The ingredients they have on hand -- they have 110 pounds of cookie dough and 32 pounds of icing.
  \item The amount of oven space available -- they have room to bake a total of 140 dozen cookies.
  \item The amount of preparation time available -- together they have 15 hours for cookie preparation.
 \end{itemize}

 
 \bigskip
 Why on earth should the Woo's care how many cookies of each kind they make? Well, you guessed it! They want to make as much profit as possible. The plain cookies sell for \$6.00 a dozen and cost \$4.50 a dozen to make.  The iced cookies sell for \$7.00 a dozen and cost \$5.00 a dozen to make. 

 \bigskip
 
 The Big Question is:
 \begin{quote}
 How many dozens of each kind of cookie should Abby and Bing make so that their profit is as high as possible.
\end{quote}
 };
 \end{tikzpicture}
 \end{center}


Over the next few days, we'll build a complete solution to this problem, and many others. Feel free to work ahead of the problem set, and answer this question.


\begin{problem}
Make sure you read the scenario above. 
Let $p$ be the number of dozens of plain cookies, and $i$ be the number of dozens of iced cookies that Abby and Bing will make for tomorrow.
\begin{enumerate}
 \item Pick some values for $p$ and $i$ that meets all the conditions in the scenario above (Abby and Bing could actually make this many dozens of each type of cookie). Show that you meet each of the conditions. Then state the profit that Abby and Bing will make if they use these numbers for $p$ and $i$. 
 \item Find some different values for $p$ and $i$ that will increase the profit above your previous choices. What is the profit for these values of $p$ and $i$.  
\end{enumerate}
\end{problem}

\begin{problem}
Again, let $p$ be the number of dozens of plain cookies, and $i$ be the number of dozens of iced cookies that Abby and Bing will make for tomorrow.
\begin{enumerate}
 \item The Bings have 100 lbs of cookie dough.  Since plain cookies require 1 lb of dough, and iced cookies require .7 lbs of dough, we know that a possible answer to their problem must satisfy the inequality $1p+.7i\leq 110$. Use the requirements on the lbs of icing, prep time, and oven time, to obtain three other inequalities. These four inequalities are often call constraints. 
 \item These 4 inequalities provide you with 4 equations of lines.  Draw these 4 lines in the $pi$-plane (so let $p$ be the $x$-axis and $i$ be the $y$-axis).
 \item Pick values for $p$ and $i$.  Test your choice against all 4 inequalities.  If it satisfies all 4 values use a green marker to put a dot on your graph. If your choice for $p$ and $i$ does not satisfy one of the conditions, put a red $X$ on that point.  
 \item Repeat the previous step for many values of $p$ and $i$, until you have many points that have a green dot, and many that have a red $X$.
 \item Use your pencil to shade the region in the plane that represents all possible options for $p$ and $i$. 
\end{enumerate}
\end{problem}



\section{Prep for Friday July 4}
Happy 4th of July! No Class
\section{Prep for Friday July 5}
We're canceling class on this day so that you have time to complete the exam.



\section{Prep for Monday July 8}

We talked about radio waves and radio communication.


\section{Prep for Tuesday July 9}

\begin{hw*}
 Complete problems 7.5 (page 264) and 7.9 (page 266) in Schaum's.
\end{hw*}


\begin{problem}
Last week we learned that if the columns of $A$ are pairwise orthogonal, then $A^TA$ is a diagonal matrix.  For example, if we let $A=\bvec{3&-8\\4&6}$, then we can compute $A^TA = \bvec{25&0\\ 0&100}.$ 
\begin{enumerate}
 \item What are the lengths of the columns of $A$?  How are the lengths of the columns of $A$ related to the product $A^TA$?
 \item Multiply the first column by $\frac{1}{5}$ to obtain the matrix $B=\bvec{3/5&-8\\4/5&6}$.  Now compute $B^TB$. How long is each column of $B$?
 \item How can you modify matrix $B$ to obtain a new matrix $C$ so that $C^TC$ is the identity matrix?  
\end{enumerate}
\end{problem}

\begin{problem}
 Suppose that $A$ is a 3 by 3 matrix so that $A^TA = I$ is the identity matrix. 
 \begin{enumerate}
  \item What do you know about the length of each column of $A$? 
  \item If we let $\vec c_1$ be the first column of $A$ and we let $\vec c_2$ be second column of $A$, then what is dot product $\vec c_1\cdot \vec c_2$? Explain.
  \item Give an example of a 3 by 3 matrix (not equal to the identity matrix) so that $A^TA=I$. This means that the inverse of the matrix is simply the transpose. 
 \end{enumerate}
\end{problem}


\marginpar{This is the graph of the 4 equations corresponding to these inequalities.

\includegraphics[width=\marginparwidth]{cookies1}}%
Remember the cookie problem from last week. Please reread the statement of the problem. In class we obtained the inequalities 
$$
p+.7i\leq110,\quad
.4i\leq32,\quad
p+i\leq140,\quad
.1p+.15i\leq15.
$$
See the right for a graph.


\begin{problem}
The profit function for the cookies problem is $P(p,i)=1.5p+2i$. On your calculator, start by obtaining a plot that has the 4 constraints (matching the plot to the right). Alternately, you can use Sage to obtain this plot.  See \href{http://bmw.byuimath.com/dokuwiki/doku.php?id=linear\_programming}{http://bmw.byuimath.com/dokuwiki/doku.php?id=linear\_programming}.
\begin{enumerate}
 \item If $p=20$ and $i=80$, then the profit is $P(20,80)=1.5(20)+2(80)=\$190$. There are other ways to make \$190. The curve $$1.5p+2i=\$190,$$
 would give all possible ways to make a profit of \$190.  Add this curve to the plot of the 4 constraints. Every point $(p,i)$ on this curve would result in profit of \$190. 
 \item If we wanted the profit to be \$200, this gives us the equation $1.5p+2i=\$200$.   Add this plot to the 4 equations you already have. 
 \item For each of \$210, \$220, and \$230, add a similar curve to your plot. 
 \item What do you think the maximum possible profit is, and how many plain and iced cookies should you make? Explain.
\end{enumerate}
\end{problem}



%Third
\begin{problem}
 Consider the profit function $P(x,y) = 1.5x+2y$.  
 \begin{enumerate}
  \item If we were to think of each variable as a function of $t$, then we could differentiate both sides with respect to $t$. Do this.  Your answer will involve $dx/dt$ and $dy/dt$.
  \item If we think of $dx/dt$ and $dy/dt$ as constants, then write $dP/dt$ as a linear combination and the matrix product
  $$\frac{dP}{dt} = (\quad)\frac{dx}{dt}+(\quad)\frac{dy}{dt} = \bvec{\rule{.5in}{.5pt}&\rule{.5in}{.5pt}}\bvec{dx/dt\\dy/dt}.$$
  \item On the same axes, draw the curves $0=1.5x+2y$, $2=1.5x+2y$, $4=1.5x+2y$, and $8=1.5x+2y$. If you end up with 4 parallel lines, then you're doing this right. 
  \item The matrix you obtained in part 2 represents a vector field (it happens to be a constant vector field). At several points on the lines you drew in part 3, draw the vector given from this vector field. If you get a bunch of vectors pointing up to the right, you're doing this correctly.
  \item Do you notice any connection between the lines you drew in part 3, and the vectors you drew in part 4?
 \end{enumerate}

\end{problem}













\section{Prep for Thursday July 11}

\begin{hw*}
 This will be up soon.  You can immediately jump into the second and third problems.
\end{hw*}

%First

\begin{center}
\begin{tikzpicture}
\draw node[rounded corners,fill=blue!10,inner sep=1ex,text width=6.5in]
{
[This problem again comes from the IMP program's text ``Cookies''.] The Hits on a Shoestring music company is planning its next month's work. The company makes CDs of both rock and rap music. 
 
 \bigskip
 It costs th ecompany an average of \$15,000 to produce a rock CD and an average of \$12,000 to produce a rap CD (the higher costs for rock comes from needing more instrumentalists for rock CDs).  
 Also, it takes about 18 hours to produce a rock CD and about 25 hours to produce a rap CD.
 
 \bigskip
 The company can afford to spend up to \$150,000 on production next month. Also, according to its agreement with the employee union, the company will spend at least 175 hours on production.
 
 \bigskip
 Hits on a Shoestring earns \$20,000 in profit on each rock CD it produces and \$30,000 in profit on each rap CD it produces.  But the company recently promised its distributor that it would not release more rap music than rock, because the distributor thinks the company is more closely associated with rock in the public mind. 
 
 \bigskip
 The company needs to decide how many of each type of CD to make.  Note It can make a fraction of a CD next month and finish it the month after.
 };
 \end{tikzpicture}
 \end{center}


\begin{problem}
Please read the scenario above. Then use it to answer the questions below.
\begin{enumerate}
 \item You should be able to obtain three constraints (inequalities) from the information above.  Use these three equations to determine the feasible region (region in which a solution can exist). Construct a plot that shows the feasible region.  Feel free to use Sage or your calculator. Use $x$ for rock CDs, and $y$ for rap CDs.  
 \item What is the profit function?  Draw several profit curves (constant profit) on your plot so that you have several parallel lines. 
 \item What should $x$ and $y$ equal to maximize the profit.
 \item If the distributor will allow us to make at most twice as many rap CDs as rock CDs, how does this change the answer?
\end{enumerate}



\end{problem}



%Second
\begin{problem}
In the original set up of the Wong's bakery problem, we assumed that the Wong's would sell all the cookies that they make.  This however may not be a valid assumption. Let's adjust this assumption slightly, and see what happens to the solution.

Suppose that the iced cookies are so popular that they will always sell all their iced cookies for a profit of \$2 per dozen.  However, the plain cookies are not as popular.  They have found that if they sell the cookies for profit of \$1.50 per dozen, then they will only sell 60 dozens.  If they drop the price by a penny, then they can sell one more dozen plain cookies.  If they raise the price a penny, they will sell 1 less dozen. For each drop in price of 1 penny, they will sell one additional dozen.
\begin{enumerate}
 \item If we let $c$ be cost of a cookie, and we let $p$ be the number of dozens of plain cookies sold, obtain an equation that relates $c$ to $p$.  Then show that the profit function for the Wong's is $P(p,i) = 2.1p-0.01p^2+2i$. 
 \item 
 \marginpar{\href{http://bmw.byuimath.com/dokuwiki/doku.php?id=linear\_programming}{You can use Sage} or your calculator.
}%
 If the profit is \$190, then we obtain the level profit curve $190 = 2.1p-0.01p^2+2i$. Plot this curve, together with the 4 constraint curves.
 \item Add to your plot the curves obtained by letting the profit equal \$200, \$210, \$220.   Then determine how many dozens of each cookie the Wong's should make to maximize their profit. 
\end{enumerate}


\end{problem}



%Third
The profit function from the previous problem was not linear. The graphs were parabolas. We needed to find a parabola that touched the feasible region.  We can turn these profit functions into vector fields, and then use the arrows to find our maximum profit.  To do this, we need to become comfortable with implicit differentiation, and writing linear combinations. 
\begin{problem}
Consider the function $f(x,y)=x^2+3y$. If we assume that both $x$ and $y$ depend on $t$, then we can use implicit differentiation to compute the derivative of $f$.  This gives us (remembering the chain rule) 
$$\frac{df}{dt} = 2x\frac{dx}{dt}+3\frac{dy}{dt} = \bvec{2x&3}\bvec{dx/dt\\dy/dt}.$$
The matrix $\bvec{2x&3}$ is called the derivative of $f$, and we'll often write it as $Df(x,y)$. This matrix does not depend on $t$ at all, rather it just depends on $x$ and $y$. \marginpar{If you've ever learned about partial derivatives, then you may notice that the partial derivatives are the columns of $f$. The partial derivatives form a part of the whole derivative.}

For each function below, use implicit differentiation and organize your work into matrix form to obtain the derivative of $f$.  
\begin{enumerate}
 \item $f(x,y) = x^2-3y^2$
 \item $f(x,y) = x^2+4xy+5y^2$ (You should get $Df(x,y) = \bvec{2x+4y&4x+10y}$. Don't forget the product rule on $(4x)(y)$.)
 \item $f(x,y) = x^2y^3$ (You'll need the product rule.)
 \item $f(x,y) = (1.5 - .01(x-60))x+2y$
 %\item $f(x,y) = (1.5 - .01(x-60))x+(2-.02(y-30))y$
 \item $f(x,y,z) = x^2y^3z^4$ (You should get a matrix that has 3 columns.) 
\end{enumerate}

\end{problem}



%Fourth
Draw several profit curves, and draw the corresponding vector field.  Make sure we leave class knowing the connection between the two. 
\begin{problem}
There will be one more problem.  It will have to do with drawing vector fields.  I'll give you software to help you with this one.
\end{problem}


\end{document}


\section{Prep for Friday July 12}
\begin{hw*}
 
\end{hw*}

%First
\begin{problem}

\end{problem}



%Second
\begin{problem}

\end{problem}



%Third
\begin{problem}

\end{problem}



%Fourth
\begin{problem}

\end{problem}


\section{Prep for Monday July 15}
\begin{hw*}
 
\end{hw*}

%First
\begin{problem}

\end{problem}



%Second
\begin{problem}

\end{problem}



%Third
\begin{problem}

\end{problem}



%Fourth
\begin{problem}

\end{problem}


\section{Prep for Tuesday July 16}
\begin{hw*}
 
\end{hw*}

%First
\begin{problem}

\end{problem}



%Second
\begin{problem}

\end{problem}



%Third
\begin{problem}

\end{problem}



%Fourth
\begin{problem}

\end{problem}


\section{Prep for Thursday July 18}
\begin{hw*}
 
\end{hw*}

%First
\begin{problem}

\end{problem}



%Second
\begin{problem}

\end{problem}



%Third
\begin{problem}

\end{problem}



%Fourth
\begin{problem}

\end{problem}


\section{Prep for Thursday July 19}
\begin{hw*}
 
\end{hw*}

%First
\begin{problem}

\end{problem}



%Second
\begin{problem}

\end{problem}



%Third
\begin{problem}

\end{problem}



%Fourth
\begin{problem}

\end{problem}














Over the next few days, one of our main goals is to learn how radio transmission works.  The idea is to focus on what it means to send out a radio wave.  

\begin{itemize}
 \item \href{http://mrdoob.github.io/three.js/examples/webgl\_geometry\_extrude\_splines.html}{http://mrdoob.github.io/three.js/examples/webgl\_geometry\_extrude\_splines.html}
\end{itemize}
The web browser you use must support WebGL to run. On my computer, Firefox works great, but Chrome does not.



%I would love to have a 3D picture drawn, and then place a camera in the picture.  I could then draw the 3D image and next to it put a 2D image (what the camera sees). Then we can talk about a kernel.
\begin{problem}
Please start by opening the link above.  Basically it allows you to see what it looks like to build a 3D animation of a roller coaster (and more). There's a lot going on in this applet. Make sure you toggle between having the ``Camera Spline Animation View'' turned on or off. Also see what happens if you put check marks in the checkboxes. 

This problem has to do with the kernel of a linear transformation.  Let's focus on 3D animations. 
\end{problem}















\end{document}
\section{Prep for Monday July 8}
\begin{hw*}
 
\end{hw*}

%First
\begin{problem}

\end{problem}



%Second
\begin{problem}

\end{problem}



%Third
\begin{problem}

\end{problem}



%Fourth
\begin{problem}

\end{problem}



\section{Prep for Friday July 12}
\section{Prep for Monday July 15}
\section{Prep for Tuesday July 16}
\section{Prep for Thursday July 18}
\section{Prep for Thursday July 19}
\section{Prep for Monday July 22}
\section{Prep for Tuesday July 23}






\end{document}
























\begin{problem}
 Kim and Ben currently have 3 kids and they drive a small Honda civic.  They decide to have another kid, which means they need a new car. After looking through several websites and consulting consumerreports.com, they decide to purchase a minivan (a Toyota Sienna).  The head online to AutoTrader.com, and search for several minivans online.  Ben teaches math at the university, so he decides to hunt for the best deal using what he teaches at school.  For each car in a 100 mile radius, he records the mileage and price. His data is summarized in table... which you can access in Sage at ...  He would like to find a line that best approximates the points.  
 
 Express the system of equations that Ben needs to solve as a matrix equation $A\vec x=\vec b$.  
 Find $A^TA$ and $A^T\vec b$.  Then find $(A^TA)^{-1}$.  Use this to obtain $\vec x$.  What is the equation of the least square regression line.
 The day after making this list, a new car appears in town.  It has mileage  ... and costs ...  Would you buy it?
 The next town over there is a car that has mileage ... and costs ...  Should you buy it?
\end{problem}





















If the matrix is symmetric, show that the eigenvectors are orthogonal.  Is this always true?  Yes!  Why?  What makes this true?  It's a huge theorem. This leads to the SVD.

Projection review, with movie preference example. Don't worry about the functions being orthogonal

Projection example onto a subspace (linear regression problem).  Have them compare and contrast two problems, where in one example the vectors are orthogonal and in the other they are not. Why are things easy....  

Another Linear programming problem.  This time draw the vector field associated with the profit function (by computing the derivative)


